{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\Shamir\\\\PycharmProjects\\\\future eye\\\\Overall_Training_Data_30July2019_v0.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1550, 35)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checkng the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>AF3_THETA</th>\n",
       "      <th>AF3_ALPHA</th>\n",
       "      <th>AF3_LOW_BETA</th>\n",
       "      <th>AF3_HIGH_BETA</th>\n",
       "      <th>AF3_GAMMA</th>\n",
       "      <th>T7_THETA</th>\n",
       "      <th>T7_ALPHA</th>\n",
       "      <th>T7_LOW_BETA</th>\n",
       "      <th>...</th>\n",
       "      <th>AF4_HIGH_BETA</th>\n",
       "      <th>AF4_GAMMA</th>\n",
       "      <th>CQ_AF3</th>\n",
       "      <th>CQ_T7</th>\n",
       "      <th>CQ_Pz</th>\n",
       "      <th>CQ_T8</th>\n",
       "      <th>CQ_AF4</th>\n",
       "      <th>TimeStamp_Readable</th>\n",
       "      <th>seconds_of_timestamp</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>449</td>\n",
       "      <td>1563945527</td>\n",
       "      <td>1602.004637</td>\n",
       "      <td>820.143124</td>\n",
       "      <td>468.603529</td>\n",
       "      <td>312.692672</td>\n",
       "      <td>43.838238</td>\n",
       "      <td>1.113403</td>\n",
       "      <td>3.143814</td>\n",
       "      <td>3.228099</td>\n",
       "      <td>...</td>\n",
       "      <td>321.680915</td>\n",
       "      <td>43.443617</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18:47.1</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450</td>\n",
       "      <td>1563945527</td>\n",
       "      <td>1648.410749</td>\n",
       "      <td>1027.630001</td>\n",
       "      <td>543.252317</td>\n",
       "      <td>273.849371</td>\n",
       "      <td>47.554865</td>\n",
       "      <td>1.187707</td>\n",
       "      <td>3.543250</td>\n",
       "      <td>3.267439</td>\n",
       "      <td>...</td>\n",
       "      <td>275.556757</td>\n",
       "      <td>46.710437</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18:47.2</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>451</td>\n",
       "      <td>1563945527</td>\n",
       "      <td>1605.193182</td>\n",
       "      <td>1189.284067</td>\n",
       "      <td>630.953231</td>\n",
       "      <td>250.604223</td>\n",
       "      <td>52.334560</td>\n",
       "      <td>1.174995</td>\n",
       "      <td>3.800832</td>\n",
       "      <td>3.285394</td>\n",
       "      <td>...</td>\n",
       "      <td>247.283044</td>\n",
       "      <td>51.381376</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18:47.3</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>452</td>\n",
       "      <td>1563945527</td>\n",
       "      <td>1462.585805</td>\n",
       "      <td>1264.364852</td>\n",
       "      <td>703.198872</td>\n",
       "      <td>249.608310</td>\n",
       "      <td>57.832213</td>\n",
       "      <td>1.237306</td>\n",
       "      <td>3.847343</td>\n",
       "      <td>3.329154</td>\n",
       "      <td>...</td>\n",
       "      <td>242.736111</td>\n",
       "      <td>57.083412</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18:47.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>453</td>\n",
       "      <td>1563945528</td>\n",
       "      <td>1305.079769</td>\n",
       "      <td>1264.657727</td>\n",
       "      <td>762.149646</td>\n",
       "      <td>275.511102</td>\n",
       "      <td>63.599263</td>\n",
       "      <td>1.214110</td>\n",
       "      <td>3.735482</td>\n",
       "      <td>3.538992</td>\n",
       "      <td>...</td>\n",
       "      <td>265.861959</td>\n",
       "      <td>63.196649</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18:47.6</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   TimeStamp    AF3_THETA    AF3_ALPHA  AF3_LOW_BETA  \\\n",
       "0         449  1563945527  1602.004637   820.143124    468.603529   \n",
       "1         450  1563945527  1648.410749  1027.630001    543.252317   \n",
       "2         451  1563945527  1605.193182  1189.284067    630.953231   \n",
       "3         452  1563945527  1462.585805  1264.364852    703.198872   \n",
       "4         453  1563945528  1305.079769  1264.657727    762.149646   \n",
       "\n",
       "   AF3_HIGH_BETA  AF3_GAMMA  T7_THETA  T7_ALPHA  T7_LOW_BETA  ...  \\\n",
       "0     312.692672  43.838238  1.113403  3.143814     3.228099  ...   \n",
       "1     273.849371  47.554865  1.187707  3.543250     3.267439  ...   \n",
       "2     250.604223  52.334560  1.174995  3.800832     3.285394  ...   \n",
       "3     249.608310  57.832213  1.237306  3.847343     3.329154  ...   \n",
       "4     275.511102  63.599263  1.214110  3.735482     3.538992  ...   \n",
       "\n",
       "   AF4_HIGH_BETA  AF4_GAMMA  CQ_AF3  CQ_T7  CQ_Pz  CQ_T8  CQ_AF4  \\\n",
       "0     321.680915  43.443617       4      0      4      2       2   \n",
       "1     275.556757  46.710437       4      0      4      2       2   \n",
       "2     247.283044  51.381376       4      0      4      2       2   \n",
       "3     242.736111  57.083412       4      0      4      2       2   \n",
       "4     265.861959  63.196649       4      0      1      4       4   \n",
       "\n",
       "   TimeStamp_Readable  seconds_of_timestamp  Label  \n",
       "0             18:47.1                    47      1  \n",
       "1             18:47.2                    47      1  \n",
       "2             18:47.3                    47      1  \n",
       "3             18:47.5                    47      1  \n",
       "4             18:47.6                    47      1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1550 entries, 0 to 1549\n",
      "Data columns (total 35 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            1550 non-null   int64  \n",
      " 1   TimeStamp             1550 non-null   int64  \n",
      " 2   AF3_THETA             1550 non-null   float64\n",
      " 3   AF3_ALPHA             1550 non-null   float64\n",
      " 4   AF3_LOW_BETA          1550 non-null   float64\n",
      " 5   AF3_HIGH_BETA         1550 non-null   float64\n",
      " 6   AF3_GAMMA             1550 non-null   float64\n",
      " 7   T7_THETA              1550 non-null   float64\n",
      " 8   T7_ALPHA              1550 non-null   float64\n",
      " 9   T7_LOW_BETA           1550 non-null   float64\n",
      " 10  T7_HIGH_BETA          1550 non-null   float64\n",
      " 11  T7_GAMMA              1550 non-null   float64\n",
      " 12  Pz_THETA              1550 non-null   float64\n",
      " 13  Pz_ALPHA              1550 non-null   float64\n",
      " 14  Pz_LOW_BETA           1550 non-null   float64\n",
      " 15  Pz_HIGH_BETA          1550 non-null   float64\n",
      " 16  Pz_GAMMA              1550 non-null   float64\n",
      " 17  T8_THETA              1550 non-null   float64\n",
      " 18  T8_ALPHA              1550 non-null   float64\n",
      " 19  T8_LOW_BETA           1550 non-null   float64\n",
      " 20  T8_HIGH_BETA          1550 non-null   float64\n",
      " 21  T8_GAMMA              1550 non-null   float64\n",
      " 22  AF4_THETA             1550 non-null   float64\n",
      " 23  AF4_ALPHA             1550 non-null   float64\n",
      " 24  AF4_LOW_BETA          1550 non-null   float64\n",
      " 25  AF4_HIGH_BETA         1550 non-null   float64\n",
      " 26  AF4_GAMMA             1550 non-null   float64\n",
      " 27  CQ_AF3                1550 non-null   int64  \n",
      " 28  CQ_T7                 1550 non-null   int64  \n",
      " 29  CQ_Pz                 1550 non-null   int64  \n",
      " 30  CQ_T8                 1550 non-null   int64  \n",
      " 31  CQ_AF4                1550 non-null   int64  \n",
      " 32  TimeStamp_Readable    1550 non-null   object \n",
      " 33  seconds_of_timestamp  1550 non-null   int64  \n",
      " 34  Label                 1550 non-null   int64  \n",
      "dtypes: float64(25), int64(9), object(1)\n",
      "memory usage: 424.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#information about each attribute\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>AF3_THETA</th>\n",
       "      <th>AF3_ALPHA</th>\n",
       "      <th>AF3_LOW_BETA</th>\n",
       "      <th>AF3_HIGH_BETA</th>\n",
       "      <th>AF3_GAMMA</th>\n",
       "      <th>T7_THETA</th>\n",
       "      <th>T7_ALPHA</th>\n",
       "      <th>T7_LOW_BETA</th>\n",
       "      <th>...</th>\n",
       "      <th>AF4_LOW_BETA</th>\n",
       "      <th>AF4_HIGH_BETA</th>\n",
       "      <th>AF4_GAMMA</th>\n",
       "      <th>CQ_AF3</th>\n",
       "      <th>CQ_T7</th>\n",
       "      <th>CQ_Pz</th>\n",
       "      <th>CQ_T8</th>\n",
       "      <th>CQ_AF4</th>\n",
       "      <th>seconds_of_timestamp</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1.550000e+03</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1114.807097</td>\n",
       "      <td>1.564145e+09</td>\n",
       "      <td>1549.064953</td>\n",
       "      <td>650.558935</td>\n",
       "      <td>251.449355</td>\n",
       "      <td>79.770908</td>\n",
       "      <td>18.621272</td>\n",
       "      <td>57.545559</td>\n",
       "      <td>11.945923</td>\n",
       "      <td>5.659711</td>\n",
       "      <td>...</td>\n",
       "      <td>239.277757</td>\n",
       "      <td>77.028814</td>\n",
       "      <td>16.570991</td>\n",
       "      <td>3.824516</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>1.970323</td>\n",
       "      <td>3.863871</td>\n",
       "      <td>3.820645</td>\n",
       "      <td>27.116129</td>\n",
       "      <td>2.494839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>329.877542</td>\n",
       "      <td>9.984974e+04</td>\n",
       "      <td>8057.989865</td>\n",
       "      <td>3348.831447</td>\n",
       "      <td>1255.027448</td>\n",
       "      <td>403.163899</td>\n",
       "      <td>90.477763</td>\n",
       "      <td>410.407526</td>\n",
       "      <td>109.756889</td>\n",
       "      <td>38.754052</td>\n",
       "      <td>...</td>\n",
       "      <td>1197.815250</td>\n",
       "      <td>399.503613</td>\n",
       "      <td>90.458850</td>\n",
       "      <td>0.714269</td>\n",
       "      <td>1.667023</td>\n",
       "      <td>1.701902</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.724085</td>\n",
       "      <td>16.528769</td>\n",
       "      <td>1.119537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>449.000000</td>\n",
       "      <td>1.563946e+09</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.124150</td>\n",
       "      <td>0.127748</td>\n",
       "      <td>0.052506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>809.250000</td>\n",
       "      <td>1.564194e+09</td>\n",
       "      <td>7.485803</td>\n",
       "      <td>3.910045</td>\n",
       "      <td>2.569978</td>\n",
       "      <td>1.736854</td>\n",
       "      <td>1.199417</td>\n",
       "      <td>0.642321</td>\n",
       "      <td>0.636984</td>\n",
       "      <td>0.583449</td>\n",
       "      <td>...</td>\n",
       "      <td>2.156875</td>\n",
       "      <td>1.581896</td>\n",
       "      <td>1.038773</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1180.500000</td>\n",
       "      <td>1.564194e+09</td>\n",
       "      <td>17.506139</td>\n",
       "      <td>6.748391</td>\n",
       "      <td>4.740691</td>\n",
       "      <td>3.383892</td>\n",
       "      <td>2.416862</td>\n",
       "      <td>1.203127</td>\n",
       "      <td>1.193747</td>\n",
       "      <td>0.967019</td>\n",
       "      <td>...</td>\n",
       "      <td>4.035095</td>\n",
       "      <td>2.593284</td>\n",
       "      <td>2.167698</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1382.750000</td>\n",
       "      <td>1.564195e+09</td>\n",
       "      <td>46.821041</td>\n",
       "      <td>13.160046</td>\n",
       "      <td>8.797218</td>\n",
       "      <td>8.473603</td>\n",
       "      <td>7.813450</td>\n",
       "      <td>2.190947</td>\n",
       "      <td>2.294018</td>\n",
       "      <td>2.303781</td>\n",
       "      <td>...</td>\n",
       "      <td>7.414548</td>\n",
       "      <td>4.990787</td>\n",
       "      <td>4.734957</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1681.000000</td>\n",
       "      <td>1.564197e+09</td>\n",
       "      <td>90293.425120</td>\n",
       "      <td>34604.705590</td>\n",
       "      <td>10233.842950</td>\n",
       "      <td>4883.002471</td>\n",
       "      <td>1434.346143</td>\n",
       "      <td>7267.583591</td>\n",
       "      <td>2039.531480</td>\n",
       "      <td>708.018749</td>\n",
       "      <td>...</td>\n",
       "      <td>10029.288400</td>\n",
       "      <td>4903.277441</td>\n",
       "      <td>1440.991202</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     TimeStamp     AF3_THETA     AF3_ALPHA  AF3_LOW_BETA  \\\n",
       "count  1550.000000  1.550000e+03   1550.000000   1550.000000   1550.000000   \n",
       "mean   1114.807097  1.564145e+09   1549.064953    650.558935    251.449355   \n",
       "std     329.877542  9.984974e+04   8057.989865   3348.831447   1255.027448   \n",
       "min     449.000000  1.563946e+09      0.001542      0.000756      0.000428   \n",
       "25%     809.250000  1.564194e+09      7.485803      3.910045      2.569978   \n",
       "50%    1180.500000  1.564194e+09     17.506139      6.748391      4.740691   \n",
       "75%    1382.750000  1.564195e+09     46.821041     13.160046      8.797218   \n",
       "max    1681.000000  1.564197e+09  90293.425120  34604.705590  10233.842950   \n",
       "\n",
       "       AF3_HIGH_BETA    AF3_GAMMA     T7_THETA     T7_ALPHA  T7_LOW_BETA  ...  \\\n",
       "count    1550.000000  1550.000000  1550.000000  1550.000000  1550.000000  ...   \n",
       "mean       79.770908    18.621272    57.545559    11.945923     5.659711  ...   \n",
       "std       403.163899    90.477763   410.407526   109.756889    38.754052  ...   \n",
       "min         0.000373     0.000113     0.124150     0.127748     0.052506  ...   \n",
       "25%         1.736854     1.199417     0.642321     0.636984     0.583449  ...   \n",
       "50%         3.383892     2.416862     1.203127     1.193747     0.967019  ...   \n",
       "75%         8.473603     7.813450     2.190947     2.294018     2.303781  ...   \n",
       "max      4883.002471  1434.346143  7267.583591  2039.531480   708.018749  ...   \n",
       "\n",
       "       AF4_LOW_BETA  AF4_HIGH_BETA    AF4_GAMMA       CQ_AF3        CQ_T7  \\\n",
       "count   1550.000000    1550.000000  1550.000000  1550.000000  1550.000000   \n",
       "mean     239.277757      77.028814    16.570991     3.824516     2.140000   \n",
       "std     1197.815250     399.503613    90.458850     0.714269     1.667023   \n",
       "min        0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "25%        2.156875       1.581896     1.038773     4.000000     1.000000   \n",
       "50%        4.035095       2.593284     2.167698     4.000000     1.000000   \n",
       "75%        7.414548       4.990787     4.734957     4.000000     4.000000   \n",
       "max    10029.288400    4903.277441  1440.991202     4.000000     4.000000   \n",
       "\n",
       "             CQ_Pz        CQ_T8       CQ_AF4  seconds_of_timestamp  \\\n",
       "count  1550.000000  1550.000000  1550.000000           1550.000000   \n",
       "mean      1.970323     3.863871     3.820645             27.116129   \n",
       "std       1.701902     0.607823     0.724085             16.528769   \n",
       "min       0.000000     0.000000     0.000000              0.000000   \n",
       "25%       0.000000     4.000000     4.000000             13.000000   \n",
       "50%       2.000000     4.000000     4.000000             25.000000   \n",
       "75%       4.000000     4.000000     4.000000             41.000000   \n",
       "max       4.000000     4.000000     4.000000             59.000000   \n",
       "\n",
       "             Label  \n",
       "count  1550.000000  \n",
       "mean      2.494839  \n",
       "std       1.119537  \n",
       "min       1.000000  \n",
       "25%       1.000000  \n",
       "50%       2.000000  \n",
       "75%       3.000000  \n",
       "max       4.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              0\n",
       "TimeStamp               0\n",
       "AF3_THETA               0\n",
       "AF3_ALPHA               0\n",
       "AF3_LOW_BETA            0\n",
       "AF3_HIGH_BETA           0\n",
       "AF3_GAMMA               0\n",
       "T7_THETA                0\n",
       "T7_ALPHA                0\n",
       "T7_LOW_BETA             0\n",
       "T7_HIGH_BETA            0\n",
       "T7_GAMMA                0\n",
       "Pz_THETA                0\n",
       "Pz_ALPHA                0\n",
       "Pz_LOW_BETA             0\n",
       "Pz_HIGH_BETA            0\n",
       "Pz_GAMMA                0\n",
       "T8_THETA                0\n",
       "T8_ALPHA                0\n",
       "T8_LOW_BETA             0\n",
       "T8_HIGH_BETA            0\n",
       "T8_GAMMA                0\n",
       "AF4_THETA               0\n",
       "AF4_ALPHA               0\n",
       "AF4_LOW_BETA            0\n",
       "AF4_HIGH_BETA           0\n",
       "AF4_GAMMA               0\n",
       "CQ_AF3                  0\n",
       "CQ_T7                   0\n",
       "CQ_Pz                   0\n",
       "CQ_T8                   0\n",
       "CQ_AF4                  0\n",
       "TimeStamp_Readable      0\n",
       "seconds_of_timestamp    0\n",
       "Label                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the data for better results\n",
    "data=data.reindex(np.random.permutation(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>AF3_THETA</th>\n",
       "      <th>AF3_ALPHA</th>\n",
       "      <th>AF3_LOW_BETA</th>\n",
       "      <th>AF3_HIGH_BETA</th>\n",
       "      <th>AF3_GAMMA</th>\n",
       "      <th>T7_THETA</th>\n",
       "      <th>T7_ALPHA</th>\n",
       "      <th>T7_LOW_BETA</th>\n",
       "      <th>...</th>\n",
       "      <th>AF4_HIGH_BETA</th>\n",
       "      <th>AF4_GAMMA</th>\n",
       "      <th>CQ_AF3</th>\n",
       "      <th>CQ_T7</th>\n",
       "      <th>CQ_Pz</th>\n",
       "      <th>CQ_T8</th>\n",
       "      <th>CQ_AF4</th>\n",
       "      <th>TimeStamp_Readable</th>\n",
       "      <th>seconds_of_timestamp</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1227</td>\n",
       "      <td>1564194471</td>\n",
       "      <td>12.726230</td>\n",
       "      <td>19.844567</td>\n",
       "      <td>9.713400</td>\n",
       "      <td>8.942052</td>\n",
       "      <td>5.941134</td>\n",
       "      <td>0.589011</td>\n",
       "      <td>1.621218</td>\n",
       "      <td>1.265758</td>\n",
       "      <td>...</td>\n",
       "      <td>9.152907</td>\n",
       "      <td>6.297666</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27:50.6</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1149</td>\n",
       "      <td>1564194461</td>\n",
       "      <td>14.909019</td>\n",
       "      <td>11.870369</td>\n",
       "      <td>19.704848</td>\n",
       "      <td>5.685385</td>\n",
       "      <td>3.108268</td>\n",
       "      <td>1.723112</td>\n",
       "      <td>1.002739</td>\n",
       "      <td>1.020720</td>\n",
       "      <td>...</td>\n",
       "      <td>5.735370</td>\n",
       "      <td>2.846950</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27:40.7</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>1517</td>\n",
       "      <td>1564196551</td>\n",
       "      <td>1.623020</td>\n",
       "      <td>0.821573</td>\n",
       "      <td>1.601461</td>\n",
       "      <td>0.849796</td>\n",
       "      <td>0.496348</td>\n",
       "      <td>0.962294</td>\n",
       "      <td>0.432965</td>\n",
       "      <td>0.733779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889711</td>\n",
       "      <td>0.454725</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>02:31.2</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1320</td>\n",
       "      <td>1564194482</td>\n",
       "      <td>8.969575</td>\n",
       "      <td>22.033707</td>\n",
       "      <td>18.431503</td>\n",
       "      <td>6.780860</td>\n",
       "      <td>5.490058</td>\n",
       "      <td>0.826573</td>\n",
       "      <td>1.905906</td>\n",
       "      <td>3.227909</td>\n",
       "      <td>...</td>\n",
       "      <td>8.454829</td>\n",
       "      <td>5.494282</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>28:02.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1302</td>\n",
       "      <td>1564194480</td>\n",
       "      <td>18.204900</td>\n",
       "      <td>14.722269</td>\n",
       "      <td>8.856604</td>\n",
       "      <td>7.207677</td>\n",
       "      <td>4.556495</td>\n",
       "      <td>0.715697</td>\n",
       "      <td>1.225095</td>\n",
       "      <td>0.786003</td>\n",
       "      <td>...</td>\n",
       "      <td>5.499905</td>\n",
       "      <td>6.027209</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>28:00.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   TimeStamp  AF3_THETA  AF3_ALPHA  AF3_LOW_BETA  \\\n",
       "414         1227  1564194471  12.726230  19.844567      9.713400   \n",
       "354         1149  1564194461  14.909019  11.870369     19.704848   \n",
       "1403        1517  1564196551   1.623020   0.821573      1.601461   \n",
       "489         1320  1564194482   8.969575  22.033707     18.431503   \n",
       "471         1302  1564194480  18.204900  14.722269      8.856604   \n",
       "\n",
       "      AF3_HIGH_BETA  AF3_GAMMA  T7_THETA  T7_ALPHA  T7_LOW_BETA  ...  \\\n",
       "414        8.942052   5.941134  0.589011  1.621218     1.265758  ...   \n",
       "354        5.685385   3.108268  1.723112  1.002739     1.020720  ...   \n",
       "1403       0.849796   0.496348  0.962294  0.432965     0.733779  ...   \n",
       "489        6.780860   5.490058  0.826573  1.905906     3.227909  ...   \n",
       "471        7.207677   4.556495  0.715697  1.225095     0.786003  ...   \n",
       "\n",
       "      AF4_HIGH_BETA  AF4_GAMMA  CQ_AF3  CQ_T7  CQ_Pz  CQ_T8  CQ_AF4  \\\n",
       "414        9.152907   6.297666       4      1      1      4       4   \n",
       "354        5.735370   2.846950       4      1      0      4       4   \n",
       "1403       0.889711   0.454725       4      4      4      4       4   \n",
       "489        8.454829   5.494282       4      1      0      4       4   \n",
       "471        5.499905   6.027209       4      1      0      4       4   \n",
       "\n",
       "      TimeStamp_Readable  seconds_of_timestamp  Label  \n",
       "414              27:50.6                    50      2  \n",
       "354              27:40.7                    40      1  \n",
       "1403             02:31.2                    31      3  \n",
       "489              28:02.3                     2      3  \n",
       "471              28:00.0                     0      3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Label']\n",
    "data = data.drop(['Label','TimeStamp','TimeStamp_Readable','seconds_of_timestamp','CQ_AF3','CQ_T7','CQ_Pz','CQ_T8','CQ_AF4'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AF3_THETA</th>\n",
       "      <th>AF3_ALPHA</th>\n",
       "      <th>AF3_LOW_BETA</th>\n",
       "      <th>AF3_HIGH_BETA</th>\n",
       "      <th>AF3_GAMMA</th>\n",
       "      <th>T7_THETA</th>\n",
       "      <th>T7_ALPHA</th>\n",
       "      <th>T7_LOW_BETA</th>\n",
       "      <th>T7_HIGH_BETA</th>\n",
       "      <th>...</th>\n",
       "      <th>T8_THETA</th>\n",
       "      <th>T8_ALPHA</th>\n",
       "      <th>T8_LOW_BETA</th>\n",
       "      <th>T8_HIGH_BETA</th>\n",
       "      <th>T8_GAMMA</th>\n",
       "      <th>AF4_THETA</th>\n",
       "      <th>AF4_ALPHA</th>\n",
       "      <th>AF4_LOW_BETA</th>\n",
       "      <th>AF4_HIGH_BETA</th>\n",
       "      <th>AF4_GAMMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1227</td>\n",
       "      <td>12.726230</td>\n",
       "      <td>19.844567</td>\n",
       "      <td>9.713400</td>\n",
       "      <td>8.942052</td>\n",
       "      <td>5.941134</td>\n",
       "      <td>0.589011</td>\n",
       "      <td>1.621218</td>\n",
       "      <td>1.265758</td>\n",
       "      <td>1.637947</td>\n",
       "      <td>...</td>\n",
       "      <td>6.451215</td>\n",
       "      <td>25.355407</td>\n",
       "      <td>8.492784</td>\n",
       "      <td>9.415896</td>\n",
       "      <td>6.528726</td>\n",
       "      <td>7.466402</td>\n",
       "      <td>23.095866</td>\n",
       "      <td>8.970308</td>\n",
       "      <td>9.152907</td>\n",
       "      <td>6.297666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1149</td>\n",
       "      <td>14.909019</td>\n",
       "      <td>11.870369</td>\n",
       "      <td>19.704848</td>\n",
       "      <td>5.685385</td>\n",
       "      <td>3.108268</td>\n",
       "      <td>1.723112</td>\n",
       "      <td>1.002739</td>\n",
       "      <td>1.020720</td>\n",
       "      <td>1.257025</td>\n",
       "      <td>...</td>\n",
       "      <td>9.971119</td>\n",
       "      <td>9.942204</td>\n",
       "      <td>15.124484</td>\n",
       "      <td>8.980670</td>\n",
       "      <td>4.625246</td>\n",
       "      <td>32.258727</td>\n",
       "      <td>14.448040</td>\n",
       "      <td>16.930656</td>\n",
       "      <td>5.735370</td>\n",
       "      <td>2.846950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>1517</td>\n",
       "      <td>1.623020</td>\n",
       "      <td>0.821573</td>\n",
       "      <td>1.601461</td>\n",
       "      <td>0.849796</td>\n",
       "      <td>0.496348</td>\n",
       "      <td>0.962294</td>\n",
       "      <td>0.432965</td>\n",
       "      <td>0.733779</td>\n",
       "      <td>0.394708</td>\n",
       "      <td>...</td>\n",
       "      <td>1.256251</td>\n",
       "      <td>0.735139</td>\n",
       "      <td>0.978498</td>\n",
       "      <td>0.803878</td>\n",
       "      <td>0.573701</td>\n",
       "      <td>1.340886</td>\n",
       "      <td>1.005539</td>\n",
       "      <td>1.801735</td>\n",
       "      <td>0.889711</td>\n",
       "      <td>0.454725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1320</td>\n",
       "      <td>8.969575</td>\n",
       "      <td>22.033707</td>\n",
       "      <td>18.431503</td>\n",
       "      <td>6.780860</td>\n",
       "      <td>5.490058</td>\n",
       "      <td>0.826573</td>\n",
       "      <td>1.905906</td>\n",
       "      <td>3.227909</td>\n",
       "      <td>0.890798</td>\n",
       "      <td>...</td>\n",
       "      <td>10.156426</td>\n",
       "      <td>22.419656</td>\n",
       "      <td>25.418539</td>\n",
       "      <td>8.300292</td>\n",
       "      <td>7.544211</td>\n",
       "      <td>12.301363</td>\n",
       "      <td>28.309988</td>\n",
       "      <td>20.289352</td>\n",
       "      <td>8.454829</td>\n",
       "      <td>5.494282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1302</td>\n",
       "      <td>18.204900</td>\n",
       "      <td>14.722269</td>\n",
       "      <td>8.856604</td>\n",
       "      <td>7.207677</td>\n",
       "      <td>4.556495</td>\n",
       "      <td>0.715697</td>\n",
       "      <td>1.225095</td>\n",
       "      <td>0.786003</td>\n",
       "      <td>0.870750</td>\n",
       "      <td>...</td>\n",
       "      <td>9.995492</td>\n",
       "      <td>16.648648</td>\n",
       "      <td>6.859594</td>\n",
       "      <td>4.520854</td>\n",
       "      <td>6.046772</td>\n",
       "      <td>14.137458</td>\n",
       "      <td>11.674797</td>\n",
       "      <td>5.028948</td>\n",
       "      <td>5.499905</td>\n",
       "      <td>6.027209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  AF3_THETA  AF3_ALPHA  AF3_LOW_BETA  AF3_HIGH_BETA  \\\n",
       "414         1227  12.726230  19.844567      9.713400       8.942052   \n",
       "354         1149  14.909019  11.870369     19.704848       5.685385   \n",
       "1403        1517   1.623020   0.821573      1.601461       0.849796   \n",
       "489         1320   8.969575  22.033707     18.431503       6.780860   \n",
       "471         1302  18.204900  14.722269      8.856604       7.207677   \n",
       "\n",
       "      AF3_GAMMA  T7_THETA  T7_ALPHA  T7_LOW_BETA  T7_HIGH_BETA  ...  \\\n",
       "414    5.941134  0.589011  1.621218     1.265758      1.637947  ...   \n",
       "354    3.108268  1.723112  1.002739     1.020720      1.257025  ...   \n",
       "1403   0.496348  0.962294  0.432965     0.733779      0.394708  ...   \n",
       "489    5.490058  0.826573  1.905906     3.227909      0.890798  ...   \n",
       "471    4.556495  0.715697  1.225095     0.786003      0.870750  ...   \n",
       "\n",
       "       T8_THETA   T8_ALPHA  T8_LOW_BETA  T8_HIGH_BETA  T8_GAMMA  AF4_THETA  \\\n",
       "414    6.451215  25.355407     8.492784      9.415896  6.528726   7.466402   \n",
       "354    9.971119   9.942204    15.124484      8.980670  4.625246  32.258727   \n",
       "1403   1.256251   0.735139     0.978498      0.803878  0.573701   1.340886   \n",
       "489   10.156426  22.419656    25.418539      8.300292  7.544211  12.301363   \n",
       "471    9.995492  16.648648     6.859594      4.520854  6.046772  14.137458   \n",
       "\n",
       "      AF4_ALPHA  AF4_LOW_BETA  AF4_HIGH_BETA  AF4_GAMMA  \n",
       "414   23.095866      8.970308       9.152907   6.297666  \n",
       "354   14.448040     16.930656       5.735370   2.846950  \n",
       "1403   1.005539      1.801735       0.889711   0.454725  \n",
       "489   28.309988     20.289352       8.454829   5.494282  \n",
       "471   11.674797      5.028948       5.499905   6.027209  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the un-named Column\n",
    "data = data.drop(data.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the dataset- scaling down the data\n",
    "x = preprocessing.StandardScaler().fit(x).transform(x.astype(float))\n",
    "#attaching the lost hedder while preprocesing the data. \n",
    "x = pd.DataFrame(x, columns = data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1550, 25)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1550,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data to x_train, y_train, x_test, y_test with test set size of 20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split( np.asarray(x), np.asarray(y), test_size=0.2, random_state=0,shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train : (1240, 25)\n",
      "Shape of x_test : (310, 25)\n",
      "Shape of y_train : (1240,)\n",
      "Shape of y_test : (310,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of x_train :\", x_train.shape)\n",
    "print(\"Shape of x_test :\", x_test.shape)\n",
    "print(\"Shape of y_train :\", y_train.shape)\n",
    "print(\"Shape of y_test :\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414     2\n",
       "354     1\n",
       "1403    3\n",
       "489     3\n",
       "471     3\n",
       "       ..\n",
       "944     1\n",
       "1499    4\n",
       "353     1\n",
       "544     4\n",
       "561     4\n",
       "Name: Label, Length: 1550, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# The known number of output classes.\n",
    "num_classes = 5\n",
    "# Input dimensions\n",
    "input_shape = (25,)\n",
    "# Convert class vectors to binary class matrices. This uses 1 hot encoding.\n",
    "y_train_binary = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_binary = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.reshape(1240, 5, 5, 1)\n",
    "x_test = x_test.reshape(310, 5, 5, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 64)          320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 33,861\n",
      "Trainable params: 33,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1240 samples, validate on 310 samples\n",
      "Epoch 1/1500\n",
      "1240/1240 [==============================] - 1s 592us/sample - loss: 1.3361 - acc: 0.3234 - val_loss: 1.3429 - val_acc: 0.3387\n",
      "Epoch 2/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 1.2747 - acc: 0.3435 - val_loss: 1.2768 - val_acc: 0.2968\n",
      "Epoch 3/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 1.2627 - acc: 0.3395 - val_loss: 1.2576 - val_acc: 0.3548\n",
      "Epoch 4/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 1.2517 - acc: 0.3589 - val_loss: 1.2562 - val_acc: 0.3548\n",
      "Epoch 5/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 1.2417 - acc: 0.3790 - val_loss: 1.2395 - val_acc: 0.4129\n",
      "Epoch 6/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 1.2318 - acc: 0.3976 - val_loss: 1.2226 - val_acc: 0.3677\n",
      "Epoch 7/1500\n",
      "1240/1240 [==============================] - 0s 299us/sample - loss: 1.2217 - acc: 0.4105 - val_loss: 1.2176 - val_acc: 0.4194\n",
      "Epoch 8/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 1.2105 - acc: 0.4226 - val_loss: 1.2028 - val_acc: 0.4419\n",
      "Epoch 9/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 1.2029 - acc: 0.4290 - val_loss: 1.1896 - val_acc: 0.3968\n",
      "Epoch 10/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 1.1947 - acc: 0.4218 - val_loss: 1.1911 - val_acc: 0.3871\n",
      "Epoch 11/1500\n",
      "1240/1240 [==============================] - 1s 404us/sample - loss: 1.1848 - acc: 0.4306 - val_loss: 1.1838 - val_acc: 0.4323\n",
      "Epoch 12/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 1.1812 - acc: 0.4460 - val_loss: 1.1995 - val_acc: 0.4452\n",
      "Epoch 13/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 1.1828 - acc: 0.4331 - val_loss: 1.1783 - val_acc: 0.4258\n",
      "Epoch 14/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 1.1784 - acc: 0.4476 - val_loss: 1.1861 - val_acc: 0.4548\n",
      "Epoch 15/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 1.1748 - acc: 0.4371 - val_loss: 1.1729 - val_acc: 0.4323\n",
      "Epoch 16/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 1.1699 - acc: 0.4468 - val_loss: 1.1583 - val_acc: 0.4290\n",
      "Epoch 17/1500\n",
      "1240/1240 [==============================] - 0s 374us/sample - loss: 1.1723 - acc: 0.4427 - val_loss: 1.1580 - val_acc: 0.4194\n",
      "Epoch 18/1500\n",
      "1240/1240 [==============================] - 0s 366us/sample - loss: 1.1685 - acc: 0.4468 - val_loss: 1.1590 - val_acc: 0.4129\n",
      "Epoch 19/1500\n",
      "1240/1240 [==============================] - 0s 367us/sample - loss: 1.1588 - acc: 0.4516 - val_loss: 1.1712 - val_acc: 0.4710\n",
      "Epoch 20/1500\n",
      "1240/1240 [==============================] - 0s 296us/sample - loss: 1.1627 - acc: 0.4452 - val_loss: 1.1394 - val_acc: 0.4581\n",
      "Epoch 21/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 1.1520 - acc: 0.4573 - val_loss: 1.1990 - val_acc: 0.4355\n",
      "Epoch 22/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 1.1568 - acc: 0.4661 - val_loss: 1.1410 - val_acc: 0.4839\n",
      "Epoch 23/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 1.1502 - acc: 0.4589 - val_loss: 1.1515 - val_acc: 0.4419\n",
      "Epoch 24/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 1.1463 - acc: 0.4532 - val_loss: 1.1541 - val_acc: 0.4548\n",
      "Epoch 25/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 1.1462 - acc: 0.4718 - val_loss: 1.1231 - val_acc: 0.4645\n",
      "Epoch 26/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 1.1433 - acc: 0.4653 - val_loss: 1.1385 - val_acc: 0.4484\n",
      "Epoch 27/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 1.1387 - acc: 0.4677 - val_loss: 1.1123 - val_acc: 0.4645\n",
      "Epoch 28/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 1.1357 - acc: 0.4685 - val_loss: 1.1104 - val_acc: 0.4613\n",
      "Epoch 29/1500\n",
      "1240/1240 [==============================] - 0s 292us/sample - loss: 1.1290 - acc: 0.4629 - val_loss: 1.1196 - val_acc: 0.4516\n",
      "Epoch 30/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 1.1294 - acc: 0.4718 - val_loss: 1.1066 - val_acc: 0.4806\n",
      "Epoch 31/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 1.1269 - acc: 0.4645 - val_loss: 1.1052 - val_acc: 0.5129\n",
      "Epoch 32/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 1.1189 - acc: 0.4879 - val_loss: 1.0993 - val_acc: 0.5258\n",
      "Epoch 33/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 1.1192 - acc: 0.4782 - val_loss: 1.0943 - val_acc: 0.4903\n",
      "Epoch 34/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 1.1159 - acc: 0.4831 - val_loss: 1.0911 - val_acc: 0.5000\n",
      "Epoch 35/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 1.1116 - acc: 0.4790 - val_loss: 1.1120 - val_acc: 0.4968\n",
      "Epoch 36/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 1.1096 - acc: 0.4734 - val_loss: 1.0698 - val_acc: 0.5097\n",
      "Epoch 37/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 1.1046 - acc: 0.4863 - val_loss: 1.0936 - val_acc: 0.4806\n",
      "Epoch 38/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 1.0982 - acc: 0.4992 - val_loss: 1.1149 - val_acc: 0.4774\n",
      "Epoch 39/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 1.0994 - acc: 0.4895 - val_loss: 1.0631 - val_acc: 0.5194\n",
      "Epoch 40/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 1.0912 - acc: 0.5105 - val_loss: 1.0619 - val_acc: 0.4935\n",
      "Epoch 41/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 1.0898 - acc: 0.4911 - val_loss: 1.0534 - val_acc: 0.5161\n",
      "Epoch 42/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 1.0891 - acc: 0.4871 - val_loss: 1.0485 - val_acc: 0.5065\n",
      "Epoch 43/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 1.0810 - acc: 0.5040 - val_loss: 1.0497 - val_acc: 0.5161\n",
      "Epoch 44/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 1.0783 - acc: 0.5089 - val_loss: 1.0602 - val_acc: 0.5129\n",
      "Epoch 45/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 1.0707 - acc: 0.5008 - val_loss: 1.0485 - val_acc: 0.5097\n",
      "Epoch 46/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 1.0689 - acc: 0.5161 - val_loss: 1.0484 - val_acc: 0.5032\n",
      "Epoch 47/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 1.0663 - acc: 0.5137 - val_loss: 1.0784 - val_acc: 0.4968\n",
      "Epoch 48/1500\n",
      "1240/1240 [==============================] - 0s 295us/sample - loss: 1.0654 - acc: 0.5016 - val_loss: 1.0202 - val_acc: 0.5290\n",
      "Epoch 49/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 1.0619 - acc: 0.5089 - val_loss: 1.0277 - val_acc: 0.5161\n",
      "Epoch 50/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 1.0574 - acc: 0.5234 - val_loss: 1.0311 - val_acc: 0.4871\n",
      "Epoch 51/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 1.0572 - acc: 0.5210 - val_loss: 1.0166 - val_acc: 0.4968\n",
      "Epoch 52/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 1.0498 - acc: 0.5218 - val_loss: 1.0299 - val_acc: 0.5194\n",
      "Epoch 53/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 1.0502 - acc: 0.5210 - val_loss: 1.0214 - val_acc: 0.5129\n",
      "Epoch 54/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 1.0514 - acc: 0.5097 - val_loss: 1.0055 - val_acc: 0.5194\n",
      "Epoch 55/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 1.0419 - acc: 0.5137 - val_loss: 1.0144 - val_acc: 0.5258\n",
      "Epoch 56/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 1.0411 - acc: 0.5169 - val_loss: 1.0143 - val_acc: 0.5645\n",
      "Epoch 57/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 1.0332 - acc: 0.5306 - val_loss: 1.0337 - val_acc: 0.5000\n",
      "Epoch 58/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 1.0343 - acc: 0.5258 - val_loss: 1.0006 - val_acc: 0.5484\n",
      "Epoch 59/1500\n",
      "1240/1240 [==============================] - 0s 339us/sample - loss: 1.0256 - acc: 0.5379 - val_loss: 1.0128 - val_acc: 0.5290\n",
      "Epoch 60/1500\n",
      "1240/1240 [==============================] - 0s 320us/sample - loss: 1.0232 - acc: 0.5339 - val_loss: 0.9821 - val_acc: 0.5677\n",
      "Epoch 61/1500\n",
      "1240/1240 [==============================] - 0s 347us/sample - loss: 1.0179 - acc: 0.5444 - val_loss: 0.9986 - val_acc: 0.5226\n",
      "Epoch 62/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 1.0162 - acc: 0.5508 - val_loss: 1.0056 - val_acc: 0.5258\n",
      "Epoch 63/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 1.0168 - acc: 0.5540 - val_loss: 0.9896 - val_acc: 0.5355\n",
      "Epoch 64/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 1.0159 - acc: 0.5323 - val_loss: 0.9825 - val_acc: 0.5419\n",
      "Epoch 65/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 1.0219 - acc: 0.5379 - val_loss: 0.9797 - val_acc: 0.5419\n",
      "Epoch 66/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 1.0094 - acc: 0.5379 - val_loss: 0.9661 - val_acc: 0.5581\n",
      "Epoch 67/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 1.0040 - acc: 0.5492 - val_loss: 0.9862 - val_acc: 0.5677\n",
      "Epoch 68/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 1.0058 - acc: 0.5516 - val_loss: 0.9744 - val_acc: 0.5484\n",
      "Epoch 69/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 1.0027 - acc: 0.5492 - val_loss: 1.0181 - val_acc: 0.5161\n",
      "Epoch 70/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.9976 - acc: 0.5427 - val_loss: 0.9786 - val_acc: 0.5548\n",
      "Epoch 71/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.9931 - acc: 0.5500 - val_loss: 0.9553 - val_acc: 0.5677\n",
      "Epoch 72/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.9951 - acc: 0.5516 - val_loss: 0.9723 - val_acc: 0.5387\n",
      "Epoch 73/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.9927 - acc: 0.5371 - val_loss: 0.9553 - val_acc: 0.5613\n",
      "Epoch 74/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.9840 - acc: 0.5613 - val_loss: 0.9601 - val_acc: 0.5935\n",
      "Epoch 75/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.9838 - acc: 0.5540 - val_loss: 0.9660 - val_acc: 0.5613\n",
      "Epoch 76/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.9800 - acc: 0.5556 - val_loss: 0.9384 - val_acc: 0.5839\n",
      "Epoch 77/1500\n",
      "1240/1240 [==============================] - 0s 268us/sample - loss: 0.9825 - acc: 0.5677 - val_loss: 0.9280 - val_acc: 0.5806\n",
      "Epoch 78/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.9809 - acc: 0.5573 - val_loss: 0.9340 - val_acc: 0.5871\n",
      "Epoch 79/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.9743 - acc: 0.5565 - val_loss: 1.0200 - val_acc: 0.5161\n",
      "Epoch 80/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.9700 - acc: 0.5734 - val_loss: 0.9441 - val_acc: 0.5774\n",
      "Epoch 81/1500\n",
      "1240/1240 [==============================] - 0s 295us/sample - loss: 0.9704 - acc: 0.5637 - val_loss: 0.9291 - val_acc: 0.5742\n",
      "Epoch 82/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.9670 - acc: 0.5661 - val_loss: 0.9184 - val_acc: 0.5806\n",
      "Epoch 83/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.9642 - acc: 0.5653 - val_loss: 0.9526 - val_acc: 0.5516\n",
      "Epoch 84/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.9597 - acc: 0.5750 - val_loss: 0.9515 - val_acc: 0.5516\n",
      "Epoch 85/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.9651 - acc: 0.5629 - val_loss: 0.9333 - val_acc: 0.5613\n",
      "Epoch 86/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.9577 - acc: 0.5742 - val_loss: 0.9244 - val_acc: 0.5677\n",
      "Epoch 87/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.9599 - acc: 0.5685 - val_loss: 0.9269 - val_acc: 0.5516\n",
      "Epoch 88/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.9525 - acc: 0.5677 - val_loss: 0.9107 - val_acc: 0.5677\n",
      "Epoch 89/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.9488 - acc: 0.5726 - val_loss: 0.9094 - val_acc: 0.6032\n",
      "Epoch 90/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.9397 - acc: 0.5758 - val_loss: 0.9079 - val_acc: 0.5677\n",
      "Epoch 91/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.9425 - acc: 0.5726 - val_loss: 0.9166 - val_acc: 0.5935\n",
      "Epoch 92/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.9469 - acc: 0.5685 - val_loss: 0.9029 - val_acc: 0.5871\n",
      "Epoch 93/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.9418 - acc: 0.5871 - val_loss: 0.8909 - val_acc: 0.6032\n",
      "Epoch 94/1500\n",
      "1240/1240 [==============================] - 0s 319us/sample - loss: 0.9347 - acc: 0.5863 - val_loss: 0.8963 - val_acc: 0.5806\n",
      "Epoch 95/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.9360 - acc: 0.5694 - val_loss: 0.9237 - val_acc: 0.5774\n",
      "Epoch 96/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.9293 - acc: 0.5927 - val_loss: 0.9184 - val_acc: 0.5774\n",
      "Epoch 97/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.9298 - acc: 0.5847 - val_loss: 0.9085 - val_acc: 0.6097\n",
      "Epoch 98/1500\n",
      "1240/1240 [==============================] - 0s 340us/sample - loss: 0.9261 - acc: 0.5726 - val_loss: 0.9177 - val_acc: 0.6129\n",
      "Epoch 99/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.9207 - acc: 0.5984 - val_loss: 0.8752 - val_acc: 0.6290\n",
      "Epoch 100/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.9202 - acc: 0.5895 - val_loss: 0.8697 - val_acc: 0.6419\n",
      "Epoch 101/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.9229 - acc: 0.5935 - val_loss: 0.8602 - val_acc: 0.6323\n",
      "Epoch 102/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.9153 - acc: 0.6008 - val_loss: 0.8683 - val_acc: 0.6032\n",
      "Epoch 103/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.9120 - acc: 0.5919 - val_loss: 0.8849 - val_acc: 0.6129\n",
      "Epoch 104/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.9119 - acc: 0.5798 - val_loss: 0.8973 - val_acc: 0.6194\n",
      "Epoch 105/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.9136 - acc: 0.5960 - val_loss: 0.8769 - val_acc: 0.6032\n",
      "Epoch 106/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.9011 - acc: 0.5919 - val_loss: 0.8659 - val_acc: 0.6032\n",
      "Epoch 107/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.9068 - acc: 0.5968 - val_loss: 0.8886 - val_acc: 0.6194\n",
      "Epoch 108/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.8999 - acc: 0.6048 - val_loss: 0.8656 - val_acc: 0.6097\n",
      "Epoch 109/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.9010 - acc: 0.5879 - val_loss: 0.8659 - val_acc: 0.6355\n",
      "Epoch 110/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.9005 - acc: 0.5879 - val_loss: 0.8417 - val_acc: 0.6000\n",
      "Epoch 111/1500\n",
      "1240/1240 [==============================] - 0s 321us/sample - loss: 0.8924 - acc: 0.5944 - val_loss: 0.8945 - val_acc: 0.5839\n",
      "Epoch 112/1500\n",
      "1240/1240 [==============================] - 0s 337us/sample - loss: 0.8955 - acc: 0.5903 - val_loss: 0.8434 - val_acc: 0.6032\n",
      "Epoch 113/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.8887 - acc: 0.5992 - val_loss: 0.8589 - val_acc: 0.6194\n",
      "Epoch 114/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.8876 - acc: 0.6056 - val_loss: 0.8927 - val_acc: 0.5903\n",
      "Epoch 115/1500\n",
      "1240/1240 [==============================] - 0s 293us/sample - loss: 0.8880 - acc: 0.6024 - val_loss: 0.8596 - val_acc: 0.6065\n",
      "Epoch 116/1500\n",
      "1240/1240 [==============================] - 0s 355us/sample - loss: 0.8813 - acc: 0.6024 - val_loss: 0.8748 - val_acc: 0.6258\n",
      "Epoch 117/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.8838 - acc: 0.6113 - val_loss: 0.8561 - val_acc: 0.6097\n",
      "Epoch 118/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.8714 - acc: 0.6169 - val_loss: 0.8352 - val_acc: 0.6290\n",
      "Epoch 119/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.8722 - acc: 0.6161 - val_loss: 0.8504 - val_acc: 0.6355\n",
      "Epoch 120/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.8716 - acc: 0.6040 - val_loss: 0.8250 - val_acc: 0.6355\n",
      "Epoch 121/1500\n",
      "1240/1240 [==============================] - 0s 346us/sample - loss: 0.8635 - acc: 0.6153 - val_loss: 0.8171 - val_acc: 0.6419\n",
      "Epoch 122/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.8657 - acc: 0.6258 - val_loss: 0.8273 - val_acc: 0.6516\n",
      "Epoch 123/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.8696 - acc: 0.6040 - val_loss: 0.8220 - val_acc: 0.6355\n",
      "Epoch 124/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.8648 - acc: 0.6169 - val_loss: 0.8225 - val_acc: 0.6677\n",
      "Epoch 125/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.8596 - acc: 0.6089 - val_loss: 0.8785 - val_acc: 0.6065\n",
      "Epoch 126/1500\n",
      "1240/1240 [==============================] - 0s 266us/sample - loss: 0.8614 - acc: 0.6129 - val_loss: 0.8369 - val_acc: 0.6000\n",
      "Epoch 127/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.8540 - acc: 0.6105 - val_loss: 0.8395 - val_acc: 0.5935\n",
      "Epoch 128/1500\n",
      "1240/1240 [==============================] - 0s 266us/sample - loss: 0.8600 - acc: 0.6048 - val_loss: 0.8260 - val_acc: 0.5935\n",
      "Epoch 129/1500\n",
      "1240/1240 [==============================] - 0s 264us/sample - loss: 0.8487 - acc: 0.6258 - val_loss: 0.8200 - val_acc: 0.6581\n",
      "Epoch 130/1500\n",
      "1240/1240 [==============================] - 0s 265us/sample - loss: 0.8550 - acc: 0.6008 - val_loss: 0.8021 - val_acc: 0.6516\n",
      "Epoch 131/1500\n",
      "1240/1240 [==============================] - 0s 262us/sample - loss: 0.8522 - acc: 0.6153 - val_loss: 0.8363 - val_acc: 0.6129\n",
      "Epoch 132/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.8344 - acc: 0.6282 - val_loss: 0.8120 - val_acc: 0.6774\n",
      "Epoch 133/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.8363 - acc: 0.6210 - val_loss: 0.8104 - val_acc: 0.6677\n",
      "Epoch 134/1500\n",
      "1240/1240 [==============================] - 0s 268us/sample - loss: 0.8433 - acc: 0.6161 - val_loss: 0.8188 - val_acc: 0.6452\n",
      "Epoch 135/1500\n",
      "1240/1240 [==============================] - 0s 267us/sample - loss: 0.8343 - acc: 0.6282 - val_loss: 0.7914 - val_acc: 0.6452\n",
      "Epoch 136/1500\n",
      "1240/1240 [==============================] - 0s 264us/sample - loss: 0.8396 - acc: 0.6194 - val_loss: 0.8333 - val_acc: 0.6419\n",
      "Epoch 137/1500\n",
      "1240/1240 [==============================] - 0s 266us/sample - loss: 0.8342 - acc: 0.6355 - val_loss: 0.8148 - val_acc: 0.6355\n",
      "Epoch 138/1500\n",
      "1240/1240 [==============================] - 0s 265us/sample - loss: 0.8328 - acc: 0.6250 - val_loss: 0.8009 - val_acc: 0.6677\n",
      "Epoch 139/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.8289 - acc: 0.6250 - val_loss: 0.8458 - val_acc: 0.6065\n",
      "Epoch 140/1500\n",
      "1240/1240 [==============================] - 0s 265us/sample - loss: 0.8304 - acc: 0.6274 - val_loss: 0.7750 - val_acc: 0.6742\n",
      "Epoch 141/1500\n",
      "1240/1240 [==============================] - 0s 265us/sample - loss: 0.8208 - acc: 0.6379 - val_loss: 0.7948 - val_acc: 0.6548\n",
      "Epoch 142/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.8123 - acc: 0.6282 - val_loss: 0.8050 - val_acc: 0.6387\n",
      "Epoch 143/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.8202 - acc: 0.6347 - val_loss: 0.7665 - val_acc: 0.6806\n",
      "Epoch 144/1500\n",
      "1240/1240 [==============================] - 0s 262us/sample - loss: 0.8126 - acc: 0.6290 - val_loss: 0.7675 - val_acc: 0.6484\n",
      "Epoch 145/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.8182 - acc: 0.6419 - val_loss: 0.7823 - val_acc: 0.6645\n",
      "Epoch 146/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.8205 - acc: 0.6387 - val_loss: 0.7576 - val_acc: 0.6742\n",
      "Epoch 147/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.8143 - acc: 0.6379 - val_loss: 0.7519 - val_acc: 0.6935\n",
      "Epoch 148/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.8093 - acc: 0.6484 - val_loss: 0.8035 - val_acc: 0.6419\n",
      "Epoch 149/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 0.8146 - acc: 0.6484 - val_loss: 0.7585 - val_acc: 0.6806\n",
      "Epoch 150/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.8131 - acc: 0.6395 - val_loss: 0.8009 - val_acc: 0.6452\n",
      "Epoch 151/1500\n",
      "1240/1240 [==============================] - 0s 268us/sample - loss: 0.7982 - acc: 0.6298 - val_loss: 0.7847 - val_acc: 0.6452\n",
      "Epoch 152/1500\n",
      "1240/1240 [==============================] - 0s 267us/sample - loss: 0.7978 - acc: 0.6540 - val_loss: 0.7661 - val_acc: 0.6484\n",
      "Epoch 153/1500\n",
      "1240/1240 [==============================] - 0s 321us/sample - loss: 0.7950 - acc: 0.6435 - val_loss: 0.7463 - val_acc: 0.6613\n",
      "Epoch 154/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.7985 - acc: 0.6403 - val_loss: 0.8183 - val_acc: 0.6355\n",
      "Epoch 155/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.7938 - acc: 0.6444 - val_loss: 0.7636 - val_acc: 0.6935\n",
      "Epoch 156/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.7971 - acc: 0.6387 - val_loss: 0.7685 - val_acc: 0.6774\n",
      "Epoch 157/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.7907 - acc: 0.6476 - val_loss: 0.8364 - val_acc: 0.6226\n",
      "Epoch 158/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.7909 - acc: 0.6532 - val_loss: 0.7833 - val_acc: 0.6774\n",
      "Epoch 159/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.7896 - acc: 0.6556 - val_loss: 0.7670 - val_acc: 0.6839\n",
      "Epoch 160/1500\n",
      "1240/1240 [==============================] - 0s 265us/sample - loss: 0.7884 - acc: 0.6548 - val_loss: 0.7511 - val_acc: 0.6839\n",
      "Epoch 161/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.7805 - acc: 0.6653 - val_loss: 0.7549 - val_acc: 0.6774\n",
      "Epoch 162/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.7773 - acc: 0.6524 - val_loss: 0.7620 - val_acc: 0.6839\n",
      "Epoch 163/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.7766 - acc: 0.6548 - val_loss: 0.7429 - val_acc: 0.6871\n",
      "Epoch 164/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.7809 - acc: 0.6565 - val_loss: 0.7794 - val_acc: 0.6484\n",
      "Epoch 165/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.7714 - acc: 0.6669 - val_loss: 0.8027 - val_acc: 0.6129\n",
      "Epoch 166/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.7769 - acc: 0.6540 - val_loss: 0.7364 - val_acc: 0.6677\n",
      "Epoch 167/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.7709 - acc: 0.6774 - val_loss: 0.8045 - val_acc: 0.6677\n",
      "Epoch 168/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.7705 - acc: 0.6621 - val_loss: 0.7720 - val_acc: 0.6742\n",
      "Epoch 169/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.7639 - acc: 0.6790 - val_loss: 0.7628 - val_acc: 0.7065\n",
      "Epoch 170/1500\n",
      "1240/1240 [==============================] - 0s 262us/sample - loss: 0.7622 - acc: 0.6613 - val_loss: 0.7385 - val_acc: 0.6839\n",
      "Epoch 171/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.7637 - acc: 0.6734 - val_loss: 0.7740 - val_acc: 0.6645\n",
      "Epoch 172/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.7619 - acc: 0.6758 - val_loss: 0.7380 - val_acc: 0.6677\n",
      "Epoch 173/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.7504 - acc: 0.6718 - val_loss: 0.7264 - val_acc: 0.6903\n",
      "Epoch 174/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.7646 - acc: 0.6597 - val_loss: 0.8088 - val_acc: 0.6355\n",
      "Epoch 175/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.7638 - acc: 0.6758 - val_loss: 0.6932 - val_acc: 0.7065\n",
      "Epoch 176/1500\n",
      "1240/1240 [==============================] - 0s 258us/sample - loss: 0.7548 - acc: 0.6742 - val_loss: 0.7442 - val_acc: 0.6935\n",
      "Epoch 177/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.7513 - acc: 0.6742 - val_loss: 0.6996 - val_acc: 0.7258\n",
      "Epoch 178/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.7465 - acc: 0.6702 - val_loss: 0.7270 - val_acc: 0.6710\n",
      "Epoch 179/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.7537 - acc: 0.6702 - val_loss: 0.7751 - val_acc: 0.6806\n",
      "Epoch 180/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.7441 - acc: 0.6879 - val_loss: 0.8481 - val_acc: 0.6129\n",
      "Epoch 181/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.7451 - acc: 0.6823 - val_loss: 0.7358 - val_acc: 0.6935\n",
      "Epoch 182/1500\n",
      "1240/1240 [==============================] - 0s 260us/sample - loss: 0.7444 - acc: 0.6782 - val_loss: 0.7002 - val_acc: 0.7161\n",
      "Epoch 183/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.7447 - acc: 0.6823 - val_loss: 0.7022 - val_acc: 0.7290\n",
      "Epoch 184/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.7390 - acc: 0.6855 - val_loss: 0.7250 - val_acc: 0.7032\n",
      "Epoch 185/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.7424 - acc: 0.6758 - val_loss: 0.6775 - val_acc: 0.7323\n",
      "Epoch 186/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.7374 - acc: 0.6758 - val_loss: 0.6950 - val_acc: 0.6871\n",
      "Epoch 187/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.7381 - acc: 0.6702 - val_loss: 0.6876 - val_acc: 0.7032\n",
      "Epoch 188/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.7330 - acc: 0.6758 - val_loss: 0.7415 - val_acc: 0.6710\n",
      "Epoch 189/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.7293 - acc: 0.6839 - val_loss: 0.6885 - val_acc: 0.7097\n",
      "Epoch 190/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.7324 - acc: 0.6806 - val_loss: 0.7523 - val_acc: 0.6903\n",
      "Epoch 191/1500\n",
      "1240/1240 [==============================] - 0s 258us/sample - loss: 0.7250 - acc: 0.6927 - val_loss: 0.6988 - val_acc: 0.6935\n",
      "Epoch 192/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.7176 - acc: 0.6960 - val_loss: 0.7309 - val_acc: 0.6613\n",
      "Epoch 193/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.7302 - acc: 0.6968 - val_loss: 0.6921 - val_acc: 0.7226\n",
      "Epoch 194/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.7281 - acc: 0.6823 - val_loss: 0.6995 - val_acc: 0.7065\n",
      "Epoch 195/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.7271 - acc: 0.6823 - val_loss: 0.7648 - val_acc: 0.6516\n",
      "Epoch 196/1500\n",
      "1240/1240 [==============================] - 0s 248us/sample - loss: 0.7131 - acc: 0.6911 - val_loss: 0.7130 - val_acc: 0.7000\n",
      "Epoch 197/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.7170 - acc: 0.6839 - val_loss: 0.7066 - val_acc: 0.7032\n",
      "Epoch 198/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.7199 - acc: 0.6903 - val_loss: 0.6657 - val_acc: 0.7226\n",
      "Epoch 199/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.7176 - acc: 0.6887 - val_loss: 0.7152 - val_acc: 0.6968\n",
      "Epoch 200/1500\n",
      "1240/1240 [==============================] - 0s 295us/sample - loss: 0.7087 - acc: 0.6944 - val_loss: 0.6859 - val_acc: 0.6903\n",
      "Epoch 201/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.7113 - acc: 0.6911 - val_loss: 0.7447 - val_acc: 0.6548\n",
      "Epoch 202/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.7107 - acc: 0.6903 - val_loss: 0.7194 - val_acc: 0.6774\n",
      "Epoch 203/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.7126 - acc: 0.6895 - val_loss: 0.7151 - val_acc: 0.6742\n",
      "Epoch 204/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.7126 - acc: 0.6879 - val_loss: 0.6682 - val_acc: 0.7323\n",
      "Epoch 205/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.7023 - acc: 0.7040 - val_loss: 0.6784 - val_acc: 0.7065\n",
      "Epoch 206/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.7021 - acc: 0.6879 - val_loss: 0.7541 - val_acc: 0.6581\n",
      "Epoch 207/1500\n",
      "1240/1240 [==============================] - 0s 266us/sample - loss: 0.6974 - acc: 0.7032 - val_loss: 0.6897 - val_acc: 0.7065\n",
      "Epoch 208/1500\n",
      "1240/1240 [==============================] - 0s 261us/sample - loss: 0.7050 - acc: 0.6952 - val_loss: 0.6804 - val_acc: 0.7161\n",
      "Epoch 209/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.6954 - acc: 0.6984 - val_loss: 0.6883 - val_acc: 0.7129\n",
      "Epoch 210/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.6975 - acc: 0.6960 - val_loss: 0.6998 - val_acc: 0.7097\n",
      "Epoch 211/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6958 - acc: 0.7032 - val_loss: 0.7316 - val_acc: 0.6774\n",
      "Epoch 212/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.6960 - acc: 0.6960 - val_loss: 0.6863 - val_acc: 0.6806\n",
      "Epoch 213/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6916 - acc: 0.6992 - val_loss: 0.6488 - val_acc: 0.7161\n",
      "Epoch 214/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6915 - acc: 0.7040 - val_loss: 0.6442 - val_acc: 0.7355\n",
      "Epoch 215/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6803 - acc: 0.7024 - val_loss: 0.7025 - val_acc: 0.7000\n",
      "Epoch 216/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6827 - acc: 0.7056 - val_loss: 0.6960 - val_acc: 0.6806\n",
      "Epoch 217/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.7000 - acc: 0.6935 - val_loss: 0.6334 - val_acc: 0.7226\n",
      "Epoch 218/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6805 - acc: 0.6984 - val_loss: 0.6645 - val_acc: 0.7194\n",
      "Epoch 219/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.6860 - acc: 0.6960 - val_loss: 0.6876 - val_acc: 0.6806\n",
      "Epoch 220/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.6803 - acc: 0.7016 - val_loss: 0.6476 - val_acc: 0.7226\n",
      "Epoch 221/1500\n",
      "1240/1240 [==============================] - 0s 252us/sample - loss: 0.6781 - acc: 0.7194 - val_loss: 0.6765 - val_acc: 0.7097\n",
      "Epoch 222/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6711 - acc: 0.7210 - val_loss: 0.6901 - val_acc: 0.7129\n",
      "Epoch 223/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6794 - acc: 0.7040 - val_loss: 0.6519 - val_acc: 0.7387\n",
      "Epoch 224/1500\n",
      "1240/1240 [==============================] - 0s 263us/sample - loss: 0.6807 - acc: 0.7089 - val_loss: 0.6658 - val_acc: 0.6871\n",
      "Epoch 225/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.6726 - acc: 0.7081 - val_loss: 0.7362 - val_acc: 0.6774\n",
      "Epoch 226/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.6764 - acc: 0.7016 - val_loss: 0.6198 - val_acc: 0.7323\n",
      "Epoch 227/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6724 - acc: 0.7097 - val_loss: 0.6245 - val_acc: 0.7258\n",
      "Epoch 228/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6750 - acc: 0.6992 - val_loss: 0.6707 - val_acc: 0.7032\n",
      "Epoch 229/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.6698 - acc: 0.7129 - val_loss: 0.6789 - val_acc: 0.7323\n",
      "Epoch 230/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.6642 - acc: 0.7129 - val_loss: 0.6382 - val_acc: 0.7323\n",
      "Epoch 231/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6737 - acc: 0.7089 - val_loss: 0.6300 - val_acc: 0.7194\n",
      "Epoch 232/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.6679 - acc: 0.7105 - val_loss: 0.6104 - val_acc: 0.7194\n",
      "Epoch 233/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6575 - acc: 0.7161 - val_loss: 0.6265 - val_acc: 0.7258\n",
      "Epoch 234/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6596 - acc: 0.7169 - val_loss: 0.6254 - val_acc: 0.7129\n",
      "Epoch 235/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.6616 - acc: 0.7202 - val_loss: 0.6516 - val_acc: 0.7161\n",
      "Epoch 236/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.6634 - acc: 0.7065 - val_loss: 0.6086 - val_acc: 0.7484\n",
      "Epoch 237/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.6604 - acc: 0.7177 - val_loss: 0.6379 - val_acc: 0.7226\n",
      "Epoch 238/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6481 - acc: 0.7210 - val_loss: 0.6639 - val_acc: 0.7387\n",
      "Epoch 239/1500\n",
      "1240/1240 [==============================] - 0s 258us/sample - loss: 0.6566 - acc: 0.7153 - val_loss: 0.6073 - val_acc: 0.7355\n",
      "Epoch 240/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6482 - acc: 0.7177 - val_loss: 0.6604 - val_acc: 0.7000\n",
      "Epoch 241/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.6550 - acc: 0.7258 - val_loss: 0.6570 - val_acc: 0.7161\n",
      "Epoch 242/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6408 - acc: 0.7290 - val_loss: 0.6386 - val_acc: 0.7516\n",
      "Epoch 243/1500\n",
      "1240/1240 [==============================] - 0s 252us/sample - loss: 0.6488 - acc: 0.7185 - val_loss: 0.6435 - val_acc: 0.7484\n",
      "Epoch 244/1500\n",
      "1240/1240 [==============================] - 0s 252us/sample - loss: 0.6503 - acc: 0.7177 - val_loss: 0.6159 - val_acc: 0.7258\n",
      "Epoch 245/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.6494 - acc: 0.7218 - val_loss: 0.6284 - val_acc: 0.7258\n",
      "Epoch 246/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.6407 - acc: 0.7258 - val_loss: 0.6516 - val_acc: 0.6871\n",
      "Epoch 247/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6426 - acc: 0.7315 - val_loss: 0.6129 - val_acc: 0.7516\n",
      "Epoch 248/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6438 - acc: 0.7129 - val_loss: 0.6046 - val_acc: 0.7419\n",
      "Epoch 249/1500\n",
      "1240/1240 [==============================] - 0s 246us/sample - loss: 0.6404 - acc: 0.7282 - val_loss: 0.6741 - val_acc: 0.7194\n",
      "Epoch 250/1500\n",
      "1240/1240 [==============================] - 0s 261us/sample - loss: 0.6362 - acc: 0.7306 - val_loss: 0.6165 - val_acc: 0.7355\n",
      "Epoch 251/1500\n",
      "1240/1240 [==============================] - 0s 266us/sample - loss: 0.6403 - acc: 0.7242 - val_loss: 0.6161 - val_acc: 0.7097\n",
      "Epoch 252/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6341 - acc: 0.7460 - val_loss: 0.6133 - val_acc: 0.7194\n",
      "Epoch 253/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6338 - acc: 0.7347 - val_loss: 0.6075 - val_acc: 0.7419\n",
      "Epoch 254/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.6251 - acc: 0.7403 - val_loss: 0.6307 - val_acc: 0.7065\n",
      "Epoch 255/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.6329 - acc: 0.7363 - val_loss: 0.7024 - val_acc: 0.7161\n",
      "Epoch 256/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6344 - acc: 0.7331 - val_loss: 0.6994 - val_acc: 0.6774\n",
      "Epoch 257/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.6357 - acc: 0.7274 - val_loss: 0.5974 - val_acc: 0.7290\n",
      "Epoch 258/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.6317 - acc: 0.7177 - val_loss: 0.5970 - val_acc: 0.7226\n",
      "Epoch 259/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6279 - acc: 0.7169 - val_loss: 0.6103 - val_acc: 0.7258\n",
      "Epoch 260/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6218 - acc: 0.7298 - val_loss: 0.5867 - val_acc: 0.7484\n",
      "Epoch 261/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.6314 - acc: 0.7258 - val_loss: 0.6056 - val_acc: 0.7290\n",
      "Epoch 262/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6150 - acc: 0.7387 - val_loss: 0.5991 - val_acc: 0.7355\n",
      "Epoch 263/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.6184 - acc: 0.7395 - val_loss: 0.6501 - val_acc: 0.7419\n",
      "Epoch 264/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6298 - acc: 0.7282 - val_loss: 0.5760 - val_acc: 0.7613\n",
      "Epoch 265/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6234 - acc: 0.7323 - val_loss: 0.6262 - val_acc: 0.7323\n",
      "Epoch 266/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.6189 - acc: 0.7387 - val_loss: 0.5864 - val_acc: 0.7387\n",
      "Epoch 267/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.6168 - acc: 0.7435 - val_loss: 0.6363 - val_acc: 0.7323\n",
      "Epoch 268/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.6171 - acc: 0.7363 - val_loss: 0.5912 - val_acc: 0.7419\n",
      "Epoch 269/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6163 - acc: 0.7435 - val_loss: 0.6344 - val_acc: 0.7355\n",
      "Epoch 270/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.6127 - acc: 0.7379 - val_loss: 0.5804 - val_acc: 0.7387\n",
      "Epoch 271/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6070 - acc: 0.7331 - val_loss: 0.6192 - val_acc: 0.7226\n",
      "Epoch 272/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.6182 - acc: 0.7258 - val_loss: 0.6079 - val_acc: 0.7355\n",
      "Epoch 273/1500\n",
      "1240/1240 [==============================] - 0s 263us/sample - loss: 0.6060 - acc: 0.7379 - val_loss: 0.5729 - val_acc: 0.7419\n",
      "Epoch 274/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6125 - acc: 0.7395 - val_loss: 0.5793 - val_acc: 0.7581\n",
      "Epoch 275/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.6119 - acc: 0.7444 - val_loss: 0.6040 - val_acc: 0.7452\n",
      "Epoch 276/1500\n",
      "1240/1240 [==============================] - 0s 258us/sample - loss: 0.6038 - acc: 0.7363 - val_loss: 0.6022 - val_acc: 0.7226\n",
      "Epoch 277/1500\n",
      "1240/1240 [==============================] - 0s 252us/sample - loss: 0.5942 - acc: 0.7540 - val_loss: 0.6064 - val_acc: 0.7548\n",
      "Epoch 278/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.6072 - acc: 0.7347 - val_loss: 0.5551 - val_acc: 0.7613\n",
      "Epoch 279/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.5988 - acc: 0.7444 - val_loss: 0.6233 - val_acc: 0.7355\n",
      "Epoch 280/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.5969 - acc: 0.7323 - val_loss: 0.5531 - val_acc: 0.7548\n",
      "Epoch 281/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.5958 - acc: 0.7468 - val_loss: 0.6012 - val_acc: 0.7452\n",
      "Epoch 282/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.5936 - acc: 0.7484 - val_loss: 0.5726 - val_acc: 0.7645\n",
      "Epoch 283/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.5944 - acc: 0.7331 - val_loss: 0.5938 - val_acc: 0.7226\n",
      "Epoch 284/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.5941 - acc: 0.7476 - val_loss: 0.5384 - val_acc: 0.7677\n",
      "Epoch 285/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.5905 - acc: 0.7403 - val_loss: 0.6769 - val_acc: 0.7161\n",
      "Epoch 286/1500\n",
      "1240/1240 [==============================] - 0s 252us/sample - loss: 0.5797 - acc: 0.7468 - val_loss: 0.6080 - val_acc: 0.7258\n",
      "Epoch 287/1500\n",
      "1240/1240 [==============================] - 0s 251us/sample - loss: 0.5877 - acc: 0.7460 - val_loss: 0.5472 - val_acc: 0.7548\n",
      "Epoch 288/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.5912 - acc: 0.7298 - val_loss: 0.5908 - val_acc: 0.7581\n",
      "Epoch 289/1500\n",
      "1240/1240 [==============================] - 0s 262us/sample - loss: 0.5804 - acc: 0.7508 - val_loss: 0.5540 - val_acc: 0.7677\n",
      "Epoch 290/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.5799 - acc: 0.7516 - val_loss: 0.5808 - val_acc: 0.7677\n",
      "Epoch 291/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.5901 - acc: 0.7411 - val_loss: 0.5758 - val_acc: 0.7516\n",
      "Epoch 292/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.5849 - acc: 0.7508 - val_loss: 0.5370 - val_acc: 0.7806\n",
      "Epoch 293/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.5760 - acc: 0.7540 - val_loss: 0.5387 - val_acc: 0.7806\n",
      "Epoch 294/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.5832 - acc: 0.7508 - val_loss: 0.5342 - val_acc: 0.7710\n",
      "Epoch 295/1500\n",
      "1240/1240 [==============================] - 0s 256us/sample - loss: 0.5778 - acc: 0.7524 - val_loss: 0.5561 - val_acc: 0.7806\n",
      "Epoch 296/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.5823 - acc: 0.7484 - val_loss: 0.5984 - val_acc: 0.7419\n",
      "Epoch 297/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.5748 - acc: 0.7556 - val_loss: 0.5621 - val_acc: 0.7516\n",
      "Epoch 298/1500\n",
      "1240/1240 [==============================] - 0s 257us/sample - loss: 0.5724 - acc: 0.7629 - val_loss: 0.5685 - val_acc: 0.7323\n",
      "Epoch 299/1500\n",
      "1240/1240 [==============================] - 0s 252us/sample - loss: 0.5847 - acc: 0.7492 - val_loss: 0.5288 - val_acc: 0.7839\n",
      "Epoch 300/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.5684 - acc: 0.7653 - val_loss: 0.6855 - val_acc: 0.7097\n",
      "Epoch 301/1500\n",
      "1240/1240 [==============================] - 0s 255us/sample - loss: 0.5858 - acc: 0.7548 - val_loss: 0.5635 - val_acc: 0.7516\n",
      "Epoch 302/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.5718 - acc: 0.7565 - val_loss: 0.5615 - val_acc: 0.7387\n",
      "Epoch 303/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.5785 - acc: 0.7556 - val_loss: 0.5994 - val_acc: 0.7645\n",
      "Epoch 304/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.5678 - acc: 0.7589 - val_loss: 0.5432 - val_acc: 0.7581\n",
      "Epoch 305/1500\n",
      "1240/1240 [==============================] - 0s 253us/sample - loss: 0.5585 - acc: 0.7653 - val_loss: 0.5645 - val_acc: 0.7742\n",
      "Epoch 306/1500\n",
      "1240/1240 [==============================] - 0s 262us/sample - loss: 0.5672 - acc: 0.7613 - val_loss: 0.6297 - val_acc: 0.7258\n",
      "Epoch 307/1500\n",
      "1240/1240 [==============================] - 0s 260us/sample - loss: 0.5686 - acc: 0.7508 - val_loss: 0.5623 - val_acc: 0.7677\n",
      "Epoch 308/1500\n",
      "1240/1240 [==============================] - 0s 260us/sample - loss: 0.5687 - acc: 0.7516 - val_loss: 0.5496 - val_acc: 0.7677\n",
      "Epoch 309/1500\n",
      "1240/1240 [==============================] - 0s 254us/sample - loss: 0.5663 - acc: 0.7573 - val_loss: 0.5599 - val_acc: 0.7548\n",
      "Epoch 310/1500\n",
      "1240/1240 [==============================] - 0s 335us/sample - loss: 0.5620 - acc: 0.7637 - val_loss: 0.5314 - val_acc: 0.7710\n",
      "Epoch 311/1500\n",
      "1240/1240 [==============================] - 0s 319us/sample - loss: 0.5604 - acc: 0.7694 - val_loss: 0.5265 - val_acc: 0.7677\n",
      "Epoch 312/1500\n",
      "1240/1240 [==============================] - 0s 343us/sample - loss: 0.5647 - acc: 0.7629 - val_loss: 0.5338 - val_acc: 0.7871\n",
      "Epoch 313/1500\n",
      "1240/1240 [==============================] - 0s 329us/sample - loss: 0.5705 - acc: 0.7516 - val_loss: 0.5430 - val_acc: 0.7548\n",
      "Epoch 314/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.5566 - acc: 0.7621 - val_loss: 0.5595 - val_acc: 0.7677\n",
      "Epoch 315/1500\n",
      "1240/1240 [==============================] - 0s 295us/sample - loss: 0.5505 - acc: 0.7750 - val_loss: 0.5814 - val_acc: 0.7484\n",
      "Epoch 316/1500\n",
      "1240/1240 [==============================] - 0s 356us/sample - loss: 0.5569 - acc: 0.7460 - val_loss: 0.5075 - val_acc: 0.7968\n",
      "Epoch 317/1500\n",
      "1240/1240 [==============================] - 0s 373us/sample - loss: 0.5605 - acc: 0.7597 - val_loss: 0.5442 - val_acc: 0.7516\n",
      "Epoch 318/1500\n",
      "1240/1240 [==============================] - 0s 350us/sample - loss: 0.5557 - acc: 0.7573 - val_loss: 0.5358 - val_acc: 0.7774\n",
      "Epoch 319/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 0.5520 - acc: 0.7742 - val_loss: 0.5163 - val_acc: 0.8032\n",
      "Epoch 320/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.5485 - acc: 0.7653 - val_loss: 0.5298 - val_acc: 0.7677\n",
      "Epoch 321/1500\n",
      "1240/1240 [==============================] - 0s 296us/sample - loss: 0.5518 - acc: 0.7573 - val_loss: 0.5446 - val_acc: 0.7452\n",
      "Epoch 322/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.5423 - acc: 0.7669 - val_loss: 0.4968 - val_acc: 0.7968\n",
      "Epoch 323/1500\n",
      "1240/1240 [==============================] - 0s 291us/sample - loss: 0.5491 - acc: 0.7685 - val_loss: 0.5118 - val_acc: 0.8000\n",
      "Epoch 324/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.5536 - acc: 0.7710 - val_loss: 0.5418 - val_acc: 0.7516\n",
      "Epoch 325/1500\n",
      "1240/1240 [==============================] - 0s 293us/sample - loss: 0.5414 - acc: 0.7726 - val_loss: 0.5466 - val_acc: 0.7452\n",
      "Epoch 326/1500\n",
      "1240/1240 [==============================] - 0s 339us/sample - loss: 0.5440 - acc: 0.7855 - val_loss: 0.5112 - val_acc: 0.7935\n",
      "Epoch 327/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.5463 - acc: 0.7597 - val_loss: 0.5586 - val_acc: 0.7484\n",
      "Epoch 328/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.5407 - acc: 0.7823 - val_loss: 0.5443 - val_acc: 0.7548\n",
      "Epoch 329/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.5456 - acc: 0.7677 - val_loss: 0.5716 - val_acc: 0.7516\n",
      "Epoch 330/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.5384 - acc: 0.7823 - val_loss: 0.5720 - val_acc: 0.7516\n",
      "Epoch 331/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.5334 - acc: 0.7661 - val_loss: 0.6124 - val_acc: 0.7032\n",
      "Epoch 332/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.5403 - acc: 0.7685 - val_loss: 0.5086 - val_acc: 0.7871\n",
      "Epoch 333/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.5397 - acc: 0.7661 - val_loss: 0.5077 - val_acc: 0.7903\n",
      "Epoch 334/1500\n",
      "1240/1240 [==============================] - 0s 296us/sample - loss: 0.5359 - acc: 0.7742 - val_loss: 0.5612 - val_acc: 0.7613\n",
      "Epoch 335/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.5350 - acc: 0.7653 - val_loss: 0.4921 - val_acc: 0.7903\n",
      "Epoch 336/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.5260 - acc: 0.7710 - val_loss: 0.5355 - val_acc: 0.7581\n",
      "Epoch 337/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.5425 - acc: 0.7605 - val_loss: 0.5753 - val_acc: 0.7484\n",
      "Epoch 338/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.5388 - acc: 0.7702 - val_loss: 0.5037 - val_acc: 0.7774\n",
      "Epoch 339/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.5317 - acc: 0.7694 - val_loss: 0.5415 - val_acc: 0.7677\n",
      "Epoch 340/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.5259 - acc: 0.7847 - val_loss: 0.5900 - val_acc: 0.7323\n",
      "Epoch 341/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.5282 - acc: 0.7710 - val_loss: 0.5020 - val_acc: 0.8000\n",
      "Epoch 342/1500\n",
      "1240/1240 [==============================] - 0s 293us/sample - loss: 0.5170 - acc: 0.7766 - val_loss: 0.5468 - val_acc: 0.7742\n",
      "Epoch 343/1500\n",
      "1240/1240 [==============================] - 0s 333us/sample - loss: 0.5301 - acc: 0.7734 - val_loss: 0.5004 - val_acc: 0.7774\n",
      "Epoch 344/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 0.5112 - acc: 0.7895 - val_loss: 0.5381 - val_acc: 0.7774\n",
      "Epoch 345/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.5221 - acc: 0.7790 - val_loss: 0.4810 - val_acc: 0.8000\n",
      "Epoch 346/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.5166 - acc: 0.7831 - val_loss: 0.5440 - val_acc: 0.7677\n",
      "Epoch 347/1500\n",
      "1240/1240 [==============================] - 0s 292us/sample - loss: 0.5253 - acc: 0.7653 - val_loss: 0.5447 - val_acc: 0.7806\n",
      "Epoch 348/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.5201 - acc: 0.7855 - val_loss: 0.5146 - val_acc: 0.8032\n",
      "Epoch 349/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.5219 - acc: 0.7661 - val_loss: 0.5733 - val_acc: 0.7613\n",
      "Epoch 350/1500\n",
      "1240/1240 [==============================] - 0s 293us/sample - loss: 0.5123 - acc: 0.7847 - val_loss: 0.4982 - val_acc: 0.7968\n",
      "Epoch 351/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.5131 - acc: 0.7863 - val_loss: 0.5234 - val_acc: 0.7806\n",
      "Epoch 352/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.5125 - acc: 0.7831 - val_loss: 0.5443 - val_acc: 0.7677\n",
      "Epoch 353/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.5195 - acc: 0.7855 - val_loss: 0.5075 - val_acc: 0.7742\n",
      "Epoch 354/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.5238 - acc: 0.7734 - val_loss: 0.5231 - val_acc: 0.7419\n",
      "Epoch 355/1500\n",
      "1240/1240 [==============================] - 0s 295us/sample - loss: 0.5109 - acc: 0.7823 - val_loss: 0.4884 - val_acc: 0.7710\n",
      "Epoch 356/1500\n",
      "1240/1240 [==============================] - 0s 291us/sample - loss: 0.5116 - acc: 0.7887 - val_loss: 0.4953 - val_acc: 0.7806\n",
      "Epoch 357/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.5091 - acc: 0.7839 - val_loss: 0.5541 - val_acc: 0.7323\n",
      "Epoch 358/1500\n",
      "1240/1240 [==============================] - 0s 292us/sample - loss: 0.5024 - acc: 0.7823 - val_loss: 0.5703 - val_acc: 0.7613\n",
      "Epoch 359/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.5052 - acc: 0.7879 - val_loss: 0.5418 - val_acc: 0.7484\n",
      "Epoch 360/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.5052 - acc: 0.7895 - val_loss: 0.5085 - val_acc: 0.7903\n",
      "Epoch 361/1500\n",
      "1240/1240 [==============================] - 0s 293us/sample - loss: 0.5032 - acc: 0.7863 - val_loss: 0.4557 - val_acc: 0.8065\n",
      "Epoch 362/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.5052 - acc: 0.7766 - val_loss: 0.4653 - val_acc: 0.8032\n",
      "Epoch 363/1500\n",
      "1240/1240 [==============================] - 0s 291us/sample - loss: 0.5123 - acc: 0.7806 - val_loss: 0.5115 - val_acc: 0.8065\n",
      "Epoch 364/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.5076 - acc: 0.7831 - val_loss: 0.4652 - val_acc: 0.8226\n",
      "Epoch 365/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.5087 - acc: 0.7726 - val_loss: 0.5377 - val_acc: 0.7677\n",
      "Epoch 366/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.5043 - acc: 0.7798 - val_loss: 0.4863 - val_acc: 0.7935\n",
      "Epoch 367/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.5069 - acc: 0.7855 - val_loss: 0.4770 - val_acc: 0.8000\n",
      "Epoch 368/1500\n",
      "1240/1240 [==============================] - 0s 293us/sample - loss: 0.4997 - acc: 0.7855 - val_loss: 0.4538 - val_acc: 0.8097\n",
      "Epoch 369/1500\n",
      "1240/1240 [==============================] - 0s 295us/sample - loss: 0.4994 - acc: 0.7919 - val_loss: 0.5384 - val_acc: 0.7419\n",
      "Epoch 370/1500\n",
      "1240/1240 [==============================] - 0s 300us/sample - loss: 0.5073 - acc: 0.7855 - val_loss: 0.5003 - val_acc: 0.7968\n",
      "Epoch 371/1500\n",
      "1240/1240 [==============================] - 0s 296us/sample - loss: 0.4998 - acc: 0.7903 - val_loss: 0.4971 - val_acc: 0.8097\n",
      "Epoch 372/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.4832 - acc: 0.7927 - val_loss: 0.4967 - val_acc: 0.7935\n",
      "Epoch 373/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.4993 - acc: 0.7871 - val_loss: 0.4672 - val_acc: 0.8065\n",
      "Epoch 374/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.4893 - acc: 0.7952 - val_loss: 0.5241 - val_acc: 0.7806\n",
      "Epoch 375/1500\n",
      "1240/1240 [==============================] - 0s 303us/sample - loss: 0.4933 - acc: 0.7919 - val_loss: 0.4933 - val_acc: 0.7839\n",
      "Epoch 376/1500\n",
      "1240/1240 [==============================] - 0s 299us/sample - loss: 0.4863 - acc: 0.8032 - val_loss: 0.5275 - val_acc: 0.8161\n",
      "Epoch 377/1500\n",
      "1240/1240 [==============================] - 1s 447us/sample - loss: 0.4879 - acc: 0.7887 - val_loss: 0.5160 - val_acc: 0.7452\n",
      "Epoch 378/1500\n",
      "1240/1240 [==============================] - 1s 406us/sample - loss: 0.4981 - acc: 0.7823 - val_loss: 0.4954 - val_acc: 0.8000\n",
      "Epoch 379/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.4967 - acc: 0.7831 - val_loss: 0.4746 - val_acc: 0.8000\n",
      "Epoch 380/1500\n",
      "1240/1240 [==============================] - 0s 335us/sample - loss: 0.4908 - acc: 0.7992 - val_loss: 0.4861 - val_acc: 0.8000\n",
      "Epoch 381/1500\n",
      "1240/1240 [==============================] - 0s 357us/sample - loss: 0.4818 - acc: 0.7968 - val_loss: 0.4423 - val_acc: 0.8355\n",
      "Epoch 382/1500\n",
      "1240/1240 [==============================] - 1s 425us/sample - loss: 0.4915 - acc: 0.8024 - val_loss: 0.4881 - val_acc: 0.7710\n",
      "Epoch 383/1500\n",
      "1240/1240 [==============================] - 1s 437us/sample - loss: 0.4807 - acc: 0.8040 - val_loss: 0.5090 - val_acc: 0.7710\n",
      "Epoch 384/1500\n",
      "1240/1240 [==============================] - 1s 409us/sample - loss: 0.4885 - acc: 0.7790 - val_loss: 0.4780 - val_acc: 0.7935\n",
      "Epoch 385/1500\n",
      "1240/1240 [==============================] - 1s 413us/sample - loss: 0.4725 - acc: 0.7968 - val_loss: 0.4550 - val_acc: 0.8032\n",
      "Epoch 386/1500\n",
      "1240/1240 [==============================] - 0s 395us/sample - loss: 0.4803 - acc: 0.7927 - val_loss: 0.5152 - val_acc: 0.7806\n",
      "Epoch 387/1500\n",
      "1240/1240 [==============================] - 1s 404us/sample - loss: 0.4895 - acc: 0.7992 - val_loss: 0.4445 - val_acc: 0.8387\n",
      "Epoch 388/1500\n",
      "1240/1240 [==============================] - 0s 399us/sample - loss: 0.4741 - acc: 0.8024 - val_loss: 0.5053 - val_acc: 0.7516\n",
      "Epoch 389/1500\n",
      "1240/1240 [==============================] - 0s 402us/sample - loss: 0.4665 - acc: 0.8040 - val_loss: 0.4538 - val_acc: 0.7935\n",
      "Epoch 390/1500\n",
      "1240/1240 [==============================] - 1s 405us/sample - loss: 0.4719 - acc: 0.8032 - val_loss: 0.4540 - val_acc: 0.8097\n",
      "Epoch 391/1500\n",
      "1240/1240 [==============================] - 0s 392us/sample - loss: 0.4664 - acc: 0.8185 - val_loss: 0.5201 - val_acc: 0.7613\n",
      "Epoch 392/1500\n",
      "1240/1240 [==============================] - 0s 381us/sample - loss: 0.4764 - acc: 0.7927 - val_loss: 0.4612 - val_acc: 0.7839\n",
      "Epoch 393/1500\n",
      "1240/1240 [==============================] - 0s 361us/sample - loss: 0.4831 - acc: 0.7960 - val_loss: 0.5038 - val_acc: 0.7645\n",
      "Epoch 394/1500\n",
      "1240/1240 [==============================] - 0s 353us/sample - loss: 0.4766 - acc: 0.7976 - val_loss: 0.4713 - val_acc: 0.8226\n",
      "Epoch 395/1500\n",
      "1240/1240 [==============================] - 0s 361us/sample - loss: 0.4728 - acc: 0.8056 - val_loss: 0.4561 - val_acc: 0.8129\n",
      "Epoch 396/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.4668 - acc: 0.7944 - val_loss: 0.5237 - val_acc: 0.7710\n",
      "Epoch 397/1500\n",
      "1240/1240 [==============================] - 0s 296us/sample - loss: 0.4693 - acc: 0.8089 - val_loss: 0.4950 - val_acc: 0.7645\n",
      "Epoch 398/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.4709 - acc: 0.7935 - val_loss: 0.4649 - val_acc: 0.7935\n",
      "Epoch 399/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.4665 - acc: 0.8129 - val_loss: 0.4472 - val_acc: 0.8065\n",
      "Epoch 400/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.4706 - acc: 0.8000 - val_loss: 0.4354 - val_acc: 0.8290\n",
      "Epoch 401/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.4740 - acc: 0.7976 - val_loss: 0.4394 - val_acc: 0.8290\n",
      "Epoch 402/1500\n",
      "1240/1240 [==============================] - 0s 267us/sample - loss: 0.4653 - acc: 0.7992 - val_loss: 0.5168 - val_acc: 0.7871\n",
      "Epoch 403/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.4705 - acc: 0.7960 - val_loss: 0.4944 - val_acc: 0.7968\n",
      "Epoch 404/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.4604 - acc: 0.8129 - val_loss: 0.4237 - val_acc: 0.8355\n",
      "Epoch 405/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4637 - acc: 0.8129 - val_loss: 0.4887 - val_acc: 0.7677\n",
      "Epoch 406/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.4714 - acc: 0.7927 - val_loss: 0.4874 - val_acc: 0.7935\n",
      "Epoch 407/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.4649 - acc: 0.8016 - val_loss: 0.4732 - val_acc: 0.7903\n",
      "Epoch 408/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.4514 - acc: 0.8185 - val_loss: 0.5063 - val_acc: 0.7903\n",
      "Epoch 409/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.4603 - acc: 0.8081 - val_loss: 0.4146 - val_acc: 0.8323\n",
      "Epoch 410/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4624 - acc: 0.7984 - val_loss: 0.4589 - val_acc: 0.8290\n",
      "Epoch 411/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.4579 - acc: 0.8056 - val_loss: 0.4817 - val_acc: 0.7968\n",
      "Epoch 412/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4417 - acc: 0.8145 - val_loss: 0.5019 - val_acc: 0.8032\n",
      "Epoch 413/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.4561 - acc: 0.7992 - val_loss: 0.5416 - val_acc: 0.7710\n",
      "Epoch 414/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.4634 - acc: 0.8040 - val_loss: 0.4810 - val_acc: 0.7903\n",
      "Epoch 415/1500\n",
      "1240/1240 [==============================] - 0s 297us/sample - loss: 0.4525 - acc: 0.8113 - val_loss: 0.4604 - val_acc: 0.7935\n",
      "Epoch 416/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.4545 - acc: 0.8024 - val_loss: 0.5139 - val_acc: 0.7774\n",
      "Epoch 417/1500\n",
      "1240/1240 [==============================] - 0s 337us/sample - loss: 0.4555 - acc: 0.8129 - val_loss: 0.4465 - val_acc: 0.8097\n",
      "Epoch 418/1500\n",
      "1240/1240 [==============================] - 0s 353us/sample - loss: 0.4525 - acc: 0.8105 - val_loss: 0.4589 - val_acc: 0.7935\n",
      "Epoch 419/1500\n",
      "1240/1240 [==============================] - 0s 347us/sample - loss: 0.4539 - acc: 0.8056 - val_loss: 0.4328 - val_acc: 0.8194\n",
      "Epoch 420/1500\n",
      "1240/1240 [==============================] - 0s 388us/sample - loss: 0.4475 - acc: 0.8089 - val_loss: 0.4742 - val_acc: 0.7968\n",
      "Epoch 421/1500\n",
      "1240/1240 [==============================] - 0s 381us/sample - loss: 0.4341 - acc: 0.8226 - val_loss: 0.4971 - val_acc: 0.7903\n",
      "Epoch 422/1500\n",
      "1240/1240 [==============================] - 0s 401us/sample - loss: 0.4506 - acc: 0.8105 - val_loss: 0.5428 - val_acc: 0.7839\n",
      "Epoch 423/1500\n",
      "1240/1240 [==============================] - 0s 342us/sample - loss: 0.4597 - acc: 0.8073 - val_loss: 0.4428 - val_acc: 0.8290\n",
      "Epoch 424/1500\n",
      "1240/1240 [==============================] - 0s 370us/sample - loss: 0.4476 - acc: 0.8161 - val_loss: 0.5355 - val_acc: 0.7581\n",
      "Epoch 425/1500\n",
      "1240/1240 [==============================] - 0s 371us/sample - loss: 0.4444 - acc: 0.8234 - val_loss: 0.4904 - val_acc: 0.7548\n",
      "Epoch 426/1500\n",
      "1240/1240 [==============================] - 0s 372us/sample - loss: 0.4503 - acc: 0.8089 - val_loss: 0.4134 - val_acc: 0.8452\n",
      "Epoch 427/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.4416 - acc: 0.8298 - val_loss: 0.4939 - val_acc: 0.7452\n",
      "Epoch 428/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.4406 - acc: 0.8145 - val_loss: 0.4293 - val_acc: 0.8290\n",
      "Epoch 429/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.4420 - acc: 0.8065 - val_loss: 0.4183 - val_acc: 0.8387\n",
      "Epoch 430/1500\n",
      "1240/1240 [==============================] - 0s 384us/sample - loss: 0.4414 - acc: 0.8306 - val_loss: 0.4352 - val_acc: 0.8290\n",
      "Epoch 431/1500\n",
      "1240/1240 [==============================] - 0s 297us/sample - loss: 0.4326 - acc: 0.8266 - val_loss: 0.4754 - val_acc: 0.8097\n",
      "Epoch 432/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.4408 - acc: 0.8177 - val_loss: 0.4052 - val_acc: 0.8226\n",
      "Epoch 433/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.4444 - acc: 0.8210 - val_loss: 0.4510 - val_acc: 0.8161\n",
      "Epoch 434/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.4360 - acc: 0.8097 - val_loss: 0.4383 - val_acc: 0.7935\n",
      "Epoch 435/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.4386 - acc: 0.8169 - val_loss: 0.4709 - val_acc: 0.7903\n",
      "Epoch 436/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.4344 - acc: 0.8145 - val_loss: 0.5626 - val_acc: 0.7516\n",
      "Epoch 437/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.4413 - acc: 0.8161 - val_loss: 0.4381 - val_acc: 0.8194\n",
      "Epoch 438/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.4325 - acc: 0.8194 - val_loss: 0.5034 - val_acc: 0.7710\n",
      "Epoch 439/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.4362 - acc: 0.8266 - val_loss: 0.5353 - val_acc: 0.7710\n",
      "Epoch 440/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.4375 - acc: 0.8226 - val_loss: 0.4302 - val_acc: 0.8226\n",
      "Epoch 441/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.4394 - acc: 0.8097 - val_loss: 0.4128 - val_acc: 0.8355\n",
      "Epoch 442/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4297 - acc: 0.8258 - val_loss: 0.4472 - val_acc: 0.7935\n",
      "Epoch 443/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.4313 - acc: 0.8097 - val_loss: 0.4837 - val_acc: 0.7710\n",
      "Epoch 444/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4314 - acc: 0.8226 - val_loss: 0.4460 - val_acc: 0.8129\n",
      "Epoch 445/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.4260 - acc: 0.8242 - val_loss: 0.4337 - val_acc: 0.8129\n",
      "Epoch 446/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.4284 - acc: 0.8339 - val_loss: 0.5214 - val_acc: 0.7452\n",
      "Epoch 447/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.4307 - acc: 0.8298 - val_loss: 0.4313 - val_acc: 0.8226\n",
      "Epoch 448/1500\n",
      "1240/1240 [==============================] - 0s 293us/sample - loss: 0.4249 - acc: 0.8250 - val_loss: 0.4886 - val_acc: 0.8194\n",
      "Epoch 449/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.4296 - acc: 0.8218 - val_loss: 0.4103 - val_acc: 0.8355\n",
      "Epoch 450/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.4310 - acc: 0.8298 - val_loss: 0.4057 - val_acc: 0.8129\n",
      "Epoch 451/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4271 - acc: 0.8258 - val_loss: 0.4246 - val_acc: 0.8323\n",
      "Epoch 452/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.4213 - acc: 0.8323 - val_loss: 0.4235 - val_acc: 0.8355\n",
      "Epoch 453/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.4312 - acc: 0.8218 - val_loss: 0.4391 - val_acc: 0.8226\n",
      "Epoch 454/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.4175 - acc: 0.8274 - val_loss: 0.4268 - val_acc: 0.8194\n",
      "Epoch 455/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.4248 - acc: 0.8315 - val_loss: 0.4520 - val_acc: 0.8226\n",
      "Epoch 456/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.4228 - acc: 0.8258 - val_loss: 0.4261 - val_acc: 0.8258\n",
      "Epoch 457/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.4198 - acc: 0.8218 - val_loss: 0.4361 - val_acc: 0.8516\n",
      "Epoch 458/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.4191 - acc: 0.8298 - val_loss: 0.4336 - val_acc: 0.8194\n",
      "Epoch 459/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.4172 - acc: 0.8282 - val_loss: 0.4572 - val_acc: 0.7871\n",
      "Epoch 460/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.4161 - acc: 0.8145 - val_loss: 0.3942 - val_acc: 0.8452\n",
      "Epoch 461/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.4230 - acc: 0.8226 - val_loss: 0.4239 - val_acc: 0.8290\n",
      "Epoch 462/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.4085 - acc: 0.8298 - val_loss: 0.4384 - val_acc: 0.8226\n",
      "Epoch 463/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.4169 - acc: 0.8202 - val_loss: 0.4003 - val_acc: 0.8355\n",
      "Epoch 464/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.4186 - acc: 0.8298 - val_loss: 0.4513 - val_acc: 0.7935\n",
      "Epoch 465/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.4145 - acc: 0.8347 - val_loss: 0.4541 - val_acc: 0.7903\n",
      "Epoch 466/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4099 - acc: 0.8460 - val_loss: 0.4235 - val_acc: 0.8290\n",
      "Epoch 467/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.4103 - acc: 0.8290 - val_loss: 0.3881 - val_acc: 0.8581\n",
      "Epoch 468/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.4072 - acc: 0.8371 - val_loss: 0.4495 - val_acc: 0.8226\n",
      "Epoch 469/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.4158 - acc: 0.8306 - val_loss: 0.4325 - val_acc: 0.8129\n",
      "Epoch 470/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.4019 - acc: 0.8484 - val_loss: 0.4011 - val_acc: 0.8226\n",
      "Epoch 471/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4078 - acc: 0.8355 - val_loss: 0.3805 - val_acc: 0.8355\n",
      "Epoch 472/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.4013 - acc: 0.8452 - val_loss: 0.3787 - val_acc: 0.8645\n",
      "Epoch 473/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.4065 - acc: 0.8306 - val_loss: 0.3972 - val_acc: 0.8323\n",
      "Epoch 474/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4052 - acc: 0.8427 - val_loss: 0.4247 - val_acc: 0.8258\n",
      "Epoch 475/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.4005 - acc: 0.8419 - val_loss: 0.4717 - val_acc: 0.8097\n",
      "Epoch 476/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4095 - acc: 0.8476 - val_loss: 0.4481 - val_acc: 0.7968\n",
      "Epoch 477/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.4158 - acc: 0.8274 - val_loss: 0.4232 - val_acc: 0.8226\n",
      "Epoch 478/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3878 - acc: 0.8516 - val_loss: 0.5104 - val_acc: 0.7645\n",
      "Epoch 479/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.3967 - acc: 0.8581 - val_loss: 0.4097 - val_acc: 0.8516\n",
      "Epoch 480/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4089 - acc: 0.8306 - val_loss: 0.4212 - val_acc: 0.8161\n",
      "Epoch 481/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3970 - acc: 0.8411 - val_loss: 0.3818 - val_acc: 0.8452\n",
      "Epoch 482/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.4012 - acc: 0.8419 - val_loss: 0.4021 - val_acc: 0.8323\n",
      "Epoch 483/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4037 - acc: 0.8379 - val_loss: 0.4034 - val_acc: 0.8290\n",
      "Epoch 484/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.4044 - acc: 0.8234 - val_loss: 0.4485 - val_acc: 0.8161\n",
      "Epoch 485/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.4004 - acc: 0.8379 - val_loss: 0.4274 - val_acc: 0.7903\n",
      "Epoch 486/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3898 - acc: 0.8484 - val_loss: 0.3564 - val_acc: 0.8645\n",
      "Epoch 487/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.4091 - acc: 0.8347 - val_loss: 0.3840 - val_acc: 0.8387\n",
      "Epoch 488/1500\n",
      "1240/1240 [==============================] - 0s 263us/sample - loss: 0.3907 - acc: 0.8306 - val_loss: 0.3700 - val_acc: 0.8516\n",
      "Epoch 489/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.3840 - acc: 0.8669 - val_loss: 0.4489 - val_acc: 0.8065\n",
      "Epoch 490/1500\n",
      "1240/1240 [==============================] - 0s 266us/sample - loss: 0.3991 - acc: 0.8419 - val_loss: 0.4003 - val_acc: 0.8452\n",
      "Epoch 491/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.3905 - acc: 0.8435 - val_loss: 0.3923 - val_acc: 0.8516\n",
      "Epoch 492/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3938 - acc: 0.8532 - val_loss: 0.4206 - val_acc: 0.8226\n",
      "Epoch 493/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.3996 - acc: 0.8411 - val_loss: 0.3743 - val_acc: 0.8548\n",
      "Epoch 494/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3897 - acc: 0.8444 - val_loss: 0.4123 - val_acc: 0.8226\n",
      "Epoch 495/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3877 - acc: 0.8532 - val_loss: 0.4056 - val_acc: 0.8387\n",
      "Epoch 496/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3901 - acc: 0.8460 - val_loss: 0.3666 - val_acc: 0.8484\n",
      "Epoch 497/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.3815 - acc: 0.8548 - val_loss: 0.3553 - val_acc: 0.8774\n",
      "Epoch 498/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.3961 - acc: 0.8492 - val_loss: 0.4218 - val_acc: 0.8419\n",
      "Epoch 499/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3992 - acc: 0.8387 - val_loss: 0.4802 - val_acc: 0.8194\n",
      "Epoch 500/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.3911 - acc: 0.8468 - val_loss: 0.4972 - val_acc: 0.8129\n",
      "Epoch 501/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3855 - acc: 0.8460 - val_loss: 0.3840 - val_acc: 0.8484\n",
      "Epoch 502/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.3881 - acc: 0.8540 - val_loss: 0.4520 - val_acc: 0.7839\n",
      "Epoch 503/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.3913 - acc: 0.8435 - val_loss: 0.3794 - val_acc: 0.8516\n",
      "Epoch 504/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.3820 - acc: 0.8395 - val_loss: 0.3934 - val_acc: 0.8323\n",
      "Epoch 505/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.3836 - acc: 0.8444 - val_loss: 0.3745 - val_acc: 0.8484\n",
      "Epoch 506/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3790 - acc: 0.8468 - val_loss: 0.4695 - val_acc: 0.7935\n",
      "Epoch 507/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.3810 - acc: 0.8532 - val_loss: 0.4335 - val_acc: 0.8258\n",
      "Epoch 508/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3824 - acc: 0.8516 - val_loss: 0.3829 - val_acc: 0.8355\n",
      "Epoch 509/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 0.3794 - acc: 0.8460 - val_loss: 0.3852 - val_acc: 0.8290\n",
      "Epoch 510/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.3780 - acc: 0.8452 - val_loss: 0.4405 - val_acc: 0.7677\n",
      "Epoch 511/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3970 - acc: 0.8395 - val_loss: 0.3815 - val_acc: 0.8548\n",
      "Epoch 512/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.3734 - acc: 0.8565 - val_loss: 0.3926 - val_acc: 0.8323\n",
      "Epoch 513/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3718 - acc: 0.8540 - val_loss: 0.3772 - val_acc: 0.8419\n",
      "Epoch 514/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.3818 - acc: 0.8500 - val_loss: 0.4063 - val_acc: 0.8097\n",
      "Epoch 515/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3787 - acc: 0.8500 - val_loss: 0.3832 - val_acc: 0.8226\n",
      "Epoch 516/1500\n",
      "1240/1240 [==============================] - 0s 303us/sample - loss: 0.3703 - acc: 0.8589 - val_loss: 0.3701 - val_acc: 0.8419\n",
      "Epoch 517/1500\n",
      "1240/1240 [==============================] - 0s 368us/sample - loss: 0.3717 - acc: 0.8613 - val_loss: 0.4375 - val_acc: 0.8194\n",
      "Epoch 518/1500\n",
      "1240/1240 [==============================] - 0s 368us/sample - loss: 0.3736 - acc: 0.8637 - val_loss: 0.3732 - val_acc: 0.8516\n",
      "Epoch 519/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3740 - acc: 0.8435 - val_loss: 0.3941 - val_acc: 0.8387\n",
      "Epoch 520/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3697 - acc: 0.8500 - val_loss: 0.4295 - val_acc: 0.8258\n",
      "Epoch 521/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3735 - acc: 0.8484 - val_loss: 0.4439 - val_acc: 0.8065\n",
      "Epoch 522/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3762 - acc: 0.8516 - val_loss: 0.4968 - val_acc: 0.7968\n",
      "Epoch 523/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3705 - acc: 0.8589 - val_loss: 0.3843 - val_acc: 0.8290\n",
      "Epoch 524/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3799 - acc: 0.8419 - val_loss: 0.3853 - val_acc: 0.8613\n",
      "Epoch 525/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.3635 - acc: 0.8613 - val_loss: 0.4021 - val_acc: 0.8129\n",
      "Epoch 526/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.3673 - acc: 0.8492 - val_loss: 0.4074 - val_acc: 0.8323\n",
      "Epoch 527/1500\n",
      "1240/1240 [==============================] - 0s 291us/sample - loss: 0.3755 - acc: 0.8484 - val_loss: 0.3879 - val_acc: 0.8387\n",
      "Epoch 528/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.3739 - acc: 0.8484 - val_loss: 0.4371 - val_acc: 0.8194\n",
      "Epoch 529/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3633 - acc: 0.8605 - val_loss: 0.4334 - val_acc: 0.8161\n",
      "Epoch 530/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.3749 - acc: 0.8347 - val_loss: 0.3554 - val_acc: 0.8645\n",
      "Epoch 531/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3606 - acc: 0.8605 - val_loss: 0.3805 - val_acc: 0.8548\n",
      "Epoch 532/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.3640 - acc: 0.8621 - val_loss: 0.3959 - val_acc: 0.8258\n",
      "Epoch 533/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.3669 - acc: 0.8500 - val_loss: 0.3368 - val_acc: 0.8806\n",
      "Epoch 534/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.3636 - acc: 0.8645 - val_loss: 0.4029 - val_acc: 0.8032\n",
      "Epoch 535/1500\n",
      "1240/1240 [==============================] - 0s 300us/sample - loss: 0.3634 - acc: 0.8573 - val_loss: 0.3943 - val_acc: 0.8323\n",
      "Epoch 536/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.3720 - acc: 0.8573 - val_loss: 0.3445 - val_acc: 0.8774\n",
      "Epoch 537/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.3608 - acc: 0.8581 - val_loss: 0.3941 - val_acc: 0.8452\n",
      "Epoch 538/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3599 - acc: 0.8556 - val_loss: 0.3938 - val_acc: 0.8613\n",
      "Epoch 539/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 0.3611 - acc: 0.8597 - val_loss: 0.4342 - val_acc: 0.8258\n",
      "Epoch 540/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.3623 - acc: 0.8573 - val_loss: 0.4502 - val_acc: 0.7806\n",
      "Epoch 541/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3655 - acc: 0.8508 - val_loss: 0.4069 - val_acc: 0.8161\n",
      "Epoch 542/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3663 - acc: 0.8516 - val_loss: 0.4200 - val_acc: 0.8387\n",
      "Epoch 543/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3564 - acc: 0.8508 - val_loss: 0.3750 - val_acc: 0.8387\n",
      "Epoch 544/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.3538 - acc: 0.8677 - val_loss: 0.3470 - val_acc: 0.8871\n",
      "Epoch 545/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3445 - acc: 0.8734 - val_loss: 0.4560 - val_acc: 0.8000\n",
      "Epoch 546/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3596 - acc: 0.8702 - val_loss: 0.4069 - val_acc: 0.8065\n",
      "Epoch 547/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3560 - acc: 0.8629 - val_loss: 0.3814 - val_acc: 0.8484\n",
      "Epoch 548/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3550 - acc: 0.8629 - val_loss: 0.4079 - val_acc: 0.8226\n",
      "Epoch 549/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.3628 - acc: 0.8589 - val_loss: 0.4037 - val_acc: 0.8226\n",
      "Epoch 550/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3540 - acc: 0.8694 - val_loss: 0.3839 - val_acc: 0.8581\n",
      "Epoch 551/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.3514 - acc: 0.8677 - val_loss: 0.3499 - val_acc: 0.8710\n",
      "Epoch 552/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3454 - acc: 0.8710 - val_loss: 0.4176 - val_acc: 0.8419\n",
      "Epoch 553/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3553 - acc: 0.8516 - val_loss: 0.3767 - val_acc: 0.8387\n",
      "Epoch 554/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.3493 - acc: 0.8661 - val_loss: 0.4146 - val_acc: 0.8548\n",
      "Epoch 555/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3542 - acc: 0.8629 - val_loss: 0.3316 - val_acc: 0.8645\n",
      "Epoch 556/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3605 - acc: 0.8556 - val_loss: 0.4970 - val_acc: 0.7903\n",
      "Epoch 557/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.3609 - acc: 0.8573 - val_loss: 0.4624 - val_acc: 0.7806\n",
      "Epoch 558/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.3526 - acc: 0.8653 - val_loss: 0.3809 - val_acc: 0.8484\n",
      "Epoch 559/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.3521 - acc: 0.8661 - val_loss: 0.3732 - val_acc: 0.8387\n",
      "Epoch 560/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.3504 - acc: 0.8661 - val_loss: 0.4357 - val_acc: 0.8323\n",
      "Epoch 561/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3432 - acc: 0.8694 - val_loss: 0.3929 - val_acc: 0.8194\n",
      "Epoch 562/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.3369 - acc: 0.8653 - val_loss: 0.3983 - val_acc: 0.8581\n",
      "Epoch 563/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.3481 - acc: 0.8605 - val_loss: 0.4290 - val_acc: 0.8355\n",
      "Epoch 564/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.3418 - acc: 0.8621 - val_loss: 0.4207 - val_acc: 0.8452\n",
      "Epoch 565/1500\n",
      "1240/1240 [==============================] - 0s 317us/sample - loss: 0.3565 - acc: 0.8613 - val_loss: 0.3423 - val_acc: 0.8710\n",
      "Epoch 566/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.3502 - acc: 0.8589 - val_loss: 0.3765 - val_acc: 0.8581\n",
      "Epoch 567/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.3368 - acc: 0.8669 - val_loss: 0.3672 - val_acc: 0.8613\n",
      "Epoch 568/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.3497 - acc: 0.8685 - val_loss: 0.4048 - val_acc: 0.8290\n",
      "Epoch 569/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.3416 - acc: 0.8685 - val_loss: 0.3677 - val_acc: 0.8548\n",
      "Epoch 570/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3384 - acc: 0.8790 - val_loss: 0.3935 - val_acc: 0.8290\n",
      "Epoch 571/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3423 - acc: 0.8669 - val_loss: 0.3527 - val_acc: 0.8484\n",
      "Epoch 572/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.3370 - acc: 0.8774 - val_loss: 0.4110 - val_acc: 0.8097\n",
      "Epoch 573/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.3408 - acc: 0.8774 - val_loss: 0.3709 - val_acc: 0.8613\n",
      "Epoch 574/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.3505 - acc: 0.8548 - val_loss: 0.4214 - val_acc: 0.8032\n",
      "Epoch 575/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3263 - acc: 0.8798 - val_loss: 0.3969 - val_acc: 0.8258\n",
      "Epoch 576/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3423 - acc: 0.8669 - val_loss: 0.3702 - val_acc: 0.8387\n",
      "Epoch 577/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3457 - acc: 0.8613 - val_loss: 0.3293 - val_acc: 0.8871\n",
      "Epoch 578/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.3363 - acc: 0.8669 - val_loss: 0.3490 - val_acc: 0.8645\n",
      "Epoch 579/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3396 - acc: 0.8718 - val_loss: 0.3543 - val_acc: 0.8516\n",
      "Epoch 580/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.3220 - acc: 0.8742 - val_loss: 0.3695 - val_acc: 0.8452\n",
      "Epoch 581/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3433 - acc: 0.8637 - val_loss: 0.3549 - val_acc: 0.8677\n",
      "Epoch 582/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3394 - acc: 0.8750 - val_loss: 0.3445 - val_acc: 0.8548\n",
      "Epoch 583/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3331 - acc: 0.8685 - val_loss: 0.3131 - val_acc: 0.8871\n",
      "Epoch 584/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3394 - acc: 0.8677 - val_loss: 0.3193 - val_acc: 0.8903\n",
      "Epoch 585/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.3456 - acc: 0.8694 - val_loss: 0.3820 - val_acc: 0.8161\n",
      "Epoch 586/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3232 - acc: 0.8758 - val_loss: 0.3886 - val_acc: 0.8355\n",
      "Epoch 587/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.3344 - acc: 0.8685 - val_loss: 0.3624 - val_acc: 0.8516\n",
      "Epoch 588/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3313 - acc: 0.8806 - val_loss: 0.3387 - val_acc: 0.8645\n",
      "Epoch 589/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3372 - acc: 0.8726 - val_loss: 0.3411 - val_acc: 0.8613\n",
      "Epoch 590/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3374 - acc: 0.8766 - val_loss: 0.4509 - val_acc: 0.8387\n",
      "Epoch 591/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3410 - acc: 0.8629 - val_loss: 0.3793 - val_acc: 0.8516\n",
      "Epoch 592/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.3314 - acc: 0.8734 - val_loss: 0.3698 - val_acc: 0.8645\n",
      "Epoch 593/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.3200 - acc: 0.8766 - val_loss: 0.4474 - val_acc: 0.8581\n",
      "Epoch 594/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3275 - acc: 0.8702 - val_loss: 0.4076 - val_acc: 0.8613\n",
      "Epoch 595/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.3234 - acc: 0.8758 - val_loss: 0.3288 - val_acc: 0.8774\n",
      "Epoch 596/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3344 - acc: 0.8677 - val_loss: 0.3989 - val_acc: 0.8226\n",
      "Epoch 597/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3265 - acc: 0.8815 - val_loss: 0.3609 - val_acc: 0.8484\n",
      "Epoch 598/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3194 - acc: 0.8806 - val_loss: 0.3928 - val_acc: 0.8290\n",
      "Epoch 599/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.3402 - acc: 0.8605 - val_loss: 0.3343 - val_acc: 0.8742\n",
      "Epoch 600/1500\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.3258 - acc: 0.881 - 0s 273us/sample - loss: 0.3277 - acc: 0.8823 - val_loss: 0.3917 - val_acc: 0.8581\n",
      "Epoch 601/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.3263 - acc: 0.8774 - val_loss: 0.3568 - val_acc: 0.8710\n",
      "Epoch 602/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3392 - acc: 0.8669 - val_loss: 0.4892 - val_acc: 0.8129\n",
      "Epoch 603/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3202 - acc: 0.8790 - val_loss: 0.4312 - val_acc: 0.8258\n",
      "Epoch 604/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3291 - acc: 0.8718 - val_loss: 0.4360 - val_acc: 0.8258\n",
      "Epoch 605/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3106 - acc: 0.8887 - val_loss: 0.3905 - val_acc: 0.8516\n",
      "Epoch 606/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.3180 - acc: 0.8823 - val_loss: 0.4267 - val_acc: 0.8355\n",
      "Epoch 607/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3209 - acc: 0.8774 - val_loss: 0.3253 - val_acc: 0.8774\n",
      "Epoch 608/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3229 - acc: 0.8742 - val_loss: 0.3723 - val_acc: 0.8645\n",
      "Epoch 609/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3220 - acc: 0.8718 - val_loss: 0.3142 - val_acc: 0.8839\n",
      "Epoch 610/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3148 - acc: 0.8806 - val_loss: 0.3781 - val_acc: 0.8323\n",
      "Epoch 611/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3240 - acc: 0.8742 - val_loss: 0.3352 - val_acc: 0.8548\n",
      "Epoch 612/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.3171 - acc: 0.8831 - val_loss: 0.3174 - val_acc: 0.9000\n",
      "Epoch 613/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3153 - acc: 0.8742 - val_loss: 0.3649 - val_acc: 0.8419\n",
      "Epoch 614/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3140 - acc: 0.8879 - val_loss: 0.3760 - val_acc: 0.8516\n",
      "Epoch 615/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.3245 - acc: 0.8815 - val_loss: 0.3235 - val_acc: 0.8774\n",
      "Epoch 616/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3234 - acc: 0.8734 - val_loss: 0.3355 - val_acc: 0.8677\n",
      "Epoch 617/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3229 - acc: 0.8766 - val_loss: 0.3003 - val_acc: 0.8871\n",
      "Epoch 618/1500\n",
      "1240/1240 [==============================] - 0s 295us/sample - loss: 0.3201 - acc: 0.8839 - val_loss: 0.3441 - val_acc: 0.8581\n",
      "Epoch 619/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.3115 - acc: 0.8766 - val_loss: 0.3185 - val_acc: 0.8774\n",
      "Epoch 620/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3104 - acc: 0.8903 - val_loss: 0.4015 - val_acc: 0.8452\n",
      "Epoch 621/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3221 - acc: 0.8758 - val_loss: 0.3366 - val_acc: 0.8581\n",
      "Epoch 622/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3117 - acc: 0.8806 - val_loss: 0.3531 - val_acc: 0.8806\n",
      "Epoch 623/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.3139 - acc: 0.8758 - val_loss: 0.3350 - val_acc: 0.8677\n",
      "Epoch 624/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.3118 - acc: 0.8774 - val_loss: 0.3232 - val_acc: 0.8645\n",
      "Epoch 625/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.3131 - acc: 0.8774 - val_loss: 0.3614 - val_acc: 0.8516\n",
      "Epoch 626/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3106 - acc: 0.8798 - val_loss: 0.4070 - val_acc: 0.8387\n",
      "Epoch 627/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.3204 - acc: 0.8815 - val_loss: 0.3196 - val_acc: 0.8742\n",
      "Epoch 628/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3198 - acc: 0.8782 - val_loss: 0.3328 - val_acc: 0.8581\n",
      "Epoch 629/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3132 - acc: 0.8831 - val_loss: 0.3082 - val_acc: 0.8871\n",
      "Epoch 630/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.3063 - acc: 0.8847 - val_loss: 0.3946 - val_acc: 0.8419\n",
      "Epoch 631/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.3204 - acc: 0.8702 - val_loss: 0.3169 - val_acc: 0.9000\n",
      "Epoch 632/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3078 - acc: 0.8871 - val_loss: 0.2923 - val_acc: 0.8935\n",
      "Epoch 633/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.3140 - acc: 0.8742 - val_loss: 0.3085 - val_acc: 0.8806\n",
      "Epoch 634/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3025 - acc: 0.8879 - val_loss: 0.3148 - val_acc: 0.8677\n",
      "Epoch 635/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3100 - acc: 0.8863 - val_loss: 0.3153 - val_acc: 0.8903\n",
      "Epoch 636/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3088 - acc: 0.8815 - val_loss: 0.3880 - val_acc: 0.8355\n",
      "Epoch 637/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3108 - acc: 0.8766 - val_loss: 0.3487 - val_acc: 0.8806\n",
      "Epoch 638/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.2995 - acc: 0.8879 - val_loss: 0.3605 - val_acc: 0.8484\n",
      "Epoch 639/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3201 - acc: 0.8806 - val_loss: 0.3917 - val_acc: 0.8548\n",
      "Epoch 640/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.3051 - acc: 0.8806 - val_loss: 0.3781 - val_acc: 0.8613\n",
      "Epoch 641/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.3013 - acc: 0.8895 - val_loss: 0.3966 - val_acc: 0.8290\n",
      "Epoch 642/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3180 - acc: 0.8694 - val_loss: 0.3719 - val_acc: 0.8581\n",
      "Epoch 643/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2966 - acc: 0.8960 - val_loss: 0.3218 - val_acc: 0.8806\n",
      "Epoch 644/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.3073 - acc: 0.8871 - val_loss: 0.3575 - val_acc: 0.8516\n",
      "Epoch 645/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.3008 - acc: 0.8774 - val_loss: 0.3186 - val_acc: 0.8774\n",
      "Epoch 646/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.2935 - acc: 0.8952 - val_loss: 0.3352 - val_acc: 0.8677\n",
      "Epoch 647/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.3113 - acc: 0.8798 - val_loss: 0.3537 - val_acc: 0.8645\n",
      "Epoch 648/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.2928 - acc: 0.8774 - val_loss: 0.3708 - val_acc: 0.8710\n",
      "Epoch 649/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2990 - acc: 0.8782 - val_loss: 0.3100 - val_acc: 0.8871\n",
      "Epoch 650/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.3103 - acc: 0.8653 - val_loss: 0.3385 - val_acc: 0.8806\n",
      "Epoch 651/1500\n",
      "1240/1240 [==============================] - 0s 299us/sample - loss: 0.2947 - acc: 0.8863 - val_loss: 0.3252 - val_acc: 0.8806\n",
      "Epoch 652/1500\n",
      "1240/1240 [==============================] - 0s 291us/sample - loss: 0.3044 - acc: 0.8823 - val_loss: 0.3447 - val_acc: 0.8710\n",
      "Epoch 653/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.2986 - acc: 0.8911 - val_loss: 0.3040 - val_acc: 0.8871\n",
      "Epoch 654/1500\n",
      "1240/1240 [==============================] - 0s 370us/sample - loss: 0.3026 - acc: 0.8839 - val_loss: 0.3417 - val_acc: 0.8548\n",
      "Epoch 655/1500\n",
      "1240/1240 [==============================] - 0s 368us/sample - loss: 0.2978 - acc: 0.8806 - val_loss: 0.3013 - val_acc: 0.8871\n",
      "Epoch 656/1500\n",
      "1240/1240 [==============================] - 0s 370us/sample - loss: 0.2886 - acc: 0.8944 - val_loss: 0.3465 - val_acc: 0.8710\n",
      "Epoch 657/1500\n",
      "1240/1240 [==============================] - 0s 373us/sample - loss: 0.2928 - acc: 0.8903 - val_loss: 0.3458 - val_acc: 0.8516\n",
      "Epoch 658/1500\n",
      "1240/1240 [==============================] - 0s 371us/sample - loss: 0.2953 - acc: 0.8871 - val_loss: 0.3854 - val_acc: 0.8548\n",
      "Epoch 659/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.3013 - acc: 0.8798 - val_loss: 0.3300 - val_acc: 0.8742\n",
      "Epoch 660/1500\n",
      "1240/1240 [==============================] - 0s 360us/sample - loss: 0.2945 - acc: 0.8806 - val_loss: 0.3497 - val_acc: 0.8613\n",
      "Epoch 661/1500\n",
      "1240/1240 [==============================] - 0s 342us/sample - loss: 0.3033 - acc: 0.8903 - val_loss: 0.2750 - val_acc: 0.9032\n",
      "Epoch 662/1500\n",
      "1240/1240 [==============================] - 0s 295us/sample - loss: 0.2899 - acc: 0.8863 - val_loss: 0.3309 - val_acc: 0.8613\n",
      "Epoch 663/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.2929 - acc: 0.8863 - val_loss: 0.4184 - val_acc: 0.8387\n",
      "Epoch 664/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.2877 - acc: 0.8935 - val_loss: 0.3602 - val_acc: 0.8548\n",
      "Epoch 665/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.2952 - acc: 0.8879 - val_loss: 0.3018 - val_acc: 0.8968\n",
      "Epoch 666/1500\n",
      "1240/1240 [==============================] - 0s 300us/sample - loss: 0.3053 - acc: 0.8774 - val_loss: 0.3214 - val_acc: 0.8548\n",
      "Epoch 667/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.2898 - acc: 0.8847 - val_loss: 0.3785 - val_acc: 0.8581\n",
      "Epoch 668/1500\n",
      "1240/1240 [==============================] - 0s 301us/sample - loss: 0.2895 - acc: 0.8903 - val_loss: 0.3999 - val_acc: 0.8677\n",
      "Epoch 669/1500\n",
      "1240/1240 [==============================] - 0s 296us/sample - loss: 0.2839 - acc: 0.8952 - val_loss: 0.3372 - val_acc: 0.8806\n",
      "Epoch 670/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.2898 - acc: 0.8879 - val_loss: 0.2954 - val_acc: 0.8871\n",
      "Epoch 671/1500\n",
      "1240/1240 [==============================] - 0s 303us/sample - loss: 0.2960 - acc: 0.8863 - val_loss: 0.3113 - val_acc: 0.8871\n",
      "Epoch 672/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.2922 - acc: 0.8879 - val_loss: 0.3321 - val_acc: 0.8677\n",
      "Epoch 673/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.2759 - acc: 0.9000 - val_loss: 0.3348 - val_acc: 0.8742\n",
      "Epoch 674/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.3065 - acc: 0.8798 - val_loss: 0.2945 - val_acc: 0.8935\n",
      "Epoch 675/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.2767 - acc: 0.8952 - val_loss: 0.3179 - val_acc: 0.8839\n",
      "Epoch 676/1500\n",
      "1240/1240 [==============================] - 0s 292us/sample - loss: 0.2958 - acc: 0.8863 - val_loss: 0.3487 - val_acc: 0.8581\n",
      "Epoch 677/1500\n",
      "1240/1240 [==============================] - 0s 292us/sample - loss: 0.2928 - acc: 0.8919 - val_loss: 0.3787 - val_acc: 0.8516\n",
      "Epoch 678/1500\n",
      "1240/1240 [==============================] - 0s 320us/sample - loss: 0.2914 - acc: 0.8887 - val_loss: 0.2929 - val_acc: 0.8968\n",
      "Epoch 679/1500\n",
      "1240/1240 [==============================] - 0s 336us/sample - loss: 0.2823 - acc: 0.8927 - val_loss: 0.3213 - val_acc: 0.9032\n",
      "Epoch 680/1500\n",
      "1240/1240 [==============================] - 0s 341us/sample - loss: 0.2909 - acc: 0.8887 - val_loss: 0.3574 - val_acc: 0.8452\n",
      "Epoch 681/1500\n",
      "1240/1240 [==============================] - 0s 384us/sample - loss: 0.2752 - acc: 0.9089 - val_loss: 0.4127 - val_acc: 0.8387\n",
      "Epoch 682/1500\n",
      "1240/1240 [==============================] - 1s 424us/sample - loss: 0.2864 - acc: 0.8927 - val_loss: 0.3226 - val_acc: 0.8742\n",
      "Epoch 683/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.2947 - acc: 0.8847 - val_loss: 0.3247 - val_acc: 0.8806\n",
      "Epoch 684/1500\n",
      "1240/1240 [==============================] - 0s 316us/sample - loss: 0.2854 - acc: 0.8879 - val_loss: 0.2876 - val_acc: 0.9065\n",
      "Epoch 685/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.2813 - acc: 0.8984 - val_loss: 0.3625 - val_acc: 0.8613\n",
      "Epoch 686/1500\n",
      "1240/1240 [==============================] - 0s 327us/sample - loss: 0.2830 - acc: 0.8903 - val_loss: 0.3004 - val_acc: 0.8968\n",
      "Epoch 687/1500\n",
      "1240/1240 [==============================] - 0s 311us/sample - loss: 0.2906 - acc: 0.8766 - val_loss: 0.3238 - val_acc: 0.8806\n",
      "Epoch 688/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.2878 - acc: 0.8895 - val_loss: 0.2985 - val_acc: 0.9000\n",
      "Epoch 689/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.2862 - acc: 0.8927 - val_loss: 0.4595 - val_acc: 0.8323\n",
      "Epoch 690/1500\n",
      "1240/1240 [==============================] - 0s 335us/sample - loss: 0.2870 - acc: 0.8895 - val_loss: 0.3536 - val_acc: 0.8548\n",
      "Epoch 691/1500\n",
      "1240/1240 [==============================] - 0s 377us/sample - loss: 0.2695 - acc: 0.8911 - val_loss: 0.4085 - val_acc: 0.8677\n",
      "Epoch 692/1500\n",
      "1240/1240 [==============================] - 1s 417us/sample - loss: 0.2835 - acc: 0.8944 - val_loss: 0.3189 - val_acc: 0.8742\n",
      "Epoch 693/1500\n",
      "1240/1240 [==============================] - 0s 388us/sample - loss: 0.2856 - acc: 0.8927 - val_loss: 0.3173 - val_acc: 0.8806\n",
      "Epoch 694/1500\n",
      "1240/1240 [==============================] - 1s 425us/sample - loss: 0.2855 - acc: 0.8903 - val_loss: 0.3530 - val_acc: 0.8742\n",
      "Epoch 695/1500\n",
      "1240/1240 [==============================] - 1s 423us/sample - loss: 0.2811 - acc: 0.8960 - val_loss: 0.3201 - val_acc: 0.8710\n",
      "Epoch 696/1500\n",
      "1240/1240 [==============================] - 1s 419us/sample - loss: 0.2859 - acc: 0.8984 - val_loss: 0.2935 - val_acc: 0.8903\n",
      "Epoch 697/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.2752 - acc: 0.8952 - val_loss: 0.3472 - val_acc: 0.8387\n",
      "Epoch 698/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.2749 - acc: 0.8976 - val_loss: 0.3872 - val_acc: 0.8581\n",
      "Epoch 699/1500\n",
      "1240/1240 [==============================] - 0s 346us/sample - loss: 0.2744 - acc: 0.9000 - val_loss: 0.3002 - val_acc: 0.8806\n",
      "Epoch 700/1500\n",
      "1240/1240 [==============================] - 0s 303us/sample - loss: 0.2862 - acc: 0.8919 - val_loss: 0.3223 - val_acc: 0.8613\n",
      "Epoch 701/1500\n",
      "1240/1240 [==============================] - 0s 300us/sample - loss: 0.2866 - acc: 0.8895 - val_loss: 0.3368 - val_acc: 0.8677\n",
      "Epoch 702/1500\n",
      "1240/1240 [==============================] - 0s 321us/sample - loss: 0.2721 - acc: 0.8968 - val_loss: 0.2932 - val_acc: 0.8903\n",
      "Epoch 703/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.2759 - acc: 0.8952 - val_loss: 0.2816 - val_acc: 0.9032\n",
      "Epoch 704/1500\n",
      "1240/1240 [==============================] - 0s 340us/sample - loss: 0.2740 - acc: 0.8960 - val_loss: 0.2949 - val_acc: 0.8903\n",
      "Epoch 705/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2822 - acc: 0.8944 - val_loss: 0.3687 - val_acc: 0.8581\n",
      "Epoch 706/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.2757 - acc: 0.8952 - val_loss: 0.3231 - val_acc: 0.8806\n",
      "Epoch 707/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2674 - acc: 0.9008 - val_loss: 0.4724 - val_acc: 0.7935\n",
      "Epoch 708/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2796 - acc: 0.8911 - val_loss: 0.2838 - val_acc: 0.8839\n",
      "Epoch 709/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.2724 - acc: 0.9000 - val_loss: 0.3010 - val_acc: 0.8968\n",
      "Epoch 710/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2695 - acc: 0.8968 - val_loss: 0.3015 - val_acc: 0.9000\n",
      "Epoch 711/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.2690 - acc: 0.9008 - val_loss: 0.2988 - val_acc: 0.8935\n",
      "Epoch 712/1500\n",
      "1240/1240 [==============================] - 0s 326us/sample - loss: 0.2698 - acc: 0.9000 - val_loss: 0.3366 - val_acc: 0.8710\n",
      "Epoch 713/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2730 - acc: 0.8927 - val_loss: 0.3245 - val_acc: 0.8710\n",
      "Epoch 714/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2694 - acc: 0.9024 - val_loss: 0.3824 - val_acc: 0.8387\n",
      "Epoch 715/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2778 - acc: 0.8960 - val_loss: 0.3317 - val_acc: 0.8710\n",
      "Epoch 716/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2756 - acc: 0.8976 - val_loss: 0.4319 - val_acc: 0.8516\n",
      "Epoch 717/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2637 - acc: 0.9000 - val_loss: 0.3122 - val_acc: 0.8871\n",
      "Epoch 718/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2658 - acc: 0.9081 - val_loss: 0.2789 - val_acc: 0.8871\n",
      "Epoch 719/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.2789 - acc: 0.8984 - val_loss: 0.3225 - val_acc: 0.8839\n",
      "Epoch 720/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.2711 - acc: 0.8992 - val_loss: 0.3550 - val_acc: 0.8903\n",
      "Epoch 721/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2728 - acc: 0.8952 - val_loss: 0.3298 - val_acc: 0.8613\n",
      "Epoch 722/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.2723 - acc: 0.8952 - val_loss: 0.3553 - val_acc: 0.8774\n",
      "Epoch 723/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.2694 - acc: 0.9008 - val_loss: 0.2773 - val_acc: 0.9065\n",
      "Epoch 724/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2711 - acc: 0.9008 - val_loss: 0.4090 - val_acc: 0.8516\n",
      "Epoch 725/1500\n",
      "1240/1240 [==============================] - 0s 298us/sample - loss: 0.2622 - acc: 0.9000 - val_loss: 0.3188 - val_acc: 0.8839\n",
      "Epoch 726/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2674 - acc: 0.9000 - val_loss: 0.2733 - val_acc: 0.8935\n",
      "Epoch 727/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.2670 - acc: 0.8952 - val_loss: 0.3191 - val_acc: 0.8581\n",
      "Epoch 728/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.2630 - acc: 0.9024 - val_loss: 0.3271 - val_acc: 0.8710\n",
      "Epoch 729/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2626 - acc: 0.9016 - val_loss: 0.3216 - val_acc: 0.8806\n",
      "Epoch 730/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2744 - acc: 0.8911 - val_loss: 0.3862 - val_acc: 0.8742\n",
      "Epoch 731/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2695 - acc: 0.8968 - val_loss: 0.2848 - val_acc: 0.9097\n",
      "Epoch 732/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.2599 - acc: 0.9024 - val_loss: 0.3265 - val_acc: 0.8774\n",
      "Epoch 733/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2521 - acc: 0.9105 - val_loss: 0.3080 - val_acc: 0.8871\n",
      "Epoch 734/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.2775 - acc: 0.8919 - val_loss: 0.3310 - val_acc: 0.8548\n",
      "Epoch 735/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2598 - acc: 0.9000 - val_loss: 0.2727 - val_acc: 0.9065\n",
      "Epoch 736/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.2679 - acc: 0.9024 - val_loss: 0.3155 - val_acc: 0.8548\n",
      "Epoch 737/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.2666 - acc: 0.8935 - val_loss: 0.2912 - val_acc: 0.9000\n",
      "Epoch 738/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2646 - acc: 0.9000 - val_loss: 0.3234 - val_acc: 0.8903\n",
      "Epoch 739/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2649 - acc: 0.8992 - val_loss: 0.4329 - val_acc: 0.8710\n",
      "Epoch 740/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2546 - acc: 0.9081 - val_loss: 0.3504 - val_acc: 0.8710\n",
      "Epoch 741/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.2515 - acc: 0.9024 - val_loss: 0.3777 - val_acc: 0.8581\n",
      "Epoch 742/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.2547 - acc: 0.9145 - val_loss: 0.2881 - val_acc: 0.8968\n",
      "Epoch 743/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2655 - acc: 0.9032 - val_loss: 0.3061 - val_acc: 0.8677\n",
      "Epoch 744/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2533 - acc: 0.9056 - val_loss: 0.3117 - val_acc: 0.8742\n",
      "Epoch 745/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2588 - acc: 0.9081 - val_loss: 0.2980 - val_acc: 0.8871\n",
      "Epoch 746/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2560 - acc: 0.9153 - val_loss: 0.2846 - val_acc: 0.9032\n",
      "Epoch 747/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2603 - acc: 0.9000 - val_loss: 0.2966 - val_acc: 0.8839\n",
      "Epoch 748/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.2535 - acc: 0.9153 - val_loss: 0.3317 - val_acc: 0.8645\n",
      "Epoch 749/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2517 - acc: 0.9089 - val_loss: 0.3059 - val_acc: 0.8806\n",
      "Epoch 750/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.2542 - acc: 0.9177 - val_loss: 0.3153 - val_acc: 0.8935\n",
      "Epoch 751/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2501 - acc: 0.9065 - val_loss: 0.3465 - val_acc: 0.8613\n",
      "Epoch 752/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2545 - acc: 0.9097 - val_loss: 0.3562 - val_acc: 0.8742\n",
      "Epoch 753/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.2657 - acc: 0.8976 - val_loss: 0.3155 - val_acc: 0.8806\n",
      "Epoch 754/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.2563 - acc: 0.9032 - val_loss: 0.2670 - val_acc: 0.9032\n",
      "Epoch 755/1500\n",
      "1240/1240 [==============================] - 0s 268us/sample - loss: 0.2614 - acc: 0.9024 - val_loss: 0.3169 - val_acc: 0.8839\n",
      "Epoch 756/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2641 - acc: 0.8903 - val_loss: 0.2989 - val_acc: 0.8774\n",
      "Epoch 757/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2498 - acc: 0.9097 - val_loss: 0.3111 - val_acc: 0.8935\n",
      "Epoch 758/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2482 - acc: 0.9073 - val_loss: 0.3920 - val_acc: 0.8548\n",
      "Epoch 759/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2612 - acc: 0.9008 - val_loss: 0.2945 - val_acc: 0.9065\n",
      "Epoch 760/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2468 - acc: 0.9145 - val_loss: 0.2925 - val_acc: 0.8806\n",
      "Epoch 761/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2555 - acc: 0.9032 - val_loss: 0.2612 - val_acc: 0.9000\n",
      "Epoch 762/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.2547 - acc: 0.9081 - val_loss: 0.2913 - val_acc: 0.9000\n",
      "Epoch 763/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2501 - acc: 0.9000 - val_loss: 0.3152 - val_acc: 0.8968\n",
      "Epoch 764/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2482 - acc: 0.9097 - val_loss: 0.3381 - val_acc: 0.8774\n",
      "Epoch 765/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.2670 - acc: 0.9056 - val_loss: 0.3326 - val_acc: 0.8871\n",
      "Epoch 766/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2408 - acc: 0.9153 - val_loss: 0.3086 - val_acc: 0.8613\n",
      "Epoch 767/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2514 - acc: 0.9089 - val_loss: 0.2724 - val_acc: 0.9032\n",
      "Epoch 768/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.2516 - acc: 0.9032 - val_loss: 0.4092 - val_acc: 0.8581\n",
      "Epoch 769/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.2536 - acc: 0.9048 - val_loss: 0.3086 - val_acc: 0.8742\n",
      "Epoch 770/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2510 - acc: 0.9105 - val_loss: 0.3053 - val_acc: 0.8710\n",
      "Epoch 771/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.2515 - acc: 0.9129 - val_loss: 0.2980 - val_acc: 0.8871\n",
      "Epoch 772/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2442 - acc: 0.9105 - val_loss: 0.3180 - val_acc: 0.8645\n",
      "Epoch 773/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.2384 - acc: 0.9105 - val_loss: 0.2949 - val_acc: 0.8903\n",
      "Epoch 774/1500\n",
      "1240/1240 [==============================] - 0s 339us/sample - loss: 0.2517 - acc: 0.9056 - val_loss: 0.3500 - val_acc: 0.8516\n",
      "Epoch 775/1500\n",
      "1240/1240 [==============================] - 0s 368us/sample - loss: 0.2352 - acc: 0.9161 - val_loss: 0.3612 - val_acc: 0.8613\n",
      "Epoch 776/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.2412 - acc: 0.9153 - val_loss: 0.3044 - val_acc: 0.8677\n",
      "Epoch 777/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.2580 - acc: 0.9056 - val_loss: 0.2864 - val_acc: 0.9129\n",
      "Epoch 778/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.2534 - acc: 0.9048 - val_loss: 0.3197 - val_acc: 0.8645\n",
      "Epoch 779/1500\n",
      "1240/1240 [==============================] - 0s 363us/sample - loss: 0.2493 - acc: 0.9073 - val_loss: 0.2637 - val_acc: 0.9097\n",
      "Epoch 780/1500\n",
      "1240/1240 [==============================] - 0s 325us/sample - loss: 0.2496 - acc: 0.9185 - val_loss: 0.2854 - val_acc: 0.8968\n",
      "Epoch 781/1500\n",
      "1240/1240 [==============================] - 0s 360us/sample - loss: 0.2353 - acc: 0.9121 - val_loss: 0.2875 - val_acc: 0.9032\n",
      "Epoch 782/1500\n",
      "1240/1240 [==============================] - 0s 398us/sample - loss: 0.2392 - acc: 0.9177 - val_loss: 0.2664 - val_acc: 0.9226\n",
      "Epoch 783/1500\n",
      "1240/1240 [==============================] - 0s 398us/sample - loss: 0.2411 - acc: 0.9073 - val_loss: 0.2755 - val_acc: 0.9161\n",
      "Epoch 784/1500\n",
      "1240/1240 [==============================] - 0s 323us/sample - loss: 0.2462 - acc: 0.9097 - val_loss: 0.2582 - val_acc: 0.9097\n",
      "Epoch 785/1500\n",
      "1240/1240 [==============================] - 0s 348us/sample - loss: 0.2411 - acc: 0.9056 - val_loss: 0.2841 - val_acc: 0.9000\n",
      "Epoch 786/1500\n",
      "1240/1240 [==============================] - 0s 301us/sample - loss: 0.2459 - acc: 0.9089 - val_loss: 0.2865 - val_acc: 0.8968\n",
      "Epoch 787/1500\n",
      "1240/1240 [==============================] - 0s 332us/sample - loss: 0.2485 - acc: 0.8992 - val_loss: 0.3161 - val_acc: 0.8968\n",
      "Epoch 788/1500\n",
      "1240/1240 [==============================] - 0s 341us/sample - loss: 0.2390 - acc: 0.9153 - val_loss: 0.3144 - val_acc: 0.8710\n",
      "Epoch 789/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.2391 - acc: 0.9121 - val_loss: 0.4101 - val_acc: 0.8484\n",
      "Epoch 790/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.2527 - acc: 0.9000 - val_loss: 0.2716 - val_acc: 0.8968\n",
      "Epoch 791/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.2394 - acc: 0.9089 - val_loss: 0.2761 - val_acc: 0.9032\n",
      "Epoch 792/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.2305 - acc: 0.9129 - val_loss: 0.2429 - val_acc: 0.9097\n",
      "Epoch 793/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.2514 - acc: 0.9089 - val_loss: 0.2773 - val_acc: 0.8903\n",
      "Epoch 794/1500\n",
      "1240/1240 [==============================] - 0s 333us/sample - loss: 0.2391 - acc: 0.9129 - val_loss: 0.2653 - val_acc: 0.9097\n",
      "Epoch 795/1500\n",
      "1240/1240 [==============================] - 0s 341us/sample - loss: 0.2271 - acc: 0.9242 - val_loss: 0.2818 - val_acc: 0.8968\n",
      "Epoch 796/1500\n",
      "1240/1240 [==============================] - 0s 366us/sample - loss: 0.2327 - acc: 0.9161 - val_loss: 0.3411 - val_acc: 0.8613\n",
      "Epoch 797/1500\n",
      "1240/1240 [==============================] - 0s 401us/sample - loss: 0.2439 - acc: 0.9081 - val_loss: 0.3598 - val_acc: 0.8484\n",
      "Epoch 798/1500\n",
      "1240/1240 [==============================] - 0s 390us/sample - loss: 0.2408 - acc: 0.9129 - val_loss: 0.2868 - val_acc: 0.8839\n",
      "Epoch 799/1500\n",
      "1240/1240 [==============================] - 0s 400us/sample - loss: 0.2389 - acc: 0.9081 - val_loss: 0.3916 - val_acc: 0.8677\n",
      "Epoch 800/1500\n",
      "1240/1240 [==============================] - 0s 400us/sample - loss: 0.2260 - acc: 0.9226 - val_loss: 0.2961 - val_acc: 0.8871\n",
      "Epoch 801/1500\n",
      "1240/1240 [==============================] - 1s 405us/sample - loss: 0.2404 - acc: 0.9137 - val_loss: 0.3485 - val_acc: 0.8871\n",
      "Epoch 802/1500\n",
      "1240/1240 [==============================] - 1s 422us/sample - loss: 0.2367 - acc: 0.9121 - val_loss: 0.2984 - val_acc: 0.8806\n",
      "Epoch 803/1500\n",
      "1240/1240 [==============================] - 1s 436us/sample - loss: 0.2431 - acc: 0.9032 - val_loss: 0.3233 - val_acc: 0.8903\n",
      "Epoch 804/1500\n",
      "1240/1240 [==============================] - 1s 491us/sample - loss: 0.2399 - acc: 0.9081 - val_loss: 0.2593 - val_acc: 0.9194\n",
      "Epoch 805/1500\n",
      "1240/1240 [==============================] - 0s 398us/sample - loss: 0.2272 - acc: 0.9226 - val_loss: 0.2872 - val_acc: 0.9000\n",
      "Epoch 806/1500\n",
      "1240/1240 [==============================] - 0s 377us/sample - loss: 0.2448 - acc: 0.9105 - val_loss: 0.2920 - val_acc: 0.8839\n",
      "Epoch 807/1500\n",
      "1240/1240 [==============================] - 0s 350us/sample - loss: 0.2329 - acc: 0.9210 - val_loss: 0.3056 - val_acc: 0.8968\n",
      "Epoch 808/1500\n",
      "1240/1240 [==============================] - 0s 359us/sample - loss: 0.2238 - acc: 0.9194 - val_loss: 0.2444 - val_acc: 0.9032\n",
      "Epoch 809/1500\n",
      "1240/1240 [==============================] - 0s 354us/sample - loss: 0.2300 - acc: 0.9161 - val_loss: 0.2874 - val_acc: 0.8968\n",
      "Epoch 810/1500\n",
      "1240/1240 [==============================] - 0s 353us/sample - loss: 0.2433 - acc: 0.9105 - val_loss: 0.2552 - val_acc: 0.9032\n",
      "Epoch 811/1500\n",
      "1240/1240 [==============================] - 0s 334us/sample - loss: 0.2322 - acc: 0.9153 - val_loss: 0.2597 - val_acc: 0.9129\n",
      "Epoch 812/1500\n",
      "1240/1240 [==============================] - 0s 333us/sample - loss: 0.2267 - acc: 0.9185 - val_loss: 0.2731 - val_acc: 0.9032\n",
      "Epoch 813/1500\n",
      "1240/1240 [==============================] - 0s 297us/sample - loss: 0.2343 - acc: 0.9210 - val_loss: 0.2920 - val_acc: 0.8903\n",
      "Epoch 814/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.2365 - acc: 0.9121 - val_loss: 0.3352 - val_acc: 0.8677\n",
      "Epoch 815/1500\n",
      "1240/1240 [==============================] - 0s 316us/sample - loss: 0.2309 - acc: 0.9161 - val_loss: 0.2737 - val_acc: 0.8935\n",
      "Epoch 816/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.2423 - acc: 0.9097 - val_loss: 0.2694 - val_acc: 0.9032\n",
      "Epoch 817/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.2441 - acc: 0.9000 - val_loss: 0.2621 - val_acc: 0.9065\n",
      "Epoch 818/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2303 - acc: 0.9202 - val_loss: 0.2767 - val_acc: 0.9000\n",
      "Epoch 819/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2338 - acc: 0.9089 - val_loss: 0.2729 - val_acc: 0.8903\n",
      "Epoch 820/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.2306 - acc: 0.9121 - val_loss: 0.3507 - val_acc: 0.8613\n",
      "Epoch 821/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2309 - acc: 0.9234 - val_loss: 0.3698 - val_acc: 0.8452\n",
      "Epoch 822/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2217 - acc: 0.9169 - val_loss: 0.2422 - val_acc: 0.9161\n",
      "Epoch 823/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.2275 - acc: 0.9137 - val_loss: 0.3099 - val_acc: 0.8968\n",
      "Epoch 824/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.2316 - acc: 0.9153 - val_loss: 0.2657 - val_acc: 0.9129\n",
      "Epoch 825/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2285 - acc: 0.9161 - val_loss: 0.3384 - val_acc: 0.8742\n",
      "Epoch 826/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2220 - acc: 0.9169 - val_loss: 0.4024 - val_acc: 0.8774\n",
      "Epoch 827/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.2204 - acc: 0.9210 - val_loss: 0.2796 - val_acc: 0.8839\n",
      "Epoch 828/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2274 - acc: 0.9234 - val_loss: 0.2591 - val_acc: 0.9000\n",
      "Epoch 829/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2363 - acc: 0.9218 - val_loss: 0.2628 - val_acc: 0.9065\n",
      "Epoch 830/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2155 - acc: 0.9258 - val_loss: 0.3131 - val_acc: 0.8774\n",
      "Epoch 831/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.2324 - acc: 0.9153 - val_loss: 0.2467 - val_acc: 0.9000\n",
      "Epoch 832/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.2191 - acc: 0.9121 - val_loss: 0.2853 - val_acc: 0.8935\n",
      "Epoch 833/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.2241 - acc: 0.9202 - val_loss: 0.3603 - val_acc: 0.8581\n",
      "Epoch 834/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2281 - acc: 0.9177 - val_loss: 0.2720 - val_acc: 0.9000\n",
      "Epoch 835/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2304 - acc: 0.9226 - val_loss: 0.2652 - val_acc: 0.9065\n",
      "Epoch 836/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2235 - acc: 0.9194 - val_loss: 0.2832 - val_acc: 0.9194\n",
      "Epoch 837/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2241 - acc: 0.9218 - val_loss: 0.2873 - val_acc: 0.8935\n",
      "Epoch 838/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2289 - acc: 0.9145 - val_loss: 0.2515 - val_acc: 0.9194\n",
      "Epoch 839/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2283 - acc: 0.9202 - val_loss: 0.2692 - val_acc: 0.9065\n",
      "Epoch 840/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2167 - acc: 0.9161 - val_loss: 0.2755 - val_acc: 0.9065\n",
      "Epoch 841/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.2256 - acc: 0.9153 - val_loss: 0.2367 - val_acc: 0.9387\n",
      "Epoch 842/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2208 - acc: 0.9323 - val_loss: 0.2656 - val_acc: 0.9129\n",
      "Epoch 843/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.2320 - acc: 0.9153 - val_loss: 0.3196 - val_acc: 0.8935\n",
      "Epoch 844/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2225 - acc: 0.9185 - val_loss: 0.3276 - val_acc: 0.8806\n",
      "Epoch 845/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2198 - acc: 0.9218 - val_loss: 0.2438 - val_acc: 0.9161\n",
      "Epoch 846/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2216 - acc: 0.9177 - val_loss: 0.2635 - val_acc: 0.9000\n",
      "Epoch 847/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2294 - acc: 0.9169 - val_loss: 0.2737 - val_acc: 0.8935\n",
      "Epoch 848/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2185 - acc: 0.9266 - val_loss: 0.3204 - val_acc: 0.8548\n",
      "Epoch 849/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.2218 - acc: 0.9169 - val_loss: 0.2734 - val_acc: 0.9065\n",
      "Epoch 850/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2158 - acc: 0.9242 - val_loss: 0.3074 - val_acc: 0.8871\n",
      "Epoch 851/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2363 - acc: 0.9161 - val_loss: 0.2410 - val_acc: 0.9161\n",
      "Epoch 852/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2212 - acc: 0.9169 - val_loss: 0.3270 - val_acc: 0.9000\n",
      "Epoch 853/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2266 - acc: 0.9129 - val_loss: 0.3156 - val_acc: 0.8871\n",
      "Epoch 854/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2279 - acc: 0.9194 - val_loss: 0.2805 - val_acc: 0.8968\n",
      "Epoch 855/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2175 - acc: 0.9234 - val_loss: 0.2712 - val_acc: 0.9032\n",
      "Epoch 856/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2148 - acc: 0.9250 - val_loss: 0.2953 - val_acc: 0.8968\n",
      "Epoch 857/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2150 - acc: 0.9306 - val_loss: 0.3013 - val_acc: 0.9065\n",
      "Epoch 858/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2409 - acc: 0.9089 - val_loss: 0.2463 - val_acc: 0.9194\n",
      "Epoch 859/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2155 - acc: 0.9234 - val_loss: 0.3186 - val_acc: 0.8871\n",
      "Epoch 860/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.2179 - acc: 0.9185 - val_loss: 0.2688 - val_acc: 0.9097\n",
      "Epoch 861/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2169 - acc: 0.9234 - val_loss: 0.3165 - val_acc: 0.8903\n",
      "Epoch 862/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2178 - acc: 0.9234 - val_loss: 0.3335 - val_acc: 0.8613\n",
      "Epoch 863/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2136 - acc: 0.9226 - val_loss: 0.2895 - val_acc: 0.8935\n",
      "Epoch 864/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2044 - acc: 0.9250 - val_loss: 0.2670 - val_acc: 0.8903\n",
      "Epoch 865/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2164 - acc: 0.9250 - val_loss: 0.2792 - val_acc: 0.9129\n",
      "Epoch 866/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2134 - acc: 0.9274 - val_loss: 0.2765 - val_acc: 0.8871\n",
      "Epoch 867/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2121 - acc: 0.9177 - val_loss: 0.2897 - val_acc: 0.8806\n",
      "Epoch 868/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.2154 - acc: 0.9202 - val_loss: 0.2966 - val_acc: 0.9032\n",
      "Epoch 869/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2094 - acc: 0.9258 - val_loss: 0.4474 - val_acc: 0.8387\n",
      "Epoch 870/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.2134 - acc: 0.9234 - val_loss: 0.2557 - val_acc: 0.9065\n",
      "Epoch 871/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2132 - acc: 0.9258 - val_loss: 0.3200 - val_acc: 0.8645\n",
      "Epoch 872/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2189 - acc: 0.9202 - val_loss: 0.2562 - val_acc: 0.9161\n",
      "Epoch 873/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2206 - acc: 0.9210 - val_loss: 0.2478 - val_acc: 0.9032\n",
      "Epoch 874/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.2093 - acc: 0.9226 - val_loss: 0.3710 - val_acc: 0.8710\n",
      "Epoch 875/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2127 - acc: 0.9226 - val_loss: 0.2454 - val_acc: 0.9226\n",
      "Epoch 876/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.2100 - acc: 0.9161 - val_loss: 0.2607 - val_acc: 0.9000\n",
      "Epoch 877/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.2167 - acc: 0.9202 - val_loss: 0.2878 - val_acc: 0.8935\n",
      "Epoch 878/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2135 - acc: 0.9129 - val_loss: 0.3409 - val_acc: 0.8903\n",
      "Epoch 879/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2070 - acc: 0.9355 - val_loss: 0.2818 - val_acc: 0.8839\n",
      "Epoch 880/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2086 - acc: 0.9202 - val_loss: 0.2745 - val_acc: 0.9097\n",
      "Epoch 881/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.2133 - acc: 0.9290 - val_loss: 0.2814 - val_acc: 0.9000\n",
      "Epoch 882/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2026 - acc: 0.9347 - val_loss: 0.2945 - val_acc: 0.8968\n",
      "Epoch 883/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.2118 - acc: 0.9266 - val_loss: 0.2484 - val_acc: 0.9065\n",
      "Epoch 884/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2179 - acc: 0.9226 - val_loss: 0.3438 - val_acc: 0.8806\n",
      "Epoch 885/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.2065 - acc: 0.9226 - val_loss: 0.3175 - val_acc: 0.8677\n",
      "Epoch 886/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.2108 - acc: 0.9194 - val_loss: 0.2398 - val_acc: 0.8968\n",
      "Epoch 887/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2071 - acc: 0.9315 - val_loss: 0.2417 - val_acc: 0.9097\n",
      "Epoch 888/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2195 - acc: 0.9194 - val_loss: 0.2925 - val_acc: 0.8968\n",
      "Epoch 889/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2129 - acc: 0.9258 - val_loss: 0.3359 - val_acc: 0.8548\n",
      "Epoch 890/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.2049 - acc: 0.9274 - val_loss: 0.3208 - val_acc: 0.8710\n",
      "Epoch 891/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.2116 - acc: 0.9258 - val_loss: 0.3560 - val_acc: 0.8645\n",
      "Epoch 892/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.2162 - acc: 0.9185 - val_loss: 0.3165 - val_acc: 0.8903\n",
      "Epoch 893/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.2040 - acc: 0.9274 - val_loss: 0.2572 - val_acc: 0.9097\n",
      "Epoch 894/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2159 - acc: 0.9226 - val_loss: 0.3261 - val_acc: 0.8839\n",
      "Epoch 895/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.1997 - acc: 0.9282 - val_loss: 0.3072 - val_acc: 0.9000\n",
      "Epoch 896/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1981 - acc: 0.9323 - val_loss: 0.4065 - val_acc: 0.8613\n",
      "Epoch 897/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2055 - acc: 0.9202 - val_loss: 0.2868 - val_acc: 0.9032\n",
      "Epoch 898/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2064 - acc: 0.9282 - val_loss: 0.2571 - val_acc: 0.9161\n",
      "Epoch 899/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2034 - acc: 0.9274 - val_loss: 0.2776 - val_acc: 0.8903\n",
      "Epoch 900/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2127 - acc: 0.9226 - val_loss: 0.2369 - val_acc: 0.9065\n",
      "Epoch 901/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2017 - acc: 0.9363 - val_loss: 0.3062 - val_acc: 0.8871\n",
      "Epoch 902/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.2160 - acc: 0.9169 - val_loss: 0.2272 - val_acc: 0.9097\n",
      "Epoch 903/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.1958 - acc: 0.9331 - val_loss: 0.2563 - val_acc: 0.9226\n",
      "Epoch 904/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.2149 - acc: 0.9242 - val_loss: 0.2189 - val_acc: 0.9258\n",
      "Epoch 905/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2019 - acc: 0.9323 - val_loss: 0.2623 - val_acc: 0.9065\n",
      "Epoch 906/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1950 - acc: 0.9347 - val_loss: 0.2887 - val_acc: 0.8871\n",
      "Epoch 907/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.2132 - acc: 0.9290 - val_loss: 0.2455 - val_acc: 0.9065\n",
      "Epoch 908/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.2065 - acc: 0.9250 - val_loss: 0.3021 - val_acc: 0.8806\n",
      "Epoch 909/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2020 - acc: 0.9226 - val_loss: 0.4424 - val_acc: 0.8484\n",
      "Epoch 910/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1982 - acc: 0.9258 - val_loss: 0.2658 - val_acc: 0.8968\n",
      "Epoch 911/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2036 - acc: 0.9234 - val_loss: 0.2402 - val_acc: 0.9000\n",
      "Epoch 912/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.2023 - acc: 0.9242 - val_loss: 0.2182 - val_acc: 0.9290\n",
      "Epoch 913/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1944 - acc: 0.9282 - val_loss: 0.2452 - val_acc: 0.9032\n",
      "Epoch 914/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1882 - acc: 0.9306 - val_loss: 0.3188 - val_acc: 0.9000\n",
      "Epoch 915/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.2127 - acc: 0.9218 - val_loss: 0.2893 - val_acc: 0.9000\n",
      "Epoch 916/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.2078 - acc: 0.9218 - val_loss: 0.2598 - val_acc: 0.9129\n",
      "Epoch 917/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1889 - acc: 0.9347 - val_loss: 0.3578 - val_acc: 0.8645\n",
      "Epoch 918/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.2031 - acc: 0.9242 - val_loss: 0.2490 - val_acc: 0.9290\n",
      "Epoch 919/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.2007 - acc: 0.9242 - val_loss: 0.2528 - val_acc: 0.8968\n",
      "Epoch 920/1500\n",
      "1240/1240 [==============================] - 0s 267us/sample - loss: 0.2017 - acc: 0.9242 - val_loss: 0.3318 - val_acc: 0.8839\n",
      "Epoch 921/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2024 - acc: 0.9250 - val_loss: 0.2910 - val_acc: 0.9032\n",
      "Epoch 922/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1973 - acc: 0.9242 - val_loss: 0.2385 - val_acc: 0.9226\n",
      "Epoch 923/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.1993 - acc: 0.9323 - val_loss: 0.2315 - val_acc: 0.9226\n",
      "Epoch 924/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.1952 - acc: 0.9250 - val_loss: 0.2448 - val_acc: 0.9129\n",
      "Epoch 925/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.2047 - acc: 0.9266 - val_loss: 0.2276 - val_acc: 0.9226\n",
      "Epoch 926/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.2044 - acc: 0.9226 - val_loss: 0.2678 - val_acc: 0.9032\n",
      "Epoch 927/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1995 - acc: 0.9258 - val_loss: 0.2557 - val_acc: 0.8968\n",
      "Epoch 928/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1879 - acc: 0.9339 - val_loss: 0.3842 - val_acc: 0.8387\n",
      "Epoch 929/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.2051 - acc: 0.9226 - val_loss: 0.2301 - val_acc: 0.9258\n",
      "Epoch 930/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1899 - acc: 0.9282 - val_loss: 0.2858 - val_acc: 0.8968\n",
      "Epoch 931/1500\n",
      "1240/1240 [==============================] - 0s 263us/sample - loss: 0.2019 - acc: 0.9258 - val_loss: 0.2615 - val_acc: 0.9032\n",
      "Epoch 932/1500\n",
      "1240/1240 [==============================] - 0s 291us/sample - loss: 0.1956 - acc: 0.9323 - val_loss: 0.2523 - val_acc: 0.9065\n",
      "Epoch 933/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.1903 - acc: 0.9347 - val_loss: 0.3557 - val_acc: 0.8742\n",
      "Epoch 934/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.2053 - acc: 0.9145 - val_loss: 0.2301 - val_acc: 0.9258\n",
      "Epoch 935/1500\n",
      "1240/1240 [==============================] - 0s 267us/sample - loss: 0.1968 - acc: 0.9282 - val_loss: 0.2377 - val_acc: 0.9097\n",
      "Epoch 936/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1906 - acc: 0.9347 - val_loss: 0.3301 - val_acc: 0.8806\n",
      "Epoch 937/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1969 - acc: 0.9266 - val_loss: 0.2393 - val_acc: 0.9194\n",
      "Epoch 938/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1969 - acc: 0.9331 - val_loss: 0.2434 - val_acc: 0.9226\n",
      "Epoch 939/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.1892 - acc: 0.9347 - val_loss: 0.2468 - val_acc: 0.9161\n",
      "Epoch 940/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1923 - acc: 0.9419 - val_loss: 0.3500 - val_acc: 0.8677\n",
      "Epoch 941/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.1955 - acc: 0.9242 - val_loss: 0.2814 - val_acc: 0.9129\n",
      "Epoch 942/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1964 - acc: 0.9339 - val_loss: 0.2749 - val_acc: 0.9032\n",
      "Epoch 943/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1952 - acc: 0.9185 - val_loss: 0.2634 - val_acc: 0.9000\n",
      "Epoch 944/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1883 - acc: 0.9387 - val_loss: 0.2704 - val_acc: 0.9097\n",
      "Epoch 945/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2065 - acc: 0.9226 - val_loss: 0.2713 - val_acc: 0.9065\n",
      "Epoch 946/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1876 - acc: 0.9323 - val_loss: 0.2205 - val_acc: 0.9194\n",
      "Epoch 947/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1884 - acc: 0.9323 - val_loss: 0.2509 - val_acc: 0.9097\n",
      "Epoch 948/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1962 - acc: 0.9355 - val_loss: 0.2761 - val_acc: 0.9000\n",
      "Epoch 949/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1899 - acc: 0.9411 - val_loss: 0.2971 - val_acc: 0.8806\n",
      "Epoch 950/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1926 - acc: 0.9306 - val_loss: 0.2280 - val_acc: 0.9226\n",
      "Epoch 951/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1797 - acc: 0.9363 - val_loss: 0.2527 - val_acc: 0.9065\n",
      "Epoch 952/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1973 - acc: 0.9347 - val_loss: 0.2863 - val_acc: 0.9032\n",
      "Epoch 953/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.1961 - acc: 0.9282 - val_loss: 0.2346 - val_acc: 0.9097\n",
      "Epoch 954/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1912 - acc: 0.9339 - val_loss: 0.2704 - val_acc: 0.9129\n",
      "Epoch 955/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1939 - acc: 0.9306 - val_loss: 0.2456 - val_acc: 0.9032\n",
      "Epoch 956/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1878 - acc: 0.9315 - val_loss: 0.4256 - val_acc: 0.8903\n",
      "Epoch 957/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1891 - acc: 0.9282 - val_loss: 0.2365 - val_acc: 0.9161\n",
      "Epoch 958/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.1772 - acc: 0.9403 - val_loss: 0.2296 - val_acc: 0.9258\n",
      "Epoch 959/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1956 - acc: 0.9258 - val_loss: 0.3006 - val_acc: 0.8903\n",
      "Epoch 960/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1846 - acc: 0.9379 - val_loss: 0.3053 - val_acc: 0.8839\n",
      "Epoch 961/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.1826 - acc: 0.9379 - val_loss: 0.2236 - val_acc: 0.9065\n",
      "Epoch 962/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1906 - acc: 0.9339 - val_loss: 0.2246 - val_acc: 0.9226\n",
      "Epoch 963/1500\n",
      "1240/1240 [==============================] - ETA: 0s - loss: 0.1788 - acc: 0.940 - 0s 272us/sample - loss: 0.1842 - acc: 0.9363 - val_loss: 0.2565 - val_acc: 0.9097\n",
      "Epoch 964/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.1875 - acc: 0.9323 - val_loss: 0.2519 - val_acc: 0.9129\n",
      "Epoch 965/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.1871 - acc: 0.9363 - val_loss: 0.2666 - val_acc: 0.9129\n",
      "Epoch 966/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.1810 - acc: 0.9355 - val_loss: 0.2478 - val_acc: 0.9129\n",
      "Epoch 967/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.1806 - acc: 0.9379 - val_loss: 0.2513 - val_acc: 0.9226\n",
      "Epoch 968/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1860 - acc: 0.9331 - val_loss: 0.2711 - val_acc: 0.8903\n",
      "Epoch 969/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.1883 - acc: 0.9339 - val_loss: 0.2572 - val_acc: 0.9129\n",
      "Epoch 970/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1732 - acc: 0.9411 - val_loss: 0.4100 - val_acc: 0.8548\n",
      "Epoch 971/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1933 - acc: 0.9258 - val_loss: 0.3108 - val_acc: 0.8839\n",
      "Epoch 972/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.1811 - acc: 0.9347 - val_loss: 0.2510 - val_acc: 0.9097\n",
      "Epoch 973/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1910 - acc: 0.9403 - val_loss: 0.2682 - val_acc: 0.9097\n",
      "Epoch 974/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1824 - acc: 0.9379 - val_loss: 0.2302 - val_acc: 0.9226\n",
      "Epoch 975/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1805 - acc: 0.9323 - val_loss: 0.2065 - val_acc: 0.9290\n",
      "Epoch 976/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1926 - acc: 0.9298 - val_loss: 0.2158 - val_acc: 0.9129\n",
      "Epoch 977/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1830 - acc: 0.9347 - val_loss: 0.2431 - val_acc: 0.9194\n",
      "Epoch 978/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.1871 - acc: 0.9371 - val_loss: 0.2253 - val_acc: 0.9129\n",
      "Epoch 979/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1851 - acc: 0.9403 - val_loss: 0.2522 - val_acc: 0.9097\n",
      "Epoch 980/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1815 - acc: 0.9306 - val_loss: 0.2961 - val_acc: 0.8935\n",
      "Epoch 981/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.1817 - acc: 0.9379 - val_loss: 0.2624 - val_acc: 0.8871\n",
      "Epoch 982/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.2009 - acc: 0.9282 - val_loss: 0.3428 - val_acc: 0.8903\n",
      "Epoch 983/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.1796 - acc: 0.9331 - val_loss: 0.3342 - val_acc: 0.8968\n",
      "Epoch 984/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1810 - acc: 0.9363 - val_loss: 0.3134 - val_acc: 0.8645\n",
      "Epoch 985/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1801 - acc: 0.9379 - val_loss: 0.2794 - val_acc: 0.9065\n",
      "Epoch 986/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1770 - acc: 0.9460 - val_loss: 0.2547 - val_acc: 0.9000\n",
      "Epoch 987/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1851 - acc: 0.9419 - val_loss: 0.2646 - val_acc: 0.8968\n",
      "Epoch 988/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1887 - acc: 0.9306 - val_loss: 0.3659 - val_acc: 0.8742\n",
      "Epoch 989/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1846 - acc: 0.9355 - val_loss: 0.2700 - val_acc: 0.8968\n",
      "Epoch 990/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1840 - acc: 0.9323 - val_loss: 0.2340 - val_acc: 0.9194\n",
      "Epoch 991/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1781 - acc: 0.9387 - val_loss: 0.2911 - val_acc: 0.8903\n",
      "Epoch 992/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1754 - acc: 0.9339 - val_loss: 0.2721 - val_acc: 0.9129\n",
      "Epoch 993/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1747 - acc: 0.9411 - val_loss: 0.2464 - val_acc: 0.9065\n",
      "Epoch 994/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1727 - acc: 0.9387 - val_loss: 0.2275 - val_acc: 0.9129\n",
      "Epoch 995/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1878 - acc: 0.9315 - val_loss: 0.3004 - val_acc: 0.8839\n",
      "Epoch 996/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1851 - acc: 0.9323 - val_loss: 0.2183 - val_acc: 0.9387\n",
      "Epoch 997/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.1646 - acc: 0.9460 - val_loss: 0.2068 - val_acc: 0.9355\n",
      "Epoch 998/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1877 - acc: 0.9339 - val_loss: 0.2226 - val_acc: 0.9129\n",
      "Epoch 999/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.1737 - acc: 0.9387 - val_loss: 0.2612 - val_acc: 0.9032\n",
      "Epoch 1000/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.1763 - acc: 0.9419 - val_loss: 0.2531 - val_acc: 0.9065\n",
      "Epoch 1001/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1859 - acc: 0.9290 - val_loss: 0.2183 - val_acc: 0.9323\n",
      "Epoch 1002/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.1765 - acc: 0.9403 - val_loss: 0.2763 - val_acc: 0.9000\n",
      "Epoch 1003/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1758 - acc: 0.9403 - val_loss: 0.2427 - val_acc: 0.9194\n",
      "Epoch 1004/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1760 - acc: 0.9395 - val_loss: 0.3252 - val_acc: 0.8968\n",
      "Epoch 1005/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1701 - acc: 0.9468 - val_loss: 0.3021 - val_acc: 0.8935\n",
      "Epoch 1006/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1801 - acc: 0.9363 - val_loss: 0.2905 - val_acc: 0.9000\n",
      "Epoch 1007/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1819 - acc: 0.9452 - val_loss: 0.2699 - val_acc: 0.9000\n",
      "Epoch 1008/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1762 - acc: 0.9419 - val_loss: 0.2340 - val_acc: 0.9258\n",
      "Epoch 1009/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1734 - acc: 0.9444 - val_loss: 0.5054 - val_acc: 0.8484\n",
      "Epoch 1010/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.1916 - acc: 0.9282 - val_loss: 0.2463 - val_acc: 0.9000\n",
      "Epoch 1011/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1716 - acc: 0.9435 - val_loss: 0.2218 - val_acc: 0.9258\n",
      "Epoch 1012/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1689 - acc: 0.9468 - val_loss: 0.2863 - val_acc: 0.9000\n",
      "Epoch 1013/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1789 - acc: 0.9290 - val_loss: 0.3182 - val_acc: 0.8774\n",
      "Epoch 1014/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1769 - acc: 0.9363 - val_loss: 0.2585 - val_acc: 0.9129\n",
      "Epoch 1015/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1787 - acc: 0.9460 - val_loss: 0.2805 - val_acc: 0.9097\n",
      "Epoch 1016/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.1777 - acc: 0.9339 - val_loss: 0.2217 - val_acc: 0.9355\n",
      "Epoch 1017/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.1712 - acc: 0.9435 - val_loss: 0.2364 - val_acc: 0.9129\n",
      "Epoch 1018/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.1751 - acc: 0.9444 - val_loss: 0.2618 - val_acc: 0.8968\n",
      "Epoch 1019/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.1961 - acc: 0.9218 - val_loss: 0.2799 - val_acc: 0.8935\n",
      "Epoch 1020/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1678 - acc: 0.9460 - val_loss: 0.2428 - val_acc: 0.9065\n",
      "Epoch 1021/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.1802 - acc: 0.9444 - val_loss: 0.2558 - val_acc: 0.9129\n",
      "Epoch 1022/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.1754 - acc: 0.9355 - val_loss: 0.2431 - val_acc: 0.9161\n",
      "Epoch 1023/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.1684 - acc: 0.9395 - val_loss: 0.2933 - val_acc: 0.8871\n",
      "Epoch 1024/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.1638 - acc: 0.9435 - val_loss: 0.2841 - val_acc: 0.9000\n",
      "Epoch 1025/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.1903 - acc: 0.9331 - val_loss: 0.2611 - val_acc: 0.9129\n",
      "Epoch 1026/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1630 - acc: 0.9460 - val_loss: 0.2776 - val_acc: 0.9032\n",
      "Epoch 1027/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1775 - acc: 0.9339 - val_loss: 0.2136 - val_acc: 0.9194\n",
      "Epoch 1028/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.1754 - acc: 0.9379 - val_loss: 0.2626 - val_acc: 0.8935\n",
      "Epoch 1029/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1577 - acc: 0.9444 - val_loss: 0.2680 - val_acc: 0.9032\n",
      "Epoch 1030/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.1714 - acc: 0.9363 - val_loss: 0.2578 - val_acc: 0.9032\n",
      "Epoch 1031/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1714 - acc: 0.9435 - val_loss: 0.2718 - val_acc: 0.8774\n",
      "Epoch 1032/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1656 - acc: 0.9444 - val_loss: 0.2765 - val_acc: 0.9097\n",
      "Epoch 1033/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1689 - acc: 0.9419 - val_loss: 0.2451 - val_acc: 0.9097\n",
      "Epoch 1034/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.1713 - acc: 0.9427 - val_loss: 0.2325 - val_acc: 0.9194\n",
      "Epoch 1035/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1694 - acc: 0.9419 - val_loss: 0.3025 - val_acc: 0.9032\n",
      "Epoch 1036/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1885 - acc: 0.9298 - val_loss: 0.2589 - val_acc: 0.9194\n",
      "Epoch 1037/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1651 - acc: 0.9411 - val_loss: 0.2329 - val_acc: 0.9097\n",
      "Epoch 1038/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1702 - acc: 0.9379 - val_loss: 0.2920 - val_acc: 0.9000\n",
      "Epoch 1039/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1731 - acc: 0.9347 - val_loss: 0.2062 - val_acc: 0.9323\n",
      "Epoch 1040/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1610 - acc: 0.9444 - val_loss: 0.3256 - val_acc: 0.8806\n",
      "Epoch 1041/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.1648 - acc: 0.9427 - val_loss: 0.2042 - val_acc: 0.9194\n",
      "Epoch 1042/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.1630 - acc: 0.9500 - val_loss: 0.2403 - val_acc: 0.9194\n",
      "Epoch 1043/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1766 - acc: 0.9379 - val_loss: 0.2422 - val_acc: 0.9065\n",
      "Epoch 1044/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1621 - acc: 0.9419 - val_loss: 0.2426 - val_acc: 0.9290\n",
      "Epoch 1045/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.1593 - acc: 0.9411 - val_loss: 0.2691 - val_acc: 0.9065\n",
      "Epoch 1046/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.1686 - acc: 0.9355 - val_loss: 0.2362 - val_acc: 0.9194\n",
      "Epoch 1047/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1787 - acc: 0.9371 - val_loss: 0.2773 - val_acc: 0.8968\n",
      "Epoch 1048/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1789 - acc: 0.9387 - val_loss: 0.2325 - val_acc: 0.9161\n",
      "Epoch 1049/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1615 - acc: 0.9444 - val_loss: 0.2298 - val_acc: 0.9226\n",
      "Epoch 1050/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1577 - acc: 0.9460 - val_loss: 0.2421 - val_acc: 0.9226\n",
      "Epoch 1051/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1671 - acc: 0.9435 - val_loss: 0.3369 - val_acc: 0.8968\n",
      "Epoch 1052/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1540 - acc: 0.9452 - val_loss: 0.2846 - val_acc: 0.8968\n",
      "Epoch 1053/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1571 - acc: 0.9524 - val_loss: 0.2508 - val_acc: 0.9000\n",
      "Epoch 1054/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1694 - acc: 0.9379 - val_loss: 0.2368 - val_acc: 0.9194\n",
      "Epoch 1055/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1632 - acc: 0.9460 - val_loss: 0.3299 - val_acc: 0.9000\n",
      "Epoch 1056/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1721 - acc: 0.9403 - val_loss: 0.3219 - val_acc: 0.8935\n",
      "Epoch 1057/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1752 - acc: 0.9387 - val_loss: 0.3351 - val_acc: 0.8774\n",
      "Epoch 1058/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1642 - acc: 0.9492 - val_loss: 0.3135 - val_acc: 0.8903\n",
      "Epoch 1059/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1692 - acc: 0.9387 - val_loss: 0.2719 - val_acc: 0.8968\n",
      "Epoch 1060/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1624 - acc: 0.9452 - val_loss: 0.3228 - val_acc: 0.8806\n",
      "Epoch 1061/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.1639 - acc: 0.9379 - val_loss: 0.3394 - val_acc: 0.8903\n",
      "Epoch 1062/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.1727 - acc: 0.9339 - val_loss: 0.2127 - val_acc: 0.9226\n",
      "Epoch 1063/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1591 - acc: 0.9484 - val_loss: 0.3027 - val_acc: 0.9065\n",
      "Epoch 1064/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1651 - acc: 0.9411 - val_loss: 0.2527 - val_acc: 0.9097\n",
      "Epoch 1065/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.1567 - acc: 0.9524 - val_loss: 0.3228 - val_acc: 0.8677\n",
      "Epoch 1066/1500\n",
      "1240/1240 [==============================] - 0s 289us/sample - loss: 0.1792 - acc: 0.9355 - val_loss: 0.2173 - val_acc: 0.9097\n",
      "Epoch 1067/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1548 - acc: 0.9581 - val_loss: 0.3318 - val_acc: 0.8806\n",
      "Epoch 1068/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.1606 - acc: 0.9460 - val_loss: 0.2136 - val_acc: 0.9161\n",
      "Epoch 1069/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1638 - acc: 0.9371 - val_loss: 0.3041 - val_acc: 0.9000\n",
      "Epoch 1070/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1656 - acc: 0.9427 - val_loss: 0.2200 - val_acc: 0.9194\n",
      "Epoch 1071/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.1599 - acc: 0.9460 - val_loss: 0.2339 - val_acc: 0.9097\n",
      "Epoch 1072/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.1576 - acc: 0.9411 - val_loss: 0.2326 - val_acc: 0.9194\n",
      "Epoch 1073/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1642 - acc: 0.9395 - val_loss: 0.2278 - val_acc: 0.9161\n",
      "Epoch 1074/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1676 - acc: 0.9427 - val_loss: 0.2396 - val_acc: 0.9129\n",
      "Epoch 1075/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1656 - acc: 0.9460 - val_loss: 0.2647 - val_acc: 0.8968\n",
      "Epoch 1076/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1595 - acc: 0.9395 - val_loss: 0.2211 - val_acc: 0.9226\n",
      "Epoch 1077/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1669 - acc: 0.9371 - val_loss: 0.2458 - val_acc: 0.9000\n",
      "Epoch 1078/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1540 - acc: 0.9492 - val_loss: 0.3085 - val_acc: 0.9000\n",
      "Epoch 1079/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.1614 - acc: 0.9411 - val_loss: 0.2323 - val_acc: 0.9226\n",
      "Epoch 1080/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1608 - acc: 0.9435 - val_loss: 0.2825 - val_acc: 0.9032\n",
      "Epoch 1081/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1635 - acc: 0.9371 - val_loss: 0.4075 - val_acc: 0.8806\n",
      "Epoch 1082/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 0.1662 - acc: 0.9444 - val_loss: 0.2298 - val_acc: 0.9161\n",
      "Epoch 1083/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1537 - acc: 0.9468 - val_loss: 0.2122 - val_acc: 0.9258\n",
      "Epoch 1084/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1597 - acc: 0.9435 - val_loss: 0.2100 - val_acc: 0.9194\n",
      "Epoch 1085/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1587 - acc: 0.9452 - val_loss: 0.3082 - val_acc: 0.8903\n",
      "Epoch 1086/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.1532 - acc: 0.9476 - val_loss: 0.2628 - val_acc: 0.9000\n",
      "Epoch 1087/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.1666 - acc: 0.9411 - val_loss: 0.2283 - val_acc: 0.9226\n",
      "Epoch 1088/1500\n",
      "1240/1240 [==============================] - 0s 329us/sample - loss: 0.1636 - acc: 0.9387 - val_loss: 0.3052 - val_acc: 0.8710\n",
      "Epoch 1089/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1508 - acc: 0.9524 - val_loss: 0.2387 - val_acc: 0.9032\n",
      "Epoch 1090/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.1594 - acc: 0.9452 - val_loss: 0.2510 - val_acc: 0.9226\n",
      "Epoch 1091/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.1533 - acc: 0.9435 - val_loss: 0.2616 - val_acc: 0.8935\n",
      "Epoch 1092/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1545 - acc: 0.9484 - val_loss: 0.2783 - val_acc: 0.9000\n",
      "Epoch 1093/1500\n",
      "1240/1240 [==============================] - 0s 321us/sample - loss: 0.1605 - acc: 0.9444 - val_loss: 0.2323 - val_acc: 0.9194\n",
      "Epoch 1094/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1489 - acc: 0.9484 - val_loss: 0.5031 - val_acc: 0.8484\n",
      "Epoch 1095/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.1508 - acc: 0.9468 - val_loss: 0.2591 - val_acc: 0.9065\n",
      "Epoch 1096/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1492 - acc: 0.9476 - val_loss: 0.2144 - val_acc: 0.9226\n",
      "Epoch 1097/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.1613 - acc: 0.9435 - val_loss: 0.3217 - val_acc: 0.9000\n",
      "Epoch 1098/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1633 - acc: 0.9444 - val_loss: 0.2797 - val_acc: 0.8871\n",
      "Epoch 1099/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.1546 - acc: 0.9444 - val_loss: 0.4022 - val_acc: 0.8613\n",
      "Epoch 1100/1500\n",
      "1240/1240 [==============================] - 0s 296us/sample - loss: 0.1588 - acc: 0.9427 - val_loss: 0.3093 - val_acc: 0.9097\n",
      "Epoch 1101/1500\n",
      "1240/1240 [==============================] - 0s 322us/sample - loss: 0.1505 - acc: 0.9468 - val_loss: 0.2552 - val_acc: 0.9065\n",
      "Epoch 1102/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1596 - acc: 0.9460 - val_loss: 0.3286 - val_acc: 0.8806\n",
      "Epoch 1103/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1549 - acc: 0.9411 - val_loss: 0.2555 - val_acc: 0.9097\n",
      "Epoch 1104/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1608 - acc: 0.9460 - val_loss: 0.2468 - val_acc: 0.9000\n",
      "Epoch 1105/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1556 - acc: 0.9484 - val_loss: 0.2345 - val_acc: 0.9032\n",
      "Epoch 1106/1500\n",
      "1240/1240 [==============================] - 0s 316us/sample - loss: 0.1582 - acc: 0.9444 - val_loss: 0.3302 - val_acc: 0.8935\n",
      "Epoch 1107/1500\n",
      "1240/1240 [==============================] - 0s 299us/sample - loss: 0.1670 - acc: 0.9435 - val_loss: 0.3038 - val_acc: 0.9129\n",
      "Epoch 1108/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1647 - acc: 0.9484 - val_loss: 0.2250 - val_acc: 0.9194\n",
      "Epoch 1109/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.1484 - acc: 0.9516 - val_loss: 0.2389 - val_acc: 0.9129\n",
      "Epoch 1110/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.1611 - acc: 0.9427 - val_loss: 0.3285 - val_acc: 0.8839\n",
      "Epoch 1111/1500\n",
      "1240/1240 [==============================] - 0s 311us/sample - loss: 0.1470 - acc: 0.9492 - val_loss: 0.2142 - val_acc: 0.9226\n",
      "Epoch 1112/1500\n",
      "1240/1240 [==============================] - 0s 317us/sample - loss: 0.1479 - acc: 0.9500 - val_loss: 0.2233 - val_acc: 0.9226\n",
      "Epoch 1113/1500\n",
      "1240/1240 [==============================] - 0s 324us/sample - loss: 0.1596 - acc: 0.9460 - val_loss: 0.2790 - val_acc: 0.9000\n",
      "Epoch 1114/1500\n",
      "1240/1240 [==============================] - 0s 364us/sample - loss: 0.1593 - acc: 0.9403 - val_loss: 0.3381 - val_acc: 0.8774\n",
      "Epoch 1115/1500\n",
      "1240/1240 [==============================] - 0s 337us/sample - loss: 0.1534 - acc: 0.9452 - val_loss: 0.2941 - val_acc: 0.8903\n",
      "Epoch 1116/1500\n",
      "1240/1240 [==============================] - 0s 355us/sample - loss: 0.1484 - acc: 0.9500 - val_loss: 0.2645 - val_acc: 0.9129\n",
      "Epoch 1117/1500\n",
      "1240/1240 [==============================] - 0s 342us/sample - loss: 0.1627 - acc: 0.9435 - val_loss: 0.2680 - val_acc: 0.9032\n",
      "Epoch 1118/1500\n",
      "1240/1240 [==============================] - 0s 335us/sample - loss: 0.1531 - acc: 0.9492 - val_loss: 0.2096 - val_acc: 0.9258\n",
      "Epoch 1119/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1499 - acc: 0.9508 - val_loss: 0.2678 - val_acc: 0.9032\n",
      "Epoch 1120/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1578 - acc: 0.9484 - val_loss: 0.2831 - val_acc: 0.9065\n",
      "Epoch 1121/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1569 - acc: 0.9444 - val_loss: 0.2921 - val_acc: 0.8871\n",
      "Epoch 1122/1500\n",
      "1240/1240 [==============================] - 0s 355us/sample - loss: 0.1537 - acc: 0.9516 - val_loss: 0.2641 - val_acc: 0.9032\n",
      "Epoch 1123/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.1537 - acc: 0.9476 - val_loss: 0.2800 - val_acc: 0.9097\n",
      "Epoch 1124/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1516 - acc: 0.9484 - val_loss: 0.2606 - val_acc: 0.9258\n",
      "Epoch 1125/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1512 - acc: 0.9452 - val_loss: 0.2378 - val_acc: 0.9161\n",
      "Epoch 1126/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1672 - acc: 0.9444 - val_loss: 0.2243 - val_acc: 0.9226\n",
      "Epoch 1127/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1482 - acc: 0.9460 - val_loss: 0.2006 - val_acc: 0.9355\n",
      "Epoch 1128/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1531 - acc: 0.9500 - val_loss: 0.2421 - val_acc: 0.9161\n",
      "Epoch 1129/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1535 - acc: 0.9500 - val_loss: 0.2456 - val_acc: 0.9161\n",
      "Epoch 1130/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1487 - acc: 0.9500 - val_loss: 0.3341 - val_acc: 0.9129\n",
      "Epoch 1131/1500\n",
      "1240/1240 [==============================] - 0s 325us/sample - loss: 0.1586 - acc: 0.9468 - val_loss: 0.2244 - val_acc: 0.9226\n",
      "Epoch 1132/1500\n",
      "1240/1240 [==============================] - 0s 351us/sample - loss: 0.1394 - acc: 0.9524 - val_loss: 0.2986 - val_acc: 0.9032\n",
      "Epoch 1133/1500\n",
      "1240/1240 [==============================] - 0s 371us/sample - loss: 0.1521 - acc: 0.9524 - val_loss: 0.2873 - val_acc: 0.9032\n",
      "Epoch 1134/1500\n",
      "1240/1240 [==============================] - 0s 353us/sample - loss: 0.1518 - acc: 0.9468 - val_loss: 0.2129 - val_acc: 0.9355\n",
      "Epoch 1135/1500\n",
      "1240/1240 [==============================] - 0s 328us/sample - loss: 0.1497 - acc: 0.9532 - val_loss: 0.2347 - val_acc: 0.9097\n",
      "Epoch 1136/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1556 - acc: 0.9516 - val_loss: 0.2398 - val_acc: 0.9065\n",
      "Epoch 1137/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1427 - acc: 0.9524 - val_loss: 0.2399 - val_acc: 0.9161\n",
      "Epoch 1138/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1494 - acc: 0.9476 - val_loss: 0.2633 - val_acc: 0.9000\n",
      "Epoch 1139/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1524 - acc: 0.9460 - val_loss: 0.2208 - val_acc: 0.9258\n",
      "Epoch 1140/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1466 - acc: 0.9516 - val_loss: 0.2454 - val_acc: 0.9065\n",
      "Epoch 1141/1500\n",
      "1240/1240 [==============================] - 0s 327us/sample - loss: 0.1524 - acc: 0.9500 - val_loss: 0.2547 - val_acc: 0.9065\n",
      "Epoch 1142/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1490 - acc: 0.9435 - val_loss: 0.2275 - val_acc: 0.9258\n",
      "Epoch 1143/1500\n",
      "1240/1240 [==============================] - 0s 329us/sample - loss: 0.1441 - acc: 0.9524 - val_loss: 0.2212 - val_acc: 0.9226\n",
      "Epoch 1144/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1512 - acc: 0.9532 - val_loss: 0.2131 - val_acc: 0.9355\n",
      "Epoch 1145/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1609 - acc: 0.9379 - val_loss: 0.2137 - val_acc: 0.9161\n",
      "Epoch 1146/1500\n",
      "1240/1240 [==============================] - 0s 311us/sample - loss: 0.1571 - acc: 0.9452 - val_loss: 0.2454 - val_acc: 0.9161\n",
      "Epoch 1147/1500\n",
      "1240/1240 [==============================] - 0s 311us/sample - loss: 0.1648 - acc: 0.9403 - val_loss: 0.2159 - val_acc: 0.9194\n",
      "Epoch 1148/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1497 - acc: 0.9468 - val_loss: 0.2332 - val_acc: 0.9226\n",
      "Epoch 1149/1500\n",
      "1240/1240 [==============================] - 0s 303us/sample - loss: 0.1391 - acc: 0.9524 - val_loss: 0.2623 - val_acc: 0.9097\n",
      "Epoch 1150/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.1497 - acc: 0.9468 - val_loss: 0.2565 - val_acc: 0.9161\n",
      "Epoch 1151/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.1470 - acc: 0.9508 - val_loss: 0.2279 - val_acc: 0.9161\n",
      "Epoch 1152/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1403 - acc: 0.9435 - val_loss: 0.2839 - val_acc: 0.8935\n",
      "Epoch 1153/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1455 - acc: 0.9500 - val_loss: 0.2151 - val_acc: 0.9258\n",
      "Epoch 1154/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1522 - acc: 0.9411 - val_loss: 0.2407 - val_acc: 0.9161\n",
      "Epoch 1155/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1448 - acc: 0.9484 - val_loss: 0.2844 - val_acc: 0.9129\n",
      "Epoch 1156/1500\n",
      "1240/1240 [==============================] - 0s 361us/sample - loss: 0.1399 - acc: 0.9460 - val_loss: 0.2192 - val_acc: 0.9290\n",
      "Epoch 1157/1500\n",
      "1240/1240 [==============================] - 0s 322us/sample - loss: 0.1477 - acc: 0.9524 - val_loss: 0.2380 - val_acc: 0.9194\n",
      "Epoch 1158/1500\n",
      "1240/1240 [==============================] - 0s 323us/sample - loss: 0.1485 - acc: 0.9435 - val_loss: 0.3056 - val_acc: 0.9032\n",
      "Epoch 1159/1500\n",
      "1240/1240 [==============================] - 0s 348us/sample - loss: 0.1543 - acc: 0.9452 - val_loss: 0.2646 - val_acc: 0.9097\n",
      "Epoch 1160/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1418 - acc: 0.9492 - val_loss: 0.2428 - val_acc: 0.9194\n",
      "Epoch 1161/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.1428 - acc: 0.9508 - val_loss: 0.2008 - val_acc: 0.9290\n",
      "Epoch 1162/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.1479 - acc: 0.9460 - val_loss: 0.2399 - val_acc: 0.9226\n",
      "Epoch 1163/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1424 - acc: 0.9532 - val_loss: 0.2758 - val_acc: 0.9065\n",
      "Epoch 1164/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1384 - acc: 0.9524 - val_loss: 0.2612 - val_acc: 0.9226\n",
      "Epoch 1165/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.1521 - acc: 0.9411 - val_loss: 0.3043 - val_acc: 0.9097\n",
      "Epoch 1166/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1466 - acc: 0.9508 - val_loss: 0.2835 - val_acc: 0.9129\n",
      "Epoch 1167/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1414 - acc: 0.9565 - val_loss: 0.2223 - val_acc: 0.9258\n",
      "Epoch 1168/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.1376 - acc: 0.9524 - val_loss: 0.2843 - val_acc: 0.8871\n",
      "Epoch 1169/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1505 - acc: 0.9500 - val_loss: 0.2185 - val_acc: 0.9258\n",
      "Epoch 1170/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1395 - acc: 0.9508 - val_loss: 0.2426 - val_acc: 0.9258\n",
      "Epoch 1171/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1494 - acc: 0.9500 - val_loss: 0.2109 - val_acc: 0.9290\n",
      "Epoch 1172/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1377 - acc: 0.9524 - val_loss: 0.3243 - val_acc: 0.9097\n",
      "Epoch 1173/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1418 - acc: 0.9516 - val_loss: 0.2456 - val_acc: 0.9097\n",
      "Epoch 1174/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1479 - acc: 0.9435 - val_loss: 0.2201 - val_acc: 0.9258\n",
      "Epoch 1175/1500\n",
      "1240/1240 [==============================] - 0s 303us/sample - loss: 0.1453 - acc: 0.9532 - val_loss: 0.2555 - val_acc: 0.9097\n",
      "Epoch 1176/1500\n",
      "1240/1240 [==============================] - 0s 299us/sample - loss: 0.1425 - acc: 0.9548 - val_loss: 0.2542 - val_acc: 0.9032\n",
      "Epoch 1177/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1363 - acc: 0.9548 - val_loss: 0.3332 - val_acc: 0.8774\n",
      "Epoch 1178/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.1433 - acc: 0.9508 - val_loss: 0.2357 - val_acc: 0.9129\n",
      "Epoch 1179/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.1493 - acc: 0.9508 - val_loss: 0.2112 - val_acc: 0.9258\n",
      "Epoch 1180/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1340 - acc: 0.9581 - val_loss: 0.2175 - val_acc: 0.9226\n",
      "Epoch 1181/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1301 - acc: 0.9548 - val_loss: 0.1989 - val_acc: 0.9161\n",
      "Epoch 1182/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1315 - acc: 0.9581 - val_loss: 0.2553 - val_acc: 0.9161\n",
      "Epoch 1183/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1413 - acc: 0.9476 - val_loss: 0.2732 - val_acc: 0.9097\n",
      "Epoch 1184/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1385 - acc: 0.9556 - val_loss: 0.2079 - val_acc: 0.9290\n",
      "Epoch 1185/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1469 - acc: 0.9532 - val_loss: 0.2373 - val_acc: 0.9065\n",
      "Epoch 1186/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1439 - acc: 0.9508 - val_loss: 0.2680 - val_acc: 0.9032\n",
      "Epoch 1187/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1335 - acc: 0.9565 - val_loss: 0.2239 - val_acc: 0.9161\n",
      "Epoch 1188/1500\n",
      "1240/1240 [==============================] - 0s 278us/sample - loss: 0.1392 - acc: 0.9565 - val_loss: 0.1963 - val_acc: 0.9290\n",
      "Epoch 1189/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.1431 - acc: 0.9492 - val_loss: 0.3247 - val_acc: 0.9032\n",
      "Epoch 1190/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1517 - acc: 0.9468 - val_loss: 0.2074 - val_acc: 0.9290\n",
      "Epoch 1191/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.1337 - acc: 0.9556 - val_loss: 0.2410 - val_acc: 0.9032\n",
      "Epoch 1192/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1371 - acc: 0.9516 - val_loss: 0.2063 - val_acc: 0.9194\n",
      "Epoch 1193/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1412 - acc: 0.9516 - val_loss: 0.2094 - val_acc: 0.9355\n",
      "Epoch 1194/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1424 - acc: 0.9460 - val_loss: 0.2220 - val_acc: 0.9161\n",
      "Epoch 1195/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1410 - acc: 0.9532 - val_loss: 0.2537 - val_acc: 0.9194\n",
      "Epoch 1196/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1346 - acc: 0.9508 - val_loss: 0.2506 - val_acc: 0.8968\n",
      "Epoch 1197/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1437 - acc: 0.9492 - val_loss: 0.2450 - val_acc: 0.9161\n",
      "Epoch 1198/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1325 - acc: 0.9500 - val_loss: 0.2114 - val_acc: 0.9355\n",
      "Epoch 1199/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1314 - acc: 0.9605 - val_loss: 0.2317 - val_acc: 0.9226\n",
      "Epoch 1200/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1304 - acc: 0.9613 - val_loss: 0.2808 - val_acc: 0.9065\n",
      "Epoch 1201/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1378 - acc: 0.9500 - val_loss: 0.2183 - val_acc: 0.9226\n",
      "Epoch 1202/1500\n",
      "1240/1240 [==============================] - 0s 321us/sample - loss: 0.1324 - acc: 0.9565 - val_loss: 0.2443 - val_acc: 0.9097\n",
      "Epoch 1203/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.1370 - acc: 0.9581 - val_loss: 0.2854 - val_acc: 0.9000\n",
      "Epoch 1204/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1376 - acc: 0.9581 - val_loss: 0.2079 - val_acc: 0.9323\n",
      "Epoch 1205/1500\n",
      "1240/1240 [==============================] - 0s 292us/sample - loss: 0.1280 - acc: 0.9589 - val_loss: 0.2686 - val_acc: 0.9129\n",
      "Epoch 1206/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1454 - acc: 0.9484 - val_loss: 0.3221 - val_acc: 0.9097\n",
      "Epoch 1207/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.1381 - acc: 0.9500 - val_loss: 0.2429 - val_acc: 0.9323\n",
      "Epoch 1208/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1355 - acc: 0.9516 - val_loss: 0.1901 - val_acc: 0.9387\n",
      "Epoch 1209/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.1290 - acc: 0.9621 - val_loss: 0.2617 - val_acc: 0.9097\n",
      "Epoch 1210/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1403 - acc: 0.9492 - val_loss: 0.2225 - val_acc: 0.9290\n",
      "Epoch 1211/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1384 - acc: 0.9492 - val_loss: 0.2213 - val_acc: 0.9290\n",
      "Epoch 1212/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1455 - acc: 0.9532 - val_loss: 0.2332 - val_acc: 0.9032\n",
      "Epoch 1213/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1424 - acc: 0.9468 - val_loss: 0.2806 - val_acc: 0.9000\n",
      "Epoch 1214/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1337 - acc: 0.9532 - val_loss: 0.2504 - val_acc: 0.9161\n",
      "Epoch 1215/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.1477 - acc: 0.9444 - val_loss: 0.2721 - val_acc: 0.9097\n",
      "Epoch 1216/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.1369 - acc: 0.9444 - val_loss: 0.3185 - val_acc: 0.8839\n",
      "Epoch 1217/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1394 - acc: 0.9548 - val_loss: 0.1806 - val_acc: 0.9323\n",
      "Epoch 1218/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1506 - acc: 0.9419 - val_loss: 0.2188 - val_acc: 0.9355\n",
      "Epoch 1219/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1286 - acc: 0.9556 - val_loss: 0.2540 - val_acc: 0.9065\n",
      "Epoch 1220/1500\n",
      "1240/1240 [==============================] - 0s 316us/sample - loss: 0.1340 - acc: 0.9597 - val_loss: 0.2045 - val_acc: 0.9355\n",
      "Epoch 1221/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1354 - acc: 0.9492 - val_loss: 0.2170 - val_acc: 0.9194\n",
      "Epoch 1222/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.1344 - acc: 0.9540 - val_loss: 0.3007 - val_acc: 0.8806\n",
      "Epoch 1223/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1432 - acc: 0.9548 - val_loss: 0.1912 - val_acc: 0.9452\n",
      "Epoch 1224/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1223 - acc: 0.9645 - val_loss: 0.2761 - val_acc: 0.9000\n",
      "Epoch 1225/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.1346 - acc: 0.9532 - val_loss: 0.2730 - val_acc: 0.9065\n",
      "Epoch 1226/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1317 - acc: 0.9573 - val_loss: 0.3583 - val_acc: 0.8548\n",
      "Epoch 1227/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1460 - acc: 0.9524 - val_loss: 0.2364 - val_acc: 0.9194\n",
      "Epoch 1228/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.1318 - acc: 0.9532 - val_loss: 0.2728 - val_acc: 0.9129\n",
      "Epoch 1229/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1277 - acc: 0.9573 - val_loss: 0.2659 - val_acc: 0.9129\n",
      "Epoch 1230/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1392 - acc: 0.9565 - val_loss: 0.2933 - val_acc: 0.9065\n",
      "Epoch 1231/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1366 - acc: 0.9573 - val_loss: 0.2779 - val_acc: 0.9097\n",
      "Epoch 1232/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1364 - acc: 0.9556 - val_loss: 0.2600 - val_acc: 0.9032\n",
      "Epoch 1233/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1292 - acc: 0.9597 - val_loss: 0.1974 - val_acc: 0.9419\n",
      "Epoch 1234/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.1344 - acc: 0.9548 - val_loss: 0.2006 - val_acc: 0.9323\n",
      "Epoch 1235/1500\n",
      "1240/1240 [==============================] - 0s 293us/sample - loss: 0.1285 - acc: 0.9565 - val_loss: 0.2511 - val_acc: 0.9065\n",
      "Epoch 1236/1500\n",
      "1240/1240 [==============================] - 0s 392us/sample - loss: 0.1280 - acc: 0.9508 - val_loss: 0.2234 - val_acc: 0.9323\n",
      "Epoch 1237/1500\n",
      "1240/1240 [==============================] - 0s 337us/sample - loss: 0.1298 - acc: 0.9597 - val_loss: 0.2066 - val_acc: 0.9355\n",
      "Epoch 1238/1500\n",
      "1240/1240 [==============================] - 0s 328us/sample - loss: 0.1316 - acc: 0.9573 - val_loss: 0.2128 - val_acc: 0.9323\n",
      "Epoch 1239/1500\n",
      "1240/1240 [==============================] - 1s 409us/sample - loss: 0.1200 - acc: 0.9629 - val_loss: 0.3146 - val_acc: 0.8806\n",
      "Epoch 1240/1500\n",
      "1240/1240 [==============================] - 1s 454us/sample - loss: 0.1474 - acc: 0.9435 - val_loss: 0.2505 - val_acc: 0.9065\n",
      "Epoch 1241/1500\n",
      "1240/1240 [==============================] - 0s 392us/sample - loss: 0.1280 - acc: 0.9581 - val_loss: 0.2526 - val_acc: 0.9226\n",
      "Epoch 1242/1500\n",
      "1240/1240 [==============================] - 0s 382us/sample - loss: 0.1385 - acc: 0.9556 - val_loss: 0.2056 - val_acc: 0.9323\n",
      "Epoch 1243/1500\n",
      "1240/1240 [==============================] - 0s 336us/sample - loss: 0.1379 - acc: 0.9524 - val_loss: 0.2470 - val_acc: 0.9097\n",
      "Epoch 1244/1500\n",
      "1240/1240 [==============================] - 0s 319us/sample - loss: 0.1301 - acc: 0.9500 - val_loss: 0.2853 - val_acc: 0.9097\n",
      "Epoch 1245/1500\n",
      "1240/1240 [==============================] - 0s 384us/sample - loss: 0.1306 - acc: 0.9500 - val_loss: 0.2452 - val_acc: 0.9194\n",
      "Epoch 1246/1500\n",
      "1240/1240 [==============================] - 0s 349us/sample - loss: 0.1397 - acc: 0.9492 - val_loss: 0.2381 - val_acc: 0.9032\n",
      "Epoch 1247/1500\n",
      "1240/1240 [==============================] - 0s 346us/sample - loss: 0.1286 - acc: 0.9573 - val_loss: 0.3037 - val_acc: 0.8968\n",
      "Epoch 1248/1500\n",
      "1240/1240 [==============================] - 1s 411us/sample - loss: 0.1407 - acc: 0.9452 - val_loss: 0.2318 - val_acc: 0.9226\n",
      "Epoch 1249/1500\n",
      "1240/1240 [==============================] - 1s 426us/sample - loss: 0.1356 - acc: 0.9508 - val_loss: 0.2315 - val_acc: 0.9290\n",
      "Epoch 1250/1500\n",
      "1240/1240 [==============================] - 0s 328us/sample - loss: 0.1294 - acc: 0.9516 - val_loss: 0.1962 - val_acc: 0.9258\n",
      "Epoch 1251/1500\n",
      "1240/1240 [==============================] - 1s 418us/sample - loss: 0.1320 - acc: 0.9589 - val_loss: 0.2508 - val_acc: 0.9194\n",
      "Epoch 1252/1500\n",
      "1240/1240 [==============================] - 1s 444us/sample - loss: 0.1308 - acc: 0.9573 - val_loss: 0.2616 - val_acc: 0.9194\n",
      "Epoch 1253/1500\n",
      "1240/1240 [==============================] - 1s 524us/sample - loss: 0.1298 - acc: 0.9524 - val_loss: 0.3223 - val_acc: 0.8839\n",
      "Epoch 1254/1500\n",
      "1240/1240 [==============================] - 0s 389us/sample - loss: 0.1402 - acc: 0.9500 - val_loss: 0.2560 - val_acc: 0.9032\n",
      "Epoch 1255/1500\n",
      "1240/1240 [==============================] - 0s 317us/sample - loss: 0.1341 - acc: 0.9548 - val_loss: 0.2223 - val_acc: 0.9194\n",
      "Epoch 1256/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1274 - acc: 0.9540 - val_loss: 0.2310 - val_acc: 0.9194\n",
      "Epoch 1257/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.1397 - acc: 0.9597 - val_loss: 0.2203 - val_acc: 0.9258\n",
      "Epoch 1258/1500\n",
      "1240/1240 [==============================] - 0s 319us/sample - loss: 0.1286 - acc: 0.9540 - val_loss: 0.3130 - val_acc: 0.9000\n",
      "Epoch 1259/1500\n",
      "1240/1240 [==============================] - 0s 334us/sample - loss: 0.1291 - acc: 0.9597 - val_loss: 0.3109 - val_acc: 0.8935\n",
      "Epoch 1260/1500\n",
      "1240/1240 [==============================] - 0s 363us/sample - loss: 0.1307 - acc: 0.9573 - val_loss: 0.2655 - val_acc: 0.9097\n",
      "Epoch 1261/1500\n",
      "1240/1240 [==============================] - 0s 382us/sample - loss: 0.1401 - acc: 0.9484 - val_loss: 0.2389 - val_acc: 0.9194\n",
      "Epoch 1262/1500\n",
      "1240/1240 [==============================] - 0s 383us/sample - loss: 0.1286 - acc: 0.9581 - val_loss: 0.2256 - val_acc: 0.9194\n",
      "Epoch 1263/1500\n",
      "1240/1240 [==============================] - 0s 389us/sample - loss: 0.1341 - acc: 0.9492 - val_loss: 0.2388 - val_acc: 0.9194\n",
      "Epoch 1264/1500\n",
      "1240/1240 [==============================] - 0s 318us/sample - loss: 0.1125 - acc: 0.9637 - val_loss: 0.2771 - val_acc: 0.9065\n",
      "Epoch 1265/1500\n",
      "1240/1240 [==============================] - 1s 463us/sample - loss: 0.1289 - acc: 0.9556 - val_loss: 0.2303 - val_acc: 0.9290\n",
      "Epoch 1266/1500\n",
      "1240/1240 [==============================] - 0s 351us/sample - loss: 0.1271 - acc: 0.9532 - val_loss: 0.2207 - val_acc: 0.9226\n",
      "Epoch 1267/1500\n",
      "1240/1240 [==============================] - 0s 311us/sample - loss: 0.1359 - acc: 0.9556 - val_loss: 0.2607 - val_acc: 0.9387\n",
      "Epoch 1268/1500\n",
      "1240/1240 [==============================] - 0s 403us/sample - loss: 0.1227 - acc: 0.9548 - val_loss: 0.2444 - val_acc: 0.9129\n",
      "Epoch 1269/1500\n",
      "1240/1240 [==============================] - 1s 429us/sample - loss: 0.1456 - acc: 0.9508 - val_loss: 0.2256 - val_acc: 0.9355\n",
      "Epoch 1270/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.1233 - acc: 0.9573 - val_loss: 0.2267 - val_acc: 0.9323\n",
      "Epoch 1271/1500\n",
      "1240/1240 [==============================] - 0s 316us/sample - loss: 0.1281 - acc: 0.9573 - val_loss: 0.2369 - val_acc: 0.9226\n",
      "Epoch 1272/1500\n",
      "1240/1240 [==============================] - 0s 403us/sample - loss: 0.1251 - acc: 0.9556 - val_loss: 0.2219 - val_acc: 0.9194\n",
      "Epoch 1273/1500\n",
      "1240/1240 [==============================] - 0s 347us/sample - loss: 0.1278 - acc: 0.9589 - val_loss: 0.2035 - val_acc: 0.9290\n",
      "Epoch 1274/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1343 - acc: 0.9565 - val_loss: 0.2275 - val_acc: 0.9258\n",
      "Epoch 1275/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1202 - acc: 0.9573 - val_loss: 0.2155 - val_acc: 0.9194\n",
      "Epoch 1276/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1302 - acc: 0.9532 - val_loss: 0.2457 - val_acc: 0.9194\n",
      "Epoch 1277/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1287 - acc: 0.9556 - val_loss: 0.2902 - val_acc: 0.9129\n",
      "Epoch 1278/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.1242 - acc: 0.9605 - val_loss: 0.2668 - val_acc: 0.9129\n",
      "Epoch 1279/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1184 - acc: 0.9621 - val_loss: 0.2235 - val_acc: 0.9323\n",
      "Epoch 1280/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1293 - acc: 0.9581 - val_loss: 0.2559 - val_acc: 0.9161\n",
      "Epoch 1281/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1211 - acc: 0.9621 - val_loss: 0.2645 - val_acc: 0.9129\n",
      "Epoch 1282/1500\n",
      "1240/1240 [==============================] - 0s 338us/sample - loss: 0.1276 - acc: 0.9573 - val_loss: 0.2604 - val_acc: 0.9097\n",
      "Epoch 1283/1500\n",
      "1240/1240 [==============================] - 0s 378us/sample - loss: 0.1275 - acc: 0.9524 - val_loss: 0.2007 - val_acc: 0.9387\n",
      "Epoch 1284/1500\n",
      "1240/1240 [==============================] - 1s 405us/sample - loss: 0.1344 - acc: 0.9508 - val_loss: 0.2484 - val_acc: 0.9161\n",
      "Epoch 1285/1500\n",
      "1240/1240 [==============================] - 1s 427us/sample - loss: 0.1236 - acc: 0.9629 - val_loss: 0.2666 - val_acc: 0.9065\n",
      "Epoch 1286/1500\n",
      "1240/1240 [==============================] - 1s 478us/sample - loss: 0.1238 - acc: 0.9565 - val_loss: 0.2347 - val_acc: 0.9290\n",
      "Epoch 1287/1500\n",
      "1240/1240 [==============================] - 0s 376us/sample - loss: 0.1284 - acc: 0.9565 - val_loss: 0.2512 - val_acc: 0.9290\n",
      "Epoch 1288/1500\n",
      "1240/1240 [==============================] - 0s 311us/sample - loss: 0.1307 - acc: 0.9556 - val_loss: 0.2097 - val_acc: 0.9290\n",
      "Epoch 1289/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.1236 - acc: 0.9629 - val_loss: 0.2499 - val_acc: 0.8935\n",
      "Epoch 1290/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1152 - acc: 0.9605 - val_loss: 0.2046 - val_acc: 0.9323\n",
      "Epoch 1291/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1360 - acc: 0.9452 - val_loss: 0.2869 - val_acc: 0.9097\n",
      "Epoch 1292/1500\n",
      "1240/1240 [==============================] - 0s 321us/sample - loss: 0.1184 - acc: 0.9613 - val_loss: 0.2211 - val_acc: 0.9129\n",
      "Epoch 1293/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1288 - acc: 0.9548 - val_loss: 0.2290 - val_acc: 0.9387\n",
      "Epoch 1294/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1205 - acc: 0.9581 - val_loss: 0.2241 - val_acc: 0.9194\n",
      "Epoch 1295/1500\n",
      "1240/1240 [==============================] - 0s 339us/sample - loss: 0.1288 - acc: 0.9573 - val_loss: 0.2124 - val_acc: 0.9290\n",
      "Epoch 1296/1500\n",
      "1240/1240 [==============================] - 0s 333us/sample - loss: 0.1343 - acc: 0.9581 - val_loss: 0.2260 - val_acc: 0.9323\n",
      "Epoch 1297/1500\n",
      "1240/1240 [==============================] - 0s 340us/sample - loss: 0.1215 - acc: 0.9621 - val_loss: 0.2195 - val_acc: 0.9226\n",
      "Epoch 1298/1500\n",
      "1240/1240 [==============================] - 0s 332us/sample - loss: 0.1323 - acc: 0.9532 - val_loss: 0.2275 - val_acc: 0.9258\n",
      "Epoch 1299/1500\n",
      "1240/1240 [==============================] - 0s 318us/sample - loss: 0.1154 - acc: 0.9637 - val_loss: 0.2704 - val_acc: 0.9290\n",
      "Epoch 1300/1500\n",
      "1240/1240 [==============================] - 0s 327us/sample - loss: 0.1255 - acc: 0.9589 - val_loss: 0.2512 - val_acc: 0.9355\n",
      "Epoch 1301/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.1302 - acc: 0.9540 - val_loss: 0.2441 - val_acc: 0.9226\n",
      "Epoch 1302/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.1243 - acc: 0.9581 - val_loss: 0.2460 - val_acc: 0.9226\n",
      "Epoch 1303/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1273 - acc: 0.9573 - val_loss: 0.2052 - val_acc: 0.9355\n",
      "Epoch 1304/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.1175 - acc: 0.9669 - val_loss: 0.3226 - val_acc: 0.8935\n",
      "Epoch 1305/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.1210 - acc: 0.9661 - val_loss: 0.2493 - val_acc: 0.8935\n",
      "Epoch 1306/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1293 - acc: 0.9500 - val_loss: 0.2978 - val_acc: 0.9000\n",
      "Epoch 1307/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.1183 - acc: 0.9597 - val_loss: 0.2164 - val_acc: 0.9194\n",
      "Epoch 1308/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1223 - acc: 0.9605 - val_loss: 0.2080 - val_acc: 0.9290\n",
      "Epoch 1309/1500\n",
      "1240/1240 [==============================] - 0s 311us/sample - loss: 0.1251 - acc: 0.9556 - val_loss: 0.2012 - val_acc: 0.9387\n",
      "Epoch 1310/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.1175 - acc: 0.9621 - val_loss: 0.2184 - val_acc: 0.9194\n",
      "Epoch 1311/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1162 - acc: 0.9629 - val_loss: 0.2200 - val_acc: 0.9097\n",
      "Epoch 1312/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1196 - acc: 0.9629 - val_loss: 0.2109 - val_acc: 0.9258\n",
      "Epoch 1313/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.1210 - acc: 0.9565 - val_loss: 0.2569 - val_acc: 0.9258\n",
      "Epoch 1314/1500\n",
      "1240/1240 [==============================] - 0s 319us/sample - loss: 0.1214 - acc: 0.9597 - val_loss: 0.1905 - val_acc: 0.9355\n",
      "Epoch 1315/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1244 - acc: 0.9597 - val_loss: 0.2235 - val_acc: 0.9065\n",
      "Epoch 1316/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1155 - acc: 0.9605 - val_loss: 0.2923 - val_acc: 0.9129\n",
      "Epoch 1317/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.1239 - acc: 0.9589 - val_loss: 0.2517 - val_acc: 0.9129\n",
      "Epoch 1318/1500\n",
      "1240/1240 [==============================] - 0s 316us/sample - loss: 0.1123 - acc: 0.9637 - val_loss: 0.2840 - val_acc: 0.9226\n",
      "Epoch 1319/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1220 - acc: 0.9621 - val_loss: 0.2521 - val_acc: 0.9129\n",
      "Epoch 1320/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1159 - acc: 0.9605 - val_loss: 0.3042 - val_acc: 0.8774\n",
      "Epoch 1321/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1200 - acc: 0.9605 - val_loss: 0.1979 - val_acc: 0.9323\n",
      "Epoch 1322/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.1232 - acc: 0.9597 - val_loss: 0.2189 - val_acc: 0.9226\n",
      "Epoch 1323/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.1106 - acc: 0.9613 - val_loss: 0.2101 - val_acc: 0.9161\n",
      "Epoch 1324/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1076 - acc: 0.9685 - val_loss: 0.2535 - val_acc: 0.9452\n",
      "Epoch 1325/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1241 - acc: 0.9589 - val_loss: 0.2314 - val_acc: 0.9258\n",
      "Epoch 1326/1500\n",
      "1240/1240 [==============================] - 0s 265us/sample - loss: 0.1169 - acc: 0.9556 - val_loss: 0.2224 - val_acc: 0.9258\n",
      "Epoch 1327/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.1140 - acc: 0.9653 - val_loss: 0.2210 - val_acc: 0.9355\n",
      "Epoch 1328/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1142 - acc: 0.9653 - val_loss: 0.2050 - val_acc: 0.9323\n",
      "Epoch 1329/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1316 - acc: 0.9524 - val_loss: 0.1935 - val_acc: 0.9387\n",
      "Epoch 1330/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1115 - acc: 0.9613 - val_loss: 0.2095 - val_acc: 0.9226\n",
      "Epoch 1331/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.1233 - acc: 0.9573 - val_loss: 0.2329 - val_acc: 0.9129\n",
      "Epoch 1332/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1141 - acc: 0.9710 - val_loss: 0.2380 - val_acc: 0.9290\n",
      "Epoch 1333/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1160 - acc: 0.9621 - val_loss: 0.2033 - val_acc: 0.9226\n",
      "Epoch 1334/1500\n",
      "1240/1240 [==============================] - 0s 271us/sample - loss: 0.1172 - acc: 0.9605 - val_loss: 0.2429 - val_acc: 0.9323\n",
      "Epoch 1335/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1290 - acc: 0.9565 - val_loss: 0.2359 - val_acc: 0.9226\n",
      "Epoch 1336/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1234 - acc: 0.9581 - val_loss: 0.2843 - val_acc: 0.9032\n",
      "Epoch 1337/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1199 - acc: 0.9605 - val_loss: 0.2402 - val_acc: 0.9097\n",
      "Epoch 1338/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1212 - acc: 0.9629 - val_loss: 0.2542 - val_acc: 0.9000\n",
      "Epoch 1339/1500\n",
      "1240/1240 [==============================] - 0s 277us/sample - loss: 0.1133 - acc: 0.9645 - val_loss: 0.2601 - val_acc: 0.9161\n",
      "Epoch 1340/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1213 - acc: 0.9629 - val_loss: 0.2030 - val_acc: 0.9290\n",
      "Epoch 1341/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1158 - acc: 0.9573 - val_loss: 0.1962 - val_acc: 0.9387\n",
      "Epoch 1342/1500\n",
      "1240/1240 [==============================] - 0s 284us/sample - loss: 0.1103 - acc: 0.9629 - val_loss: 0.3049 - val_acc: 0.8935\n",
      "Epoch 1343/1500\n",
      "1240/1240 [==============================] - 0s 312us/sample - loss: 0.1158 - acc: 0.9621 - val_loss: 0.2343 - val_acc: 0.9129\n",
      "Epoch 1344/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1105 - acc: 0.9629 - val_loss: 0.2607 - val_acc: 0.9097\n",
      "Epoch 1345/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.1199 - acc: 0.9589 - val_loss: 0.2115 - val_acc: 0.9258\n",
      "Epoch 1346/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.1166 - acc: 0.9589 - val_loss: 0.2338 - val_acc: 0.9194\n",
      "Epoch 1347/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1083 - acc: 0.9694 - val_loss: 0.3317 - val_acc: 0.9032\n",
      "Epoch 1348/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1190 - acc: 0.9637 - val_loss: 0.3277 - val_acc: 0.8935\n",
      "Epoch 1349/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1228 - acc: 0.9532 - val_loss: 0.2386 - val_acc: 0.9323\n",
      "Epoch 1350/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1236 - acc: 0.9573 - val_loss: 0.2043 - val_acc: 0.9387\n",
      "Epoch 1351/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1099 - acc: 0.9597 - val_loss: 0.3065 - val_acc: 0.8839\n",
      "Epoch 1352/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1130 - acc: 0.9565 - val_loss: 0.2287 - val_acc: 0.9097\n",
      "Epoch 1353/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1149 - acc: 0.9637 - val_loss: 0.2515 - val_acc: 0.9194\n",
      "Epoch 1354/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1121 - acc: 0.9597 - val_loss: 0.2516 - val_acc: 0.9194\n",
      "Epoch 1355/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1076 - acc: 0.9653 - val_loss: 0.2124 - val_acc: 0.9355\n",
      "Epoch 1356/1500\n",
      "1240/1240 [==============================] - 0s 286us/sample - loss: 0.1154 - acc: 0.9653 - val_loss: 0.3269 - val_acc: 0.9000\n",
      "Epoch 1357/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.1124 - acc: 0.9613 - val_loss: 0.2178 - val_acc: 0.9258\n",
      "Epoch 1358/1500\n",
      "1240/1240 [==============================] - 0s 322us/sample - loss: 0.1199 - acc: 0.9565 - val_loss: 0.2177 - val_acc: 0.9258\n",
      "Epoch 1359/1500\n",
      "1240/1240 [==============================] - 0s 313us/sample - loss: 0.1186 - acc: 0.9524 - val_loss: 0.2374 - val_acc: 0.9161\n",
      "Epoch 1360/1500\n",
      "1240/1240 [==============================] - 0s 326us/sample - loss: 0.1190 - acc: 0.9581 - val_loss: 0.1720 - val_acc: 0.9387\n",
      "Epoch 1361/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1130 - acc: 0.9565 - val_loss: 0.2006 - val_acc: 0.9387\n",
      "Epoch 1362/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1146 - acc: 0.9621 - val_loss: 0.3374 - val_acc: 0.8968\n",
      "Epoch 1363/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1240 - acc: 0.9540 - val_loss: 0.2100 - val_acc: 0.9323\n",
      "Epoch 1364/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1102 - acc: 0.9613 - val_loss: 0.1891 - val_acc: 0.9387\n",
      "Epoch 1365/1500\n",
      "1240/1240 [==============================] - 0s 318us/sample - loss: 0.1214 - acc: 0.9637 - val_loss: 0.3506 - val_acc: 0.8935\n",
      "Epoch 1366/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1159 - acc: 0.9621 - val_loss: 0.2088 - val_acc: 0.9194\n",
      "Epoch 1367/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1076 - acc: 0.9605 - val_loss: 0.2612 - val_acc: 0.8903\n",
      "Epoch 1368/1500\n",
      "1240/1240 [==============================] - 0s 334us/sample - loss: 0.1113 - acc: 0.9653 - val_loss: 0.2686 - val_acc: 0.9065\n",
      "Epoch 1369/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1181 - acc: 0.9621 - val_loss: 0.2139 - val_acc: 0.9290\n",
      "Epoch 1370/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.1146 - acc: 0.9637 - val_loss: 0.2663 - val_acc: 0.9065\n",
      "Epoch 1371/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1267 - acc: 0.9532 - val_loss: 0.2484 - val_acc: 0.9226\n",
      "Epoch 1372/1500\n",
      "1240/1240 [==============================] - 0s 320us/sample - loss: 0.1024 - acc: 0.9694 - val_loss: 0.2206 - val_acc: 0.9290\n",
      "Epoch 1373/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.1143 - acc: 0.9621 - val_loss: 0.2188 - val_acc: 0.9258\n",
      "Epoch 1374/1500\n",
      "1240/1240 [==============================] - 0s 327us/sample - loss: 0.1151 - acc: 0.9629 - val_loss: 0.2441 - val_acc: 0.9097\n",
      "Epoch 1375/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1047 - acc: 0.9661 - val_loss: 0.2815 - val_acc: 0.9065\n",
      "Epoch 1376/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1181 - acc: 0.9605 - val_loss: 0.2069 - val_acc: 0.9387\n",
      "Epoch 1377/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1229 - acc: 0.9532 - val_loss: 0.2924 - val_acc: 0.9032\n",
      "Epoch 1378/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1134 - acc: 0.9605 - val_loss: 0.2684 - val_acc: 0.9000\n",
      "Epoch 1379/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1134 - acc: 0.9677 - val_loss: 0.2302 - val_acc: 0.9258\n",
      "Epoch 1380/1500\n",
      "1240/1240 [==============================] - 0s 323us/sample - loss: 0.1146 - acc: 0.9645 - val_loss: 0.2045 - val_acc: 0.9290\n",
      "Epoch 1381/1500\n",
      "1240/1240 [==============================] - 0s 367us/sample - loss: 0.1108 - acc: 0.9637 - val_loss: 0.2410 - val_acc: 0.9258\n",
      "Epoch 1382/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1179 - acc: 0.9556 - val_loss: 0.1862 - val_acc: 0.9419\n",
      "Epoch 1383/1500\n",
      "1240/1240 [==============================] - 0s 347us/sample - loss: 0.1001 - acc: 0.9685 - val_loss: 0.2353 - val_acc: 0.9194\n",
      "Epoch 1384/1500\n",
      "1240/1240 [==============================] - 0s 340us/sample - loss: 0.1166 - acc: 0.9548 - val_loss: 0.2482 - val_acc: 0.9194\n",
      "Epoch 1385/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.1064 - acc: 0.9685 - val_loss: 0.2807 - val_acc: 0.9129\n",
      "Epoch 1386/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.1143 - acc: 0.9581 - val_loss: 0.2145 - val_acc: 0.9323\n",
      "Epoch 1387/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1129 - acc: 0.9613 - val_loss: 0.2177 - val_acc: 0.9258\n",
      "Epoch 1388/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1092 - acc: 0.9661 - val_loss: 0.3151 - val_acc: 0.8871\n",
      "Epoch 1389/1500\n",
      "1240/1240 [==============================] - 0s 304us/sample - loss: 0.1197 - acc: 0.9565 - val_loss: 0.1890 - val_acc: 0.9387\n",
      "Epoch 1390/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.1078 - acc: 0.9605 - val_loss: 0.2570 - val_acc: 0.9161\n",
      "Epoch 1391/1500\n",
      "1240/1240 [==============================] - 0s 299us/sample - loss: 0.1151 - acc: 0.9581 - val_loss: 0.3458 - val_acc: 0.8935\n",
      "Epoch 1392/1500\n",
      "1240/1240 [==============================] - 0s 317us/sample - loss: 0.1085 - acc: 0.9597 - val_loss: 0.2346 - val_acc: 0.9290\n",
      "Epoch 1393/1500\n",
      "1240/1240 [==============================] - 0s 319us/sample - loss: 0.1149 - acc: 0.9637 - val_loss: 0.2126 - val_acc: 0.9290\n",
      "Epoch 1394/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1237 - acc: 0.9605 - val_loss: 0.1918 - val_acc: 0.9452\n",
      "Epoch 1395/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1051 - acc: 0.9734 - val_loss: 0.2983 - val_acc: 0.9129\n",
      "Epoch 1396/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.1067 - acc: 0.9637 - val_loss: 0.2551 - val_acc: 0.9226\n",
      "Epoch 1397/1500\n",
      "1240/1240 [==============================] - 0s 308us/sample - loss: 0.1219 - acc: 0.9589 - val_loss: 0.2823 - val_acc: 0.8968\n",
      "Epoch 1398/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1082 - acc: 0.9637 - val_loss: 0.1801 - val_acc: 0.9484\n",
      "Epoch 1399/1500\n",
      "1240/1240 [==============================] - 0s 307us/sample - loss: 0.1058 - acc: 0.9653 - val_loss: 0.2379 - val_acc: 0.9129\n",
      "Epoch 1400/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.1030 - acc: 0.9661 - val_loss: 0.2296 - val_acc: 0.9194\n",
      "Epoch 1401/1500\n",
      "1240/1240 [==============================] - 0s 306us/sample - loss: 0.1201 - acc: 0.9532 - val_loss: 0.2689 - val_acc: 0.9032\n",
      "Epoch 1402/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1117 - acc: 0.9669 - val_loss: 0.2004 - val_acc: 0.9226\n",
      "Epoch 1403/1500\n",
      "1240/1240 [==============================] - 0s 310us/sample - loss: 0.1109 - acc: 0.9645 - val_loss: 0.2993 - val_acc: 0.8903\n",
      "Epoch 1404/1500\n",
      "1240/1240 [==============================] - 0s 305us/sample - loss: 0.1116 - acc: 0.9669 - val_loss: 0.2391 - val_acc: 0.9129\n",
      "Epoch 1405/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.1069 - acc: 0.9637 - val_loss: 0.2527 - val_acc: 0.9290\n",
      "Epoch 1406/1500\n",
      "1240/1240 [==============================] - 0s 302us/sample - loss: 0.1157 - acc: 0.9653 - val_loss: 0.2510 - val_acc: 0.9226\n",
      "Epoch 1407/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1201 - acc: 0.9637 - val_loss: 0.2020 - val_acc: 0.9452\n",
      "Epoch 1408/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.1014 - acc: 0.9702 - val_loss: 0.2233 - val_acc: 0.9194\n",
      "Epoch 1409/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.1197 - acc: 0.9565 - val_loss: 0.2543 - val_acc: 0.9194\n",
      "Epoch 1410/1500\n",
      "1240/1240 [==============================] - 0s 346us/sample - loss: 0.1004 - acc: 0.9710 - val_loss: 0.2094 - val_acc: 0.9097\n",
      "Epoch 1411/1500\n",
      "1240/1240 [==============================] - 0s 400us/sample - loss: 0.1042 - acc: 0.9718 - val_loss: 0.2253 - val_acc: 0.9194\n",
      "Epoch 1412/1500\n",
      "1240/1240 [==============================] - 1s 411us/sample - loss: 0.1011 - acc: 0.9702 - val_loss: 0.2094 - val_acc: 0.9355\n",
      "Epoch 1413/1500\n",
      "1240/1240 [==============================] - 1s 466us/sample - loss: 0.1205 - acc: 0.9565 - val_loss: 0.2199 - val_acc: 0.9258\n",
      "Epoch 1414/1500\n",
      "1240/1240 [==============================] - 1s 458us/sample - loss: 0.1036 - acc: 0.9613 - val_loss: 0.2059 - val_acc: 0.9226\n",
      "Epoch 1415/1500\n",
      "1240/1240 [==============================] - 0s 318us/sample - loss: 0.1062 - acc: 0.9637 - val_loss: 0.2298 - val_acc: 0.9290\n",
      "Epoch 1416/1500\n",
      "1240/1240 [==============================] - 1s 429us/sample - loss: 0.1063 - acc: 0.9613 - val_loss: 0.2226 - val_acc: 0.9194\n",
      "Epoch 1417/1500\n",
      "1240/1240 [==============================] - 0s 327us/sample - loss: 0.0992 - acc: 0.9669 - val_loss: 0.2196 - val_acc: 0.9194\n",
      "Epoch 1418/1500\n",
      "1240/1240 [==============================] - 0s 336us/sample - loss: 0.1092 - acc: 0.9621 - val_loss: 0.2503 - val_acc: 0.9000\n",
      "Epoch 1419/1500\n",
      "1240/1240 [==============================] - 0s 401us/sample - loss: 0.1057 - acc: 0.9613 - val_loss: 0.2172 - val_acc: 0.9226\n",
      "Epoch 1420/1500\n",
      "1240/1240 [==============================] - 1s 523us/sample - loss: 0.1178 - acc: 0.9613 - val_loss: 0.1802 - val_acc: 0.9387\n",
      "Epoch 1421/1500\n",
      "1240/1240 [==============================] - 1s 524us/sample - loss: 0.1056 - acc: 0.9573 - val_loss: 0.2642 - val_acc: 0.9161\n",
      "Epoch 1422/1500\n",
      "1240/1240 [==============================] - 1s 515us/sample - loss: 0.1044 - acc: 0.9629 - val_loss: 0.2064 - val_acc: 0.9226\n",
      "Epoch 1423/1500\n",
      "1240/1240 [==============================] - 1s 512us/sample - loss: 0.1139 - acc: 0.9645 - val_loss: 0.1893 - val_acc: 0.9355\n",
      "Epoch 1424/1500\n",
      "1240/1240 [==============================] - 1s 456us/sample - loss: 0.1057 - acc: 0.9613 - val_loss: 0.2768 - val_acc: 0.9097\n",
      "Epoch 1425/1500\n",
      "1240/1240 [==============================] - 1s 442us/sample - loss: 0.1104 - acc: 0.9573 - val_loss: 0.2151 - val_acc: 0.9258\n",
      "Epoch 1426/1500\n",
      "1240/1240 [==============================] - 1s 433us/sample - loss: 0.1102 - acc: 0.9669 - val_loss: 0.2021 - val_acc: 0.9323\n",
      "Epoch 1427/1500\n",
      "1240/1240 [==============================] - 1s 424us/sample - loss: 0.1065 - acc: 0.9694 - val_loss: 0.2448 - val_acc: 0.9097\n",
      "Epoch 1428/1500\n",
      "1240/1240 [==============================] - 1s 422us/sample - loss: 0.1031 - acc: 0.9645 - val_loss: 0.2143 - val_acc: 0.9290\n",
      "Epoch 1429/1500\n",
      "1240/1240 [==============================] - 0s 317us/sample - loss: 0.1165 - acc: 0.9645 - val_loss: 0.2575 - val_acc: 0.9129\n",
      "Epoch 1430/1500\n",
      "1240/1240 [==============================] - 0s 335us/sample - loss: 0.1103 - acc: 0.9565 - val_loss: 0.2393 - val_acc: 0.9226\n",
      "Epoch 1431/1500\n",
      "1240/1240 [==============================] - 0s 314us/sample - loss: 0.0953 - acc: 0.9766 - val_loss: 0.2225 - val_acc: 0.9323\n",
      "Epoch 1432/1500\n",
      "1240/1240 [==============================] - 0s 332us/sample - loss: 0.1080 - acc: 0.9573 - val_loss: 0.2330 - val_acc: 0.9097\n",
      "Epoch 1433/1500\n",
      "1240/1240 [==============================] - 0s 309us/sample - loss: 0.1084 - acc: 0.9637 - val_loss: 0.2142 - val_acc: 0.9226\n",
      "Epoch 1434/1500\n",
      "1240/1240 [==============================] - 0s 315us/sample - loss: 0.1142 - acc: 0.9613 - val_loss: 0.2154 - val_acc: 0.9226\n",
      "Epoch 1435/1500\n",
      "1240/1240 [==============================] - 0s 316us/sample - loss: 0.1084 - acc: 0.9629 - val_loss: 0.2308 - val_acc: 0.9290\n",
      "Epoch 1436/1500\n",
      "1240/1240 [==============================] - 0s 311us/sample - loss: 0.1013 - acc: 0.9726 - val_loss: 0.3349 - val_acc: 0.8968\n",
      "Epoch 1437/1500\n",
      "1240/1240 [==============================] - 0s 299us/sample - loss: 0.1195 - acc: 0.9589 - val_loss: 0.2105 - val_acc: 0.9419\n",
      "Epoch 1438/1500\n",
      "1240/1240 [==============================] - 0s 296us/sample - loss: 0.1024 - acc: 0.9661 - val_loss: 0.2455 - val_acc: 0.9226\n",
      "Epoch 1439/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1075 - acc: 0.9661 - val_loss: 0.2433 - val_acc: 0.9258\n",
      "Epoch 1440/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1069 - acc: 0.9621 - val_loss: 0.2303 - val_acc: 0.9129\n",
      "Epoch 1441/1500\n",
      "1240/1240 [==============================] - 0s 270us/sample - loss: 0.1037 - acc: 0.9645 - val_loss: 0.2224 - val_acc: 0.9194\n",
      "Epoch 1442/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.0952 - acc: 0.9742 - val_loss: 0.2146 - val_acc: 0.9387\n",
      "Epoch 1443/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.1083 - acc: 0.9637 - val_loss: 0.2199 - val_acc: 0.9258\n",
      "Epoch 1444/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.0969 - acc: 0.9669 - val_loss: 0.2362 - val_acc: 0.9258\n",
      "Epoch 1445/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1057 - acc: 0.9629 - val_loss: 0.2539 - val_acc: 0.9097\n",
      "Epoch 1446/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.0999 - acc: 0.9605 - val_loss: 0.2305 - val_acc: 0.9194\n",
      "Epoch 1447/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1126 - acc: 0.9629 - val_loss: 0.1811 - val_acc: 0.9516\n",
      "Epoch 1448/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.0991 - acc: 0.9669 - val_loss: 0.2124 - val_acc: 0.9323\n",
      "Epoch 1449/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1082 - acc: 0.9645 - val_loss: 0.2311 - val_acc: 0.9194\n",
      "Epoch 1450/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1021 - acc: 0.9629 - val_loss: 0.2481 - val_acc: 0.8968\n",
      "Epoch 1451/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1047 - acc: 0.9613 - val_loss: 0.2748 - val_acc: 0.9065\n",
      "Epoch 1452/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.1046 - acc: 0.9621 - val_loss: 0.3398 - val_acc: 0.9032\n",
      "Epoch 1453/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.0943 - acc: 0.9734 - val_loss: 0.2001 - val_acc: 0.9323\n",
      "Epoch 1454/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1013 - acc: 0.9661 - val_loss: 0.2635 - val_acc: 0.8968\n",
      "Epoch 1455/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1115 - acc: 0.9597 - val_loss: 0.2263 - val_acc: 0.9258\n",
      "Epoch 1456/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.0965 - acc: 0.9718 - val_loss: 0.2567 - val_acc: 0.9097\n",
      "Epoch 1457/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1059 - acc: 0.9694 - val_loss: 0.3457 - val_acc: 0.9097\n",
      "Epoch 1458/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.1032 - acc: 0.9637 - val_loss: 0.2739 - val_acc: 0.9000\n",
      "Epoch 1459/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1002 - acc: 0.9685 - val_loss: 0.2134 - val_acc: 0.9226\n",
      "Epoch 1460/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1030 - acc: 0.9653 - val_loss: 0.2113 - val_acc: 0.9258\n",
      "Epoch 1461/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1002 - acc: 0.9685 - val_loss: 0.2029 - val_acc: 0.9452\n",
      "Epoch 1462/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1015 - acc: 0.9710 - val_loss: 0.2655 - val_acc: 0.9258\n",
      "Epoch 1463/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.1006 - acc: 0.9677 - val_loss: 0.3514 - val_acc: 0.8935\n",
      "Epoch 1464/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1016 - acc: 0.9694 - val_loss: 0.1932 - val_acc: 0.9387\n",
      "Epoch 1465/1500\n",
      "1240/1240 [==============================] - 0s 294us/sample - loss: 0.1058 - acc: 0.9645 - val_loss: 0.2069 - val_acc: 0.9258\n",
      "Epoch 1466/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.0999 - acc: 0.9661 - val_loss: 0.3874 - val_acc: 0.9000\n",
      "Epoch 1467/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 0.1015 - acc: 0.9694 - val_loss: 0.2134 - val_acc: 0.9355\n",
      "Epoch 1468/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.0929 - acc: 0.9750 - val_loss: 0.2323 - val_acc: 0.9129\n",
      "Epoch 1469/1500\n",
      "1240/1240 [==============================] - 0s 276us/sample - loss: 0.0936 - acc: 0.9669 - val_loss: 0.2065 - val_acc: 0.9194\n",
      "Epoch 1470/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1035 - acc: 0.9629 - val_loss: 0.2704 - val_acc: 0.8968\n",
      "Epoch 1471/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1004 - acc: 0.9621 - val_loss: 0.2577 - val_acc: 0.9226\n",
      "Epoch 1472/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.1085 - acc: 0.9669 - val_loss: 0.1994 - val_acc: 0.9452\n",
      "Epoch 1473/1500\n",
      "1240/1240 [==============================] - 0s 290us/sample - loss: 0.1010 - acc: 0.9726 - val_loss: 0.2187 - val_acc: 0.9161\n",
      "Epoch 1474/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.0943 - acc: 0.9669 - val_loss: 0.2379 - val_acc: 0.9161\n",
      "Epoch 1475/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1010 - acc: 0.9645 - val_loss: 0.2352 - val_acc: 0.9355\n",
      "Epoch 1476/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1065 - acc: 0.9613 - val_loss: 0.2039 - val_acc: 0.9161\n",
      "Epoch 1477/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.0918 - acc: 0.9702 - val_loss: 0.2717 - val_acc: 0.9032\n",
      "Epoch 1478/1500\n",
      "1240/1240 [==============================] - 0s 288us/sample - loss: 0.1001 - acc: 0.9653 - val_loss: 0.2378 - val_acc: 0.9258\n",
      "Epoch 1479/1500\n",
      "1240/1240 [==============================] - 0s 285us/sample - loss: 0.1021 - acc: 0.9613 - val_loss: 0.1855 - val_acc: 0.9355\n",
      "Epoch 1480/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.0940 - acc: 0.9726 - val_loss: 0.2905 - val_acc: 0.9065\n",
      "Epoch 1481/1500\n",
      "1240/1240 [==============================] - 0s 319us/sample - loss: 0.0992 - acc: 0.9677 - val_loss: 0.2351 - val_acc: 0.9194\n",
      "Epoch 1482/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.0952 - acc: 0.9694 - val_loss: 0.2603 - val_acc: 0.9000\n",
      "Epoch 1483/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.0982 - acc: 0.9653 - val_loss: 0.2824 - val_acc: 0.9097\n",
      "Epoch 1484/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1041 - acc: 0.9661 - val_loss: 0.2238 - val_acc: 0.9226\n",
      "Epoch 1485/1500\n",
      "1240/1240 [==============================] - 0s 280us/sample - loss: 0.0986 - acc: 0.9677 - val_loss: 0.2489 - val_acc: 0.9226\n",
      "Epoch 1486/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.1060 - acc: 0.9540 - val_loss: 0.2062 - val_acc: 0.9355\n",
      "Epoch 1487/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.0950 - acc: 0.9742 - val_loss: 0.2183 - val_acc: 0.9226\n",
      "Epoch 1488/1500\n",
      "1240/1240 [==============================] - 0s 287us/sample - loss: 0.0999 - acc: 0.9677 - val_loss: 0.2084 - val_acc: 0.9387\n",
      "Epoch 1489/1500\n",
      "1240/1240 [==============================] - 0s 279us/sample - loss: 0.1012 - acc: 0.9653 - val_loss: 0.2432 - val_acc: 0.9194\n",
      "Epoch 1490/1500\n",
      "1240/1240 [==============================] - 0s 282us/sample - loss: 0.0985 - acc: 0.9685 - val_loss: 0.1896 - val_acc: 0.9387\n",
      "Epoch 1491/1500\n",
      "1240/1240 [==============================] - 0s 269us/sample - loss: 0.0962 - acc: 0.9726 - val_loss: 0.2144 - val_acc: 0.9290\n",
      "Epoch 1492/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.0997 - acc: 0.9685 - val_loss: 0.2089 - val_acc: 0.9290\n",
      "Epoch 1493/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.1020 - acc: 0.9653 - val_loss: 0.2020 - val_acc: 0.9290\n",
      "Epoch 1494/1500\n",
      "1240/1240 [==============================] - 0s 283us/sample - loss: 0.0936 - acc: 0.9637 - val_loss: 0.1890 - val_acc: 0.9194\n",
      "Epoch 1495/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.1108 - acc: 0.9597 - val_loss: 0.2340 - val_acc: 0.9129\n",
      "Epoch 1496/1500\n",
      "1240/1240 [==============================] - 0s 275us/sample - loss: 0.0931 - acc: 0.9710 - val_loss: 0.2007 - val_acc: 0.9387\n",
      "Epoch 1497/1500\n",
      "1240/1240 [==============================] - 0s 273us/sample - loss: 0.1008 - acc: 0.9669 - val_loss: 0.3034 - val_acc: 0.9032\n",
      "Epoch 1498/1500\n",
      "1240/1240 [==============================] - 0s 272us/sample - loss: 0.0959 - acc: 0.9685 - val_loss: 0.2374 - val_acc: 0.9129\n",
      "Epoch 1499/1500\n",
      "1240/1240 [==============================] - 0s 281us/sample - loss: 0.0956 - acc: 0.9685 - val_loss: 0.2202 - val_acc: 0.9194\n",
      "Epoch 1500/1500\n",
      "1240/1240 [==============================] - 0s 274us/sample - loss: 0.0958 - acc: 0.9661 - val_loss: 0.2899 - val_acc: 0.9129\n",
      "Confusion matrix, without normalization\n",
      "[[88  1  0  0]\n",
      " [ 4 65  4  5]\n",
      " [ 1  2 69  9]\n",
      " [ 0  1  0 61]]\n",
      "Normalized confusion matrix\n",
      "[[0.99 0.01 0.   0.  ]\n",
      " [0.05 0.83 0.05 0.06]\n",
      " [0.01 0.02 0.85 0.11]\n",
      " [0.   0.02 0.   0.98]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "'''\n",
    "#the dense layer is a fully connected layer, meaning all the neurons in a layer are connected to those in the next layer.\n",
    "#The Flatten layer is a utility layer that flattens the input of shape \n",
    "#Keras Conv2D is a 2D Convolution Layer, this layer creates \n",
    " a convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n",
    "#Max pooling operation for 2D spatial data. Downsamples the input representation \n",
    " by taking the maximum value over the window defined by pool_size for each dimension along the features axis.\n",
    "#Stride is the number of pixels shifts over the input matrix. \n",
    " When the stride is 1 then we move the filters to 1 pixel at a time.\n",
    "#Same padding means the size of output feature-maps are the same as the input feature-maps \n",
    "'''\n",
    "model = Sequential()\n",
    "#In a CNN context, people sometimes use \"kernel size\" to mean the size of a convolutional filter, and likewise a \"kernel\" is the filter itself.\n",
    "#First convolution layer, it consist of 64 kernals, Therefore creating 64 samples for an input.\n",
    "model.add(Conv2D(64, kernel_size=(2,2), input_shape=(5,5,1), strides=(1, 1), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#Second convolutional layer, it consist of 128 kernals, Therefore creating 128 samples for each 64 input from previous layes.\n",
    "model.add(Conv2D(128, (2, 2), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#compiling the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#output the summary of the network\n",
    "model.summary()\n",
    "batch_size = 10\n",
    "#Traversing the data set for 1500 times.\n",
    "epochs = 1500\n",
    "history = model.fit(x_train, y_train_binary,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test_binary))\n",
    "result = model.predict_classes(x_test)\n",
    "\n",
    "#Confusion Metrics\n",
    "def plot_confusion_matrix(y_test, result, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, result)\n",
    "    # Only use the labels that appear in the data\n",
    "  #  classes = classes[unique_labels(y_test, result)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "class_names = ['Low Risk', 'Low Medium', 'Medium Risk', 'High Risk']\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, result, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, result, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 1, 3, 4, 3, 1, 1, 3, 1, 3, 3, 4, 2, 4, 1, 3, 1, 1, 1, 1, 2,\n",
       "       1, 3, 3, 4, 3, 3, 2, 4, 3, 3, 4, 1, 2, 1, 2, 3, 2, 3, 3, 3, 1, 2,\n",
       "       2, 3, 2, 1, 4, 2, 3, 4, 2, 3, 2, 4, 3, 4, 1, 3, 4, 1, 4, 3, 1, 3,\n",
       "       3, 3, 1, 2, 4, 4, 2, 4, 1, 2, 3, 1, 1, 2, 1, 3, 1, 2, 3, 1, 2, 4,\n",
       "       3, 2, 1, 3, 4, 2, 1, 3, 3, 2, 4, 3, 1, 3, 3, 4, 4, 1, 2, 4, 3, 3,\n",
       "       1, 4, 1, 3, 3, 1, 3, 4, 2, 4, 1, 3, 2, 1, 1, 3, 3, 3, 1, 3, 1, 1,\n",
       "       4, 2, 1, 3, 3, 1, 2, 4, 1, 3, 1, 2, 4, 3, 3, 1, 2, 1, 1, 2, 1, 4,\n",
       "       1, 1, 1, 4, 4, 4, 4, 2, 1, 4, 4, 2, 2, 1, 4, 2, 1, 1, 2, 1, 3, 1,\n",
       "       2, 3, 4, 1, 3, 4, 1, 2, 2, 1, 3, 3, 3, 1, 1, 1, 3, 4, 3, 1, 1, 1,\n",
       "       1, 3, 3, 4, 2, 3, 1, 3, 4, 4, 1, 3, 1, 1, 1, 1, 4, 1, 1, 4, 3, 1,\n",
       "       2, 4, 3, 2, 2, 3, 4, 1, 2, 1, 2, 2, 3, 1, 3, 3, 1, 4, 4, 3, 4, 1,\n",
       "       1, 3, 1, 1, 3, 3, 1, 4, 3, 1, 3, 1, 1, 1, 3, 1, 4, 4, 3, 4, 1, 4,\n",
       "       3, 2, 2, 2, 1, 3, 3, 1, 3, 2, 3, 4, 4, 2, 2, 3, 3, 1, 3, 3, 1, 1,\n",
       "       2, 1, 1, 4, 4, 4, 3, 4, 4, 2, 3, 2, 3, 2, 2, 4, 3, 2, 1, 3, 1, 3,\n",
       "       4, 4], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model into the file \"CNN_model.h5\" \n",
    "model.save('CNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('CNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 5, 5, 64)          320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 2, 2, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 33,861\n",
      "Trainable params: 33,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#checking the summary of the new model, \n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-1.51e+00, -8.66e-01,  1.15e+00, -9.46e-01, -1.35e+00,\n",
       "            3.29e-01,  1.67e+00, -1.83e+00,  8.44e-01, -1.38e+00,\n",
       "            1.41e+00, -4.73e-01, -4.96e-02,  1.86e+00, -9.78e-01,\n",
       "            3.43e-01, -1.87e-01,  4.48e-01,  1.82e+00, -5.17e-01,\n",
       "            1.32e-01, -1.26e+00,  1.22e+00,  8.32e-01,  1.36e+00,\n",
       "            5.31e-01,  4.33e-01,  1.72e-01, -1.16e+00,  1.95e+00,\n",
       "            9.07e-01,  2.31e+00,  1.10e-01,  1.15e+00, -6.44e-02,\n",
       "           -3.80e-01, -8.38e-01, -3.92e-01,  1.27e-01,  1.38e+00,\n",
       "           -1.25e+00, -4.86e-01,  1.71e-01, -1.25e-01, -2.84e-02,\n",
       "            1.51e+00, -1.74e+00,  6.00e-01, -9.06e-01, -2.12e-01,\n",
       "           -1.90e+00,  1.39e+00,  1.21e+00, -6.22e-02,  1.11e-01,\n",
       "            3.18e+00, -6.00e-02,  1.29e+00,  1.23e+00, -1.45e+00,\n",
       "            1.76e+00, -1.44e-01, -1.20e-01,  9.65e-01]],\n",
       " \n",
       "         [[ 1.45e-01,  1.04e+00,  9.36e-01,  4.85e-01, -8.77e-01,\n",
       "            9.18e-01, -5.66e-01, -1.61e-01,  2.49e-01,  1.30e+00,\n",
       "            2.94e-03,  1.54e-01,  9.24e-02, -2.89e-01, -6.26e-01,\n",
       "            3.84e-01,  4.48e-02, -1.31e-01,  2.78e-01,  1.84e-01,\n",
       "            8.70e-01,  1.95e-01,  2.58e-01,  2.45e-01, -2.50e-01,\n",
       "            4.21e-01,  3.20e-01,  9.12e-01,  2.15e-01, -3.07e-01,\n",
       "            5.14e-01, -7.12e-01,  7.40e-01,  5.93e-01, -1.19e-01,\n",
       "            1.51e-01,  5.71e-01,  1.12e+00,  1.41e-01,  7.35e-02,\n",
       "            1.94e-01, -7.96e-01,  1.03e+00, -2.30e-01, -9.32e-02,\n",
       "            4.32e-02,  4.51e-02,  5.82e-01, -5.21e-01, -3.07e-01,\n",
       "            6.75e-02, -6.43e-01, -5.68e-01,  1.16e+00, -2.68e-01,\n",
       "           -9.86e-02,  4.24e-01, -6.02e-01,  5.32e-01,  9.07e-01,\n",
       "           -5.44e-01,  1.72e-01, -2.36e-01,  5.53e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.44e+00, -8.18e-01, -6.65e-01, -7.92e-01,  1.33e+00,\n",
       "           -1.06e+00, -1.52e+00, -7.61e-02,  3.68e-01,  2.20e-01,\n",
       "           -3.39e-01,  9.87e-01,  1.83e+00,  3.35e-01, -8.06e-01,\n",
       "            3.30e-01,  1.79e+00,  1.75e+00, -8.36e-01,  8.52e-01,\n",
       "            2.27e-02, -6.79e-01, -5.14e-01,  5.13e-02,  1.08e+00,\n",
       "            1.16e+00, -3.84e-01,  4.33e-01, -1.65e+00, -8.65e-03,\n",
       "            6.45e-01, -8.10e-01,  1.88e-02, -1.05e+00, -7.09e-01,\n",
       "            8.66e-01,  8.64e-02, -5.05e-01, -1.43e-01, -3.70e-01,\n",
       "           -9.49e-01,  1.99e+00, -3.54e-01, -1.24e+00, -2.82e-01,\n",
       "           -8.49e-01, -1.13e+00, -1.38e+00,  2.30e-01,  2.30e+00,\n",
       "           -1.16e+00, -1.33e+00, -1.67e+00,  2.94e-01,  1.89e+00,\n",
       "           -1.15e-01,  2.37e-01, -1.18e+00, -8.66e-01, -1.60e+00,\n",
       "           -6.96e-01,  1.91e+00, -1.02e+00,  4.59e-01]],\n",
       " \n",
       "         [[ 2.67e-01,  7.84e-01,  1.08e-01,  1.55e+00, -4.70e-01,\n",
       "           -4.88e-01, -5.39e-01,  5.97e-02,  2.99e-01, -8.36e-01,\n",
       "            1.05e+00,  1.17e+00, -6.27e-01,  9.97e-02,  6.23e-01,\n",
       "            3.88e-01, -6.03e-02,  1.56e-01, -5.30e-01,  1.29e+00,\n",
       "            8.74e-01, -3.56e-02, -9.44e-02,  6.18e-01, -9.99e-01,\n",
       "            3.41e-01, -9.11e-01,  4.17e-01,  2.67e-01, -3.28e-01,\n",
       "           -4.36e-01, -7.31e-01,  7.40e-01,  1.07e-01,  1.34e-01,\n",
       "            1.26e+00,  4.23e-01,  8.83e-01,  1.96e+00, -4.52e-01,\n",
       "           -1.58e-01, -6.80e-01,  8.79e-01,  2.21e-01, -1.51e-02,\n",
       "            2.63e-01,  3.16e-01, -1.02e-01, -6.41e-01, -7.26e-02,\n",
       "            2.25e-01, -5.81e-01, -4.91e-01,  5.55e-01, -5.91e-01,\n",
       "           -1.86e-01,  5.75e-01, -5.41e-01,  4.95e-02, -5.29e-01,\n",
       "           -5.53e-01, -4.71e-01,  1.99e-01,  1.72e-01]]]], dtype=float32),\n",
       " array([-0.42,  0.13,  0.29,  0.09, -0.24, -0.05, -0.15, -0.37, -0.28,\n",
       "        -0.13,  0.4 ,  0.34,  0.12,  0.28, -0.32,  0.24,  0.17, -0.27,\n",
       "         0.16,  0.34,  0.33, -0.23,  0.17, -0.28,  0.14, -0.37, -0.34,\n",
       "         0.35, -0.38,  0.11,  0.32,  0.04,  0.29,  0.15, -0.09,  0.36,\n",
       "         0.  ,  0.15,  0.4 , -0.  , -0.31, -0.11,  0.27, -0.17, -0.12,\n",
       "         0.1 , -0.42, -0.14, -0.33,  0.13, -0.44, -0.2 , -0.26,  0.34,\n",
       "         0.09,  0.11, -0.41, -0.17,  0.18, -0.46,  0.01,  0.14, -0.19,\n",
       "        -0.  ], dtype=float32),\n",
       " array([[[[ 9.92e-01,  8.33e-01, -6.28e-02, ..., -4.37e-02, -6.88e-01,\n",
       "           -3.49e-02],\n",
       "          [-8.40e-01, -2.43e-01, -3.82e-02, ..., -2.31e-02,  7.25e-01,\n",
       "            5.64e-02],\n",
       "          [-6.02e-01, -4.35e-02, -7.22e-02, ..., -3.69e-03, -5.29e-01,\n",
       "            5.28e-02],\n",
       "          ...,\n",
       "          [-1.59e+00, -3.26e+00, -3.67e-02, ...,  3.35e-02, -8.56e-01,\n",
       "           -2.09e-03],\n",
       "          [ 4.14e-01, -5.81e-02, -7.40e-02, ..., -7.44e-02, -3.67e-01,\n",
       "            6.47e-02],\n",
       "          [-1.06e-01,  1.34e+00,  6.83e-02, ...,  5.26e-02, -1.07e-01,\n",
       "            2.70e-02]],\n",
       " \n",
       "         [[ 5.22e-01, -8.34e-02, -4.86e-02, ...,  7.03e-02,  3.19e-02,\n",
       "            1.40e-02],\n",
       "          [ 6.43e-01, -1.09e-01, -1.95e-02, ..., -6.52e-02, -1.47e-01,\n",
       "            8.93e-02],\n",
       "          [ 5.54e-01, -3.31e-02, -7.71e-02, ...,  8.01e-02,  1.09e-01,\n",
       "            4.33e-03],\n",
       "          ...,\n",
       "          [-1.57e-01, -7.55e-03, -4.39e-02, ..., -6.19e-02, -2.41e-01,\n",
       "           -1.21e-02],\n",
       "          [-1.12e-01,  5.07e-02,  5.83e-02, ...,  8.50e-02, -4.46e-01,\n",
       "           -1.44e-02],\n",
       "          [-6.76e-01,  6.11e-03,  6.35e-02, ...,  3.99e-03,  4.46e-01,\n",
       "           -1.04e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.19e-01, -2.00e-01, -2.65e-03, ..., -5.83e-02,  4.24e-02,\n",
       "            2.23e-02],\n",
       "          [ 2.98e-02,  3.04e-01,  2.19e-02, ...,  5.66e-02,  6.61e-02,\n",
       "           -6.57e-02],\n",
       "          [-2.28e-01,  7.14e-01,  7.03e-03, ..., -7.38e-02,  1.65e+00,\n",
       "           -6.05e-02],\n",
       "          ...,\n",
       "          [ 7.92e-02, -1.36e-02, -3.56e-02, ...,  8.41e-02, -1.23e-01,\n",
       "           -5.43e-02],\n",
       "          [ 5.46e-01,  1.13e-01,  3.31e-02, ..., -6.01e-02,  3.54e-01,\n",
       "           -6.16e-02],\n",
       "          [ 8.56e-02,  1.49e-01, -5.20e-02, ..., -4.66e-03, -1.28e-02,\n",
       "            8.81e-02]],\n",
       " \n",
       "         [[ 2.47e-01, -3.98e-02,  6.82e-02, ...,  4.97e-02,  6.98e-01,\n",
       "           -1.33e-02],\n",
       "          [ 7.25e-02,  2.64e-02, -7.68e-02, ...,  2.96e-02,  2.57e-01,\n",
       "            1.96e-02],\n",
       "          [ 7.88e-01, -1.72e-02, -7.54e-02, ..., -6.45e-02, -1.97e+00,\n",
       "            7.41e-02],\n",
       "          ...,\n",
       "          [ 1.36e-02,  3.21e-02,  2.69e-02, ...,  4.65e-02, -3.72e-02,\n",
       "            3.96e-02],\n",
       "          [ 5.56e-01,  4.20e-02,  2.75e-02, ..., -6.13e-02,  4.28e-01,\n",
       "           -8.03e-02],\n",
       "          [ 3.06e-02,  9.67e-02, -7.82e-02, ...,  7.59e-02, -7.44e-02,\n",
       "            4.13e-02]]]], dtype=float32),\n",
       " array([ 0.26, -0.36, -0.  ,  0.39,  0.05,  0.39, -0.07, -0.2 , -0.28,\n",
       "         0.36, -0.24, -0.07, -0.  ,  0.23, -0.09, -0.01, -0.62, -0.08,\n",
       "        -0.01,  0.07, -0.17, -0.36, -0.32, -0.02,  0.16, -0.02, -0.27,\n",
       "        -0.57, -0.34, -0.84,  0.1 ,  0.18,  0.28,  0.16, -0.12,  0.6 ,\n",
       "         0.17, -0.34, -0.16,  0.1 , -0.08,  0.1 , -0.05, -0.01, -0.02,\n",
       "        -0.16,  0.02, -0.57, -0.02, -0.01,  0.4 , -0.03, -0.02, -0.3 ,\n",
       "        -0.04, -0.87, -0.5 ,  0.18, -0.02, -0.01, -0.11, -0.01, -0.27,\n",
       "        -0.02, -0.03,  0.26, -0.3 , -0.4 , -0.37, -0.18, -0.02,  0.11,\n",
       "         0.18, -0.05, -0.45, -0.1 , -0.36, -0.53, -0.09, -0.08,  0.18,\n",
       "        -0.42, -0.25, -0.01, -0.08,  0.06, -0.  , -0.04,  0.09, -0.01,\n",
       "         0.22, -0.02, -0.23,  0.18, -0.01,  0.03, -0.3 ,  0.26,  0.45,\n",
       "        -0.48, -0.01,  0.35,  0.02, -0.19,  0.22, -0.01,  0.27, -0.88,\n",
       "        -0.03, -0.  , -0.34,  0.16,  0.3 , -0.39, -0.35, -0.15, -0.03,\n",
       "         0.21, -0.02,  0.31, -0.  , -0.19, -0.47,  0.14,  0.22, -0.  ,\n",
       "         0.21, -0.14], dtype=float32),\n",
       " array([[-1.76e-02, -2.04e-01, -1.11e+00, -3.66e-01, -8.57e-01],\n",
       "        [-3.11e-01, -3.91e-01,  7.33e-01, -1.95e+00, -2.94e+00],\n",
       "        [-2.10e-01, -1.10e-01, -1.12e-01,  6.71e-02,  1.97e-01],\n",
       "        [-1.12e-01,  1.27e+00, -2.12e+00,  6.12e-01, -2.54e+00],\n",
       "        [-4.08e-01, -1.97e+00, -1.79e-01, -4.80e-01,  1.07e-01],\n",
       "        [-1.40e+00, -3.19e-01, -9.92e-01, -3.50e-01, -4.40e-01],\n",
       "        [-1.32e-01, -2.35e-01, -6.56e-01,  8.81e-01, -2.50e+00],\n",
       "        [-7.18e-01, -2.87e+00,  7.89e-01, -1.47e+00,  4.13e-01],\n",
       "        [-5.71e-01, -5.91e+00, -1.50e-01, -3.81e-01,  2.89e-01],\n",
       "        [-6.60e-01, -2.25e+00, -8.82e-01,  2.47e-01, -3.13e-01],\n",
       "        [-5.88e-01,  1.08e+00, -4.64e+00, -1.02e+00,  8.64e-01],\n",
       "        [ 7.43e-02, -1.53e+00,  4.28e-01, -2.65e-01, -6.36e-01],\n",
       "        [-6.52e-02, -6.45e-02, -2.06e-01, -1.10e-01,  3.66e-02],\n",
       "        [-5.90e-01, -5.70e-02, -2.87e-01, -2.61e-01, -1.70e+00],\n",
       "        [-7.25e-01, -4.63e-01, -1.35e-01, -6.50e-01, -1.40e+00],\n",
       "        [ 1.02e-01,  5.39e-03, -9.66e-02,  1.92e-01, -1.03e-01],\n",
       "        [ 4.55e-02,  2.74e+00, -2.59e+00,  1.47e+00, -4.69e+00],\n",
       "        [-1.35e+00, -1.19e+00, -4.50e-01, -6.15e-01, -4.17e-01],\n",
       "        [-4.24e-01, -1.69e+00, -1.81e+00,  2.00e+00, -2.45e+00],\n",
       "        [-5.98e-01, -2.82e+00,  1.15e-01, -2.72e-02, -1.48e+00],\n",
       "        [-4.61e-01, -5.89e+00, -1.22e+00, -5.70e-01,  1.18e+00],\n",
       "        [-8.12e-01,  4.42e+00, -5.07e+00, -3.63e+00,  1.85e+00],\n",
       "        [-1.00e+00, -3.48e+00,  1.33e+00, -1.61e-01, -1.97e+00],\n",
       "        [ 1.18e-01, -1.48e-01, -5.50e-02, -2.32e-02, -1.64e-01],\n",
       "        [-3.61e-01,  2.32e-01, -1.90e+00, -1.45e+00,  4.35e-02],\n",
       "        [ 1.89e-01, -1.41e-01, -3.61e-02,  1.44e-01,  2.81e-02],\n",
       "        [-8.27e-02,  1.96e+00, -4.44e+00, -3.36e-01, -6.53e-01],\n",
       "        [ 1.81e-01, -1.46e+00,  3.13e+00,  3.98e-02, -4.42e+00],\n",
       "        [-1.04e+00, -1.41e+00, -6.95e-02, -7.08e-01, -3.05e-01],\n",
       "        [-1.50e-02, -3.22e-03, -1.73e+00,  1.43e+00, -3.81e+00],\n",
       "        [-1.60e+00, -3.60e-01, -3.13e-01, -5.94e-01, -9.55e-01],\n",
       "        [-1.48e-01,  2.10e+00, -1.20e+00, -2.46e+00, -5.32e-01],\n",
       "        [-8.86e-01, -3.28e-01, -4.57e-01, -3.68e-01, -1.28e+00],\n",
       "        [-1.28e+00, -1.46e-01, -5.77e-01, -5.67e-01, -1.10e+00],\n",
       "        [-6.76e-01, -1.36e+00, -3.65e-01, -6.67e-01, -3.15e-01],\n",
       "        [-2.36e-01,  1.57e+00,  4.20e-01,  2.43e+00, -7.44e+00],\n",
       "        [-9.64e-01, -1.70e-01, -6.63e-01, -4.40e-01, -1.40e+00],\n",
       "        [ 8.46e-02,  2.26e+00,  1.46e-02, -1.37e+00, -2.13e+00],\n",
       "        [-2.75e-01, -2.96e-02, -1.27e+00, -1.37e+00,  5.94e-01],\n",
       "        [ 1.73e-01,  9.24e-01, -4.68e-01, -8.01e-01, -8.72e-02],\n",
       "        [-7.75e-01, -2.39e+00,  3.38e-01, -1.28e+00, -6.74e-01],\n",
       "        [-5.59e-01, -3.64e-01, -5.57e-01, -1.99e+00, -3.61e-02],\n",
       "        [ 5.37e-02, -1.26e-01, -3.44e-02, -2.05e-01,  4.62e-02],\n",
       "        [-2.05e-01, -7.56e-01,  4.16e+00, -7.80e+00, -1.28e+00],\n",
       "        [ 6.53e-02, -1.61e-01,  1.76e-01,  3.92e-02, -1.32e-01],\n",
       "        [-6.06e-01, -1.59e+00, -3.44e+00, -5.01e-01,  1.23e+00],\n",
       "        [-2.69e-01, -8.57e-01, -8.10e-01,  6.93e-02, -2.71e+00],\n",
       "        [ 1.75e-01, -1.74e-01, -5.54e+00, -8.24e-01,  1.08e+00],\n",
       "        [ 1.71e-01, -1.05e-01, -1.93e-01,  1.35e-01,  1.25e-01],\n",
       "        [-6.89e-02, -1.89e-01, -1.97e-01, -2.13e-01,  2.02e-01],\n",
       "        [-1.15e+00, -5.91e-01, -1.51e+00,  2.30e-01, -1.68e-01],\n",
       "        [-2.78e-01,  6.52e-01, -1.27e+00,  3.83e-01, -1.60e+00],\n",
       "        [ 1.78e-02,  8.33e-02,  1.42e-01,  1.60e-01,  1.48e-01],\n",
       "        [-1.48e-01, -5.58e-01,  1.07e+00, -1.58e+00, -3.22e+00],\n",
       "        [ 5.59e-02,  3.38e+00,  2.36e-01, -7.23e+00,  7.11e-02],\n",
       "        [ 8.82e-02, -6.77e-01, -1.33e+00, -7.70e-01, -3.76e-01],\n",
       "        [-6.80e-01, -1.60e+00,  1.02e+00, -8.54e-01, -1.70e+00],\n",
       "        [-1.11e+00, -5.08e-01, -1.16e-01, -1.77e+00,  5.06e-02],\n",
       "        [ 4.25e-02, -6.53e-02,  1.08e-01, -1.46e-01,  4.00e-02],\n",
       "        [-1.28e-02, -3.13e-02,  8.04e-02,  6.84e-02, -1.15e-01],\n",
       "        [-4.29e-02,  2.34e+00,  8.70e-01, -5.16e+00, -2.30e+00],\n",
       "        [ 1.88e-01, -9.25e-02,  1.87e-02, -5.00e-02,  5.35e-02],\n",
       "        [-1.26e-01, -6.36e-01, -1.87e+00, -3.29e+00,  1.74e+00],\n",
       "        [-1.09e-01, -2.08e-01, -1.15e-02, -1.59e-01,  2.65e-02],\n",
       "        [ 1.13e-01, -1.23e-01,  1.67e-03,  1.97e-01, -7.23e-02],\n",
       "        [-2.25e-01, -2.57e+00,  7.10e-01, -6.70e-01, -2.19e+00],\n",
       "        [-8.80e-01, -1.08e+00, -3.50e-01, -5.32e-01, -3.09e-01],\n",
       "        [-4.28e-01, -8.30e-02, -4.13e+00, -3.83e+00,  3.99e+00],\n",
       "        [-3.43e-02,  1.98e+00, -6.40e-01, -6.70e-01, -1.18e+00],\n",
       "        [ 5.35e-02, -3.73e+00, -5.12e+00, -4.48e+00,  4.91e+00],\n",
       "        [-5.99e-02,  4.41e+00, -4.05e+00,  6.73e-01, -4.55e+00],\n",
       "        [-7.60e-01,  1.10e+00,  4.96e-01, -3.82e+00, -3.88e-01],\n",
       "        [-3.65e-01, -2.56e-01, -4.37e-01, -7.30e-01, -1.27e+00],\n",
       "        [-6.44e-01, -1.75e-01, -8.67e-01, -8.80e-01, -2.69e-01],\n",
       "        [-2.53e-02, -1.10e+00, -1.37e+00, -8.37e-01, -5.48e-01],\n",
       "        [-7.49e-01, -2.27e+00, -4.90e-01,  3.44e-01, -1.01e+00],\n",
       "        [-7.91e-01, -2.16e-01, -3.02e+00,  1.11e+00, -1.67e-01],\n",
       "        [-3.26e-02,  3.63e-01,  1.47e+00, -5.27e+00, -6.57e-01],\n",
       "        [-6.37e-02,  1.25e+00, -3.71e+00, -1.58e+00,  6.81e-01],\n",
       "        [-4.96e-01, -4.09e+00, -3.54e+00,  9.15e-01,  1.56e+00],\n",
       "        [-7.28e-01,  1.89e+00, -1.27e+00,  9.78e-01, -3.90e+00],\n",
       "        [-5.36e-02, -2.86e+00, -1.08e+00, -1.18e+00,  4.47e-01],\n",
       "        [ 7.31e-02, -1.64e+00, -8.17e+00, -3.95e+00,  5.68e+00],\n",
       "        [ 1.05e-01, -1.06e-01,  1.67e-01,  6.93e-02, -1.92e-01],\n",
       "        [-2.30e-01,  8.81e-02, -2.16e-01, -1.65e-01, -7.41e-02],\n",
       "        [-6.79e-01,  2.20e+00, -3.19e+00,  1.81e+00, -4.59e+00],\n",
       "        [ 5.30e-02, -6.00e-02, -1.06e-02, -3.83e-02,  1.61e-01],\n",
       "        [ 1.38e-01, -8.28e-02,  7.23e-02, -3.29e-02, -2.60e-02],\n",
       "        [-2.21e-01,  7.53e-01, -1.10e-01, -1.39e+00, -2.77e+00],\n",
       "        [ 1.19e-01,  6.49e-03,  1.28e-01,  2.78e-02, -1.41e-01],\n",
       "        [-1.57e+00, -3.20e-01, -3.83e-01, -4.82e-01, -9.85e-01],\n",
       "        [ 1.45e-01, -9.72e-02,  3.78e-02, -4.17e-02,  1.43e-02],\n",
       "        [-9.21e-01, -1.21e+00, -8.37e-01, -1.11e+00,  8.45e-01],\n",
       "        [-1.13e-01, -2.40e+00, -1.24e+00,  1.30e+00, -7.49e-01],\n",
       "        [-1.47e-01, -2.87e-02,  9.07e-02,  1.04e-01,  1.29e-01],\n",
       "        [-5.27e-01, -2.52e+00,  6.26e-01, -1.17e+00, -6.19e-01],\n",
       "        [-1.15e+00, -2.41e+00, -2.65e-01, -1.11e+00, -1.08e-01],\n",
       "        [-8.36e-01, -2.03e+00, -1.69e+00, -9.74e-02, -2.22e-01],\n",
       "        [-2.59e-02, -3.36e+00,  2.35e+00, -3.59e+00, -3.26e-01],\n",
       "        [-1.32e-03, -6.62e-01, -1.56e+00, -1.17e+00, -3.51e-01],\n",
       "        [ 1.79e-01, -4.55e-02, -1.56e-01,  1.93e-01, -1.31e-01],\n",
       "        [-5.93e-01,  9.67e-01, -1.96e+00, -1.38e-01, -1.16e+00],\n",
       "        [-4.26e-02, -4.98e-01, -5.69e-01, -2.23e+00, -5.40e-01],\n",
       "        [ 3.63e-02, -5.70e-01, -5.10e-01, -1.30e+00, -8.98e-01],\n",
       "        [-1.18e+00, -3.87e-01, -1.28e+00, -5.19e-01, -2.40e-01],\n",
       "        [ 2.04e-01, -1.83e-01,  3.38e-02, -4.43e-02, -1.10e-01],\n",
       "        [ 5.52e-02,  2.90e+00,  2.27e+00, -7.48e+00, -8.72e-01],\n",
       "        [ 1.86e-01,  3.41e-01,  1.67e+00,  5.31e-01, -4.86e+00],\n",
       "        [ 1.93e-01, -1.03e-01, -7.02e-02, -4.22e-02, -7.87e-02],\n",
       "        [-3.87e-01, -2.49e+00, -5.29e-01,  1.96e-01, -1.13e+00],\n",
       "        [ 4.56e-02,  2.91e-01, -5.72e+00, -3.30e+00,  3.65e+00],\n",
       "        [ 1.98e-01,  3.00e-01, -4.41e-01, -7.79e-01,  3.59e-01],\n",
       "        [-1.57e+00, -1.32e+00, -3.75e-01, -2.59e-01, -4.15e-01],\n",
       "        [ 4.95e-02, -3.99e-01,  1.61e+00, -6.06e-01, -1.97e+00],\n",
       "        [-6.65e-01, -1.01e+00, -5.44e+00,  2.46e+00,  2.24e+00],\n",
       "        [-1.33e+00, -1.20e+00, -3.61e-01, -5.30e-01, -1.72e-01],\n",
       "        [ 1.89e-01, -2.27e-02, -3.04e-02, -1.08e-01,  1.16e-01],\n",
       "        [ 2.00e-01, -3.54e+00, -1.25e+00,  3.67e+00,  9.08e-02],\n",
       "        [-5.09e-02, -1.97e-01,  1.13e-01,  5.26e-02, -1.06e-01],\n",
       "        [-1.49e-01, -1.34e-01, -3.82e-01, -4.59e+00,  2.25e+00],\n",
       "        [ 1.88e-01, -1.34e-01,  1.82e-01, -5.43e-02, -4.82e-02],\n",
       "        [ 1.68e-01,  4.48e-01,  2.37e+00, -4.89e+00, -1.57e+00],\n",
       "        [-6.54e-01,  2.69e+00, -6.03e+00,  1.61e+00,  3.66e-01],\n",
       "        [ 3.05e-03, -1.43e+00,  4.70e-01, -1.78e+00, -7.08e-01],\n",
       "        [-6.87e-01,  1.55e+00, -1.33e+00, -1.62e-01, -2.85e+00],\n",
       "        [ 1.16e-01, -6.50e-02, -1.54e-01,  1.53e-01, -1.46e-01],\n",
       "        [-6.29e-01, -3.65e+00,  3.03e-01, -2.79e+00,  3.28e+00],\n",
       "        [-2.21e-01,  2.86e-01,  3.50e-02,  1.58e-01,  3.99e-03]],\n",
       "       dtype=float32),\n",
       " array([-1.59, -0.63, -0.81, -0.44, -0.54], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saved weights of the CNN network.\n",
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
